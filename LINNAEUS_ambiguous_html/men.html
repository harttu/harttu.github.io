
<!doctype html><html lang="en"> <head><meta charset="utf-8"> 
<title>s800 inconsistencies</title> 
<style>  
.yellow { background-color:rgba(50, 180, 180, 0.5); } 
.red { background-color:rgba(214, 75, 79, 0.5); } 
.blue { background-color:rgba(75, 75, 214, 0.5); } 
table { border-collapse: collapse; } 
th, td { border: 1px solid black; padding: 4px; } 
th {  cursor: pointer; } 
th:hover { background: yellow; }
</style></head><body>
<h2>men</h2><span class="red">Not tagged name</span> - <span class="blue">Tagged name</span> - <span class="yellow">Other name</span><br><hr><h3>pmcA1551914</h3>Travel-Related Venous Thrombosis: Results from a Large Population-Based Case Control Study (MEGA Study)
Abstract
Background
Recent studies have indicated an increased risk of venous thrombosis after air travel. Nevertheless, questions on the magnitude of risk, the underlying mechanism, and modifying factors remain unanswered.<br><br>Methods and Findings
We studied the effect of various modes and duration of travel on the risk of venous thrombosis in a large ongoing case-control study on risk factors for venous thrombosis in an unselected population (MEGA study). We also assessed the combined effect of travel and prothrombotic mutations, body mass index, height, and oral contraceptive use.
Since March 1999, consecutive <span class="yellow">patients</span> younger than 70 y with a first venous thrombosis have been invited to participate in the study, with their partners serving as matched control individuals. Information has been collected on acquired and genetic risk factors for venous thrombosis. Of 1,906 <span class="yellow">patients</span>, 233 had traveled for more than 4 h in the 8 wk preceding the event. Traveling in general was found to increase the risk of venous thrombosis 2-fold (odds ratio [OR] 2.1; 95% confidence interval [CI] 1.5–3.0). The risk of flying was similar to the risks of traveling by car, bus, or train. The risk was highest in the first week after traveling. Travel by car, bus, or train led to a high relative risk of thrombosis in individuals with factor V Leiden (OR 8.1; 95% CI 2.7–24.7), in those who had a body mass index of more than 30 kg/m2 (OR 9.9; 95% CI 3.6–27.6), in those who were more than 1.90 m tall (OR 4.7; 95% CI 1.4–15.4), and in those who used oral contraceptives (estimated OR > 20). For air travel these synergistic findings were more apparent, while <span class="yellow">people</span> shorter than 1.60 m had an increased risk of thrombosis after air travel (OR 4.9; 95% CI 0.9–25.6) as well.<br><br>Conclusions
The risk of venous thrombosis after travel is moderately increased for all modes of travel. Subgroups exist in which the risk is highly increased.<br><br>
Background.
Recently there has been increasing concern that blood clots (thromboses) in the leg or lungs occur with greater frequency after air travel. Several theories have been put forward to explain why this increase might happen, including the fact that air passengers tend to not move around much, or possibly that reduced amounts of oxygen in the blood make the blood more likely to clot. Understanding what causes such clots is important as it would help us come up with suggestions of ways to prevent them.<br><br>Why Was This Study Done?
It is not possible to test in a controlled trial whether travel causes an increase in blood clots, so the next best way of studying this problem is to do a case-control study, in which <span class="yellow">people</span> with blood clots (cases) are compared with similar <span class="yellow">people</span> who don't have a blood clot (controls—in this case, the partners of the cases), and the differences in a number of contributing factors are assessed.<br><br>What Did the Researchers Do and Find?
Since 1999, the MEGA (Multiple Environmental and Genetic Assessment of Risk Factors for Venous Thrombosis) study has aimed to identify all <span class="yellow">people</span> in an area of the Netherlands who develop a blood clot for the first time, by seeking out <span class="yellow">people</span> who receive treatment for blood clots. At the time of this report, 1,906 <span class="yellow">people</span> with clots had been found; of these, 233 had traveled for more than four hours in the eight weeks preceding the event. Traveling in general was found to increase the risk of clots two-fold, and the risk was highest in the week after traveling. The risk of flying was similar to the risk of traveling by car, bus, or train, and was highest in the first week after traveling. Certain other factors increased the risk of a blood clot even more, such as having a particular mutation (known as factor V Leiden) in a gene involved in blood clotting, having a body mass index of more than 30 kg/m2 (over 30 kg/m2 is defined as being obese), being more than 1.90 meters tall, and using oral contraceptives. All these factors made the risk of clots especially after air travel worse; in addition, <span class="yellow">people</span> shorter than 1.60 meters also had an increased risk of thrombosis after air travel. However, it should be borne in mind that the number of cases in each of these various groups was quite small, and the overall risk of getting a thrombosis is still low.<br><br>What Do These Findings Mean?
Since the risks of thrombosis are increased for all types of long travel, it seems that the main factor causing the thrombosis is immobility. However, since the risk is even higher for air travel, the relative lack of oxygen may also play a part. One interesting aspect of this study is that the researchers used partners as controls; in order to be sure that doing this did not make the results invalid, the researchers had to carefully adjust for differences between the cases and controls, such as the fact that partners were generally of the opposite sex. In a related Perspective (DOI: 10.1371/journal.pmed.0030300), Kenneth Rothman discusses the study further.<br><br>Additional Information.
Please access these Web sites via the online version of this summary at http://dx.doi.org/10.1371/journal.pmed.0030307.<br><br><br><br>
Introduction
Interest in the role of air travel in the pathogenesis of venous thrombosis has heightened in the past 5 y [1–5]. Venous thrombosis was first linked to air travel in 1954 [6], and as air travel has become more and more common, many case reports and case series have been published since. Several clinical studies have shown an association between air travel and the risk of venous thrombosis. In a series of individuals who died suddenly at Heathrow Airport, death occurred far more often in the arrival than in the departure area [7]. Two similar studies described a “dose-response” relation: the risk of pulmonary embolism in air travelers increased with the distance traveled [5,8]. A number of case-control studies, however, have shown conflicting results [9–11]. More recently, a 2-fold increased risk in <span class="yellow">patients</span> who had traveled by air was described in a case-control study among 210 <span class="yellow">patients</span> and 210 controls [3]. A case-crossover study based on record linking in Australia described a 4-fold increased risk of venous thrombosis in the first 2 wk after a long-haul flight [1]. In terms of absolute risk, two studies found similar results: one performed in New Zealand found a frequency of 1% of venous thrombosis in 878 individuals who had traveled by air for at least 10 h [2], and a German study found venous thrombotic events in 2.8% of 964 individuals who had traveled for more than 8 h in an airplane, as compared to 1% in 1,213 controls [4]. The events in both studies were mostly asymptomatic.
The available evidence suggests that the overall risk of venous thrombosis is moderately increased after air travel. Nevertheless, many questions remain unanswered: the exact underlying mechanism is still unknown, and, related to this, it is not clear whether the risk is increased after air travel only or after long-distance travel in general. Furthermore, the effect of the combination of other risk factors for venous thrombosis and travel has not yet been systematically studied, with the exception of a study by Martinelli et al., who found an additionally increased risk in <span class="yellow">patients</span> with thrombophilia and <span class="yellow">patients</span> who used oral contraceptives [3].
The Multiple Environmental and Genetic Assessment (MEGA) study of risk factors for venous thrombosis is a large ongoing case-control study aimed at assessing the combined effect of genetic and acquired risk factors for venous thrombosis. Cases and control individuals are questioned about—among many other items—travel that occurred shortly before the event. This provides an opportunity to assess the effect of travel on the risk of thrombosis in an unselected population, as well as the effect of the combination of travel with several other risk factors for thrombosis.<br><br>Methods
Study Design
Since March 1999, consecutive <span class="yellow">patients</span> younger than 70 y with a first deep-vein thrombosis (DVT) or pulmonary embolism (PE) have been identified at six regional anticoagulation clinics in the Netherlands. Anticoagulant clinics monitor the anticoagulant therapy of all <span class="yellow">patients</span> in a well-defined geographical area, allowing us to identify consecutive and unselected <span class="yellow">patients</span> with thrombosis. <span class="yellow">Patients</span> who were unable to fill in the questionnaire (because of language or severe psychiatric problems), as well as those who died soon after the venous thrombosis or who were in the end stage of a disease and for that reason did not participate, were not included. All others were considered eligible. Partners of these <span class="yellow">patients</span> were invited as control individuals, and the same exclusion criteria were applied.
All <span class="yellow">participants</span> filled in a detailed standardized questionnaire on general demographic and anthropomorphic characteristics, as well as risk factors for venous thrombosis. The questionnaire was sent to all <span class="yellow">participants</span> within a few weeks after the event and covered the period of 1 y prior to the date of the thrombotic event (index date). When the <span class="yellow">participant</span> was unable to fill in the questionnaire we asked questions by phone, using a standardized mini-questionnaire. Three months after the <span class="yellow">patients</span> had discontinued their oral anticoagulant therapy, they were invited with their partners to the anticoagulation clinic for a blood sample. In those <span class="yellow">patients</span> who continued to take oral anticoagulant therapy for more than 1 y after the event, blood was drawn during therapy. If <span class="yellow">participants</span> were unable to come to the clinic, a buccal swab was sent by mail to replace the blood sample for DNA extraction.
The study protocol was approved by the Ethics Committee of the Leiden University Medical Center. Written informed consent was obtained from all <span class="yellow">participants</span> [12].<br><br>Validation Study of Thrombosis Diagnosis
Discharge letters or diagnostic reports of the venous thrombotic event were obtained for a sample of 742 <span class="yellow">patients</span> who had their first thrombosis between March 1999 and March 2000. The diagnostic management of the <span class="yellow">patients</span> was compared to the diagnostic procedure as described in the Dutch consensus [13]. Diagnosis of clinically suspected DVT of the leg is based on a clinical score, serial compression ultrasonography, and D-dimer assay. Objective testing of clinically suspected pulmonary embolism is based on perfusion and ventilation scintigraphy, ultrasonography of the leg veins, pulmonary angiography, or helical computed tomography. Out of 395 <span class="yellow">patients</span> with DVT of the leg, 384 (97%) were objectively diagnosed, while out of 347 <span class="yellow">patients</span> with PE, 271 (78%) were confirmed with objective testing as certainly having PE. Since the diagnosis appears to be made by objective methods in virtually all cases of DVT, while being more ambiguous for PE, we also analyzed these two manifestations of venous thrombosis separately.<br><br>Current Analysis
For the current analysis we were interested in the effects of travel, and its combined effect with other common risk factors for venous thrombosis. <span class="yellow">Patients</span> with a solitary arm thrombosis were excluded from this analysis. Of 3,902 eligible cases, diagnosed up to May 2002, 656 did not participate for various reasons (such as not willing or not reachable), leading to a response of 83%. A further 3% responded only to the mini-questionnaire, taken by phone, which did not contain questions about travel. Of the remaining 3,111 cases, 78% had a partner, 77% of whom were willing to participate, which left 1,867 couples. Additionally, 229 partners were identified for whom the corresponding <span class="yellow">patient</span> originally participated but was later found not to be eligible (aged over 70 y, or not a first thrombotic event). These control individuals were matched on sex and 5-y age groups to one of the 557 <span class="yellow">patients</span> whose partner did not want to participate, so an extra 229 pairs were included, making a total of 4,192 <span class="yellow">participants</span> (2,096 pairs). As part of the general questionnaire, questions had been asked about whether or not respondents had traveled for more than 4 h in the 3 mo before the index date, about the travel date, and about mode and duration of travel. We assessed the occurrence of thrombosis in relation to the period of time that had passed since traveling. Travel was defined in the analysis as at least one journey with a duration of at least four uninterrupted hours during the 8-wk period before the event. During the analysis it appeared that some individuals had provided dates of travel after the event instead of before. As there was only one opportunity to fill in such a date, we had no information about the period before the event. This was the case in 88 cases and 146 controls. We excluded these individuals and their partners, which left 3,812 <span class="yellow">participants</span> (1,906 pairs) for the analysis.
Because we selected the partners of the cases as control individuals, and because it turned out, as expected, that couples tend to travel together, we performed a conditional logistic regression analysis to calculate odds ratios (ORs) for the relation between travel and venous thrombosis. This method fully takes this matching into account, and leads to unbiased estimates, with adjustment for all factors in which cases and controls tend to be similar, e.g., socioeconomic class [14]. Details of this method can be found in Protocol S1. The 95% confidence intervals (CIs) were derived from the model.
We assessed the combined effect of traveling and the following risk factors for thrombosis: factor V Leiden mutation, prothrombin G20210A mutation, body mass index (BMI, as kg/m2), and height. We were also interested in the combined effect of oral contraceptive use and travel. However, as the control individuals were nearly always of the opposite sex (partners of the cases were recruited as controls), it was not possible to perform a matched analysis for the combination of oral contraceptive use and travel. Therefore, we performed a case-only analysis [15]. This method allows one to examine the association between two exposures among case individuals only. ORs are interpreted as a synergy index (SI) on a multiplicative scale, with independence assumed between the exposures. As this analysis depends only on cases, it was possible to perform it in all consecutive cases, therefore also including those without a partner.<br><br>Laboratory Measurements
Blood was collected from the antecubital vein into vacuum tubes containing 0.106 mol/l trisodium citrate. High molecular weight DNA was isolated from leukocytes using a standard salting-out procedure [16] and stored at −20 °C. When a blood sample was not available, DNA was extracted from buccal swabs. Three large <span class="yellow">cotton</span> swabs in a total of 6 ml of SDS–proteinase K solution (100 mM NaCl, 10 mM EDTA, 10 mM Tris-HCl [pH 8.0], 0.5% SDS, 0.1 mg/ml proteinase K) were obtained. Upon arrival, the proteinase K concentration was raised to 0.2 mg/ml, and the sample was incubated for 2 h at 65 °C. Subsequently, the solute was recovered by centrifugation. Potassium acetate was added to the supernatant to a final concentration of 1.6 M. After 15 min incubation on ice, proteins were removed using chloroform/isomylalcohol (24:1) treatment. The DNA in the water phase was subsequently ethanol precipitated. After centrifugation, the pellet was resuspended in 200 μl of 10 mM Tris-HCl and 10 mM EDTA (pH 8.0), and frozen at −20 °C until further analysis. The factor V Leiden mutation (G1691A) and the prothrombin mutation (G20210A) were simultaneously detected by duplex polymerase chain reaction [17,18]. The technician was blinded concerning the origin of the sample, i.e., whether it was from a <span class="yellow">patient</span> or from a control individual.<br><br>
Results
Venous Thrombosis in Relation to Travel
Table 1 shows general characteristics of the 1,906 <span class="yellow">patients</span>. They ranged in age from 18 to 69 y (median 50.4 y); 51% were <span class="blue">men</span>. Diagnosis was DVT in 57% of the cases, PE in 32%, and both in 11%. As partners of the cases were included as control individuals, the sex distribution of the control individuals was the opposite; the age distribution differed only trivially.
Of the <span class="yellow">patients</span>, 233 individuals (12%) had traveled for at least 4 h by air, bus, car, or train within the 8 wk preceding the index date, as compared to 182 of the control individuals (9.5%). As the cases and control individuals were selected as couples, many pairs (135) had traveled together and were uninformative: as a consequence, 145 pairs in which either the <span class="yellow">patient</span> (98) or the control (47) had traveled could be used for the matched analysis (Table 2). This analysis showed a 2-fold increased risk of venous thrombosis for all modes of travel combined (OR 2.1; 95% CI 1.5–3.0) compared to not traveling. For air travel alone, 49 individuals (31 cases and 18 controls) had traveled without their partner, and the analysis yielded an OR of 1.7 (95% CI 1.0–3.1). For the other modes of travel (car, bus, and train) the relative risks were essentially similar to each other and to that of air travel (Table 2).
The risk of venous thrombosis was not clearly related to increased duration of travel (Table 2). Of the 233 events that occurred within 8 wk after traveling, 68 (29%) were diagnosed in the first week, after which the incidence gradually decreased (Figure 1).<br><br>The Effect of Other Risk Factors Combined with Travel
Prothrombotic mutations.
Information on the factor V Leiden mutation and prothrombin G20210A genotype was available for 1,713 <span class="yellow">patients</span> (90%) and for 1,629 of the control individuals (85%). Factor V Leiden was present in 259 cases (14%) and 84 control individuals (4%) (OR 3.1; 95% CI 2.4–4.1).
The risk of venous thrombosis was 8-fold increased in <span class="yellow">people</span> with factor V Leiden who had traveled by bus, car, or train (modes combined) as compared to noncarriers who did not travel (OR 8.1; 95% CI 2.7–24.7). For the combined effect of air travel and factor V Leiden, the risk seemed even slightly higher (OR 13.6; 95% CI 2.9–64.2).
The prothrombin G20210A mutation was found in 83 cases (4%) and in 29 control individuals (2%) (OR 2.7; 95% CI 1.7–4.2). The risk in individuals with this mutation who had traveled was difficult to interpret because of the small numbers but appeared not to increase more than additively (Table 3).<br><br>BMI.
The effect of BMI was studied by dividing individuals into three categories with the following BMI values: <25, 25–30, and >30 kg/m2 [19]. A BMI of 25–30 kg/m2 was associated with an increased risk of venous thrombosis (OR 1.4; 95% CI 1.2–1.7), and the risk was slightly higher in <span class="yellow">patients</span> with a BMI of 30 kg/m2 or more (OR 1.7; 95% CI 1.4–2.1).
The combined effect of a higher BMI and travel was the sum of the individual risks (Table 3), with the exception of <span class="yellow">people</span> with a BMI of more than 30 kg/m2 who traveled by car, bus, or train, for whom the risk was 10-fold increased (OR 9.9; 95% CI 3.6–27.6). This increase in risk was not found in <span class="yellow">people</span> who traveled by air.<br><br>Height.
Particularly short or tall <span class="yellow">people</span> may be subjected during travel to even more unnatural sitting positions than individuals with average height. Therefore, we assessed the effect of extremes of heights in combination with travel on the risk of venous thrombosis by comparing short (less than 1.60 m) and tall individuals (more than 1.90 m) with <span class="yellow">people</span> of average height (1.60–1.90 m). Compared to <span class="yellow">people</span> of average height, the risk of venous thrombosis was lower for short <span class="yellow">people</span> (OR 0.7; 95% CI 0.5–0.9) and did not differ for very tall individuals (OR 0.9; 95% CI 0.7–1.1). The risk was found to be increased in <span class="yellow">people</span> of more than 1.90 m who traveled (OR 4.7; 95% CI 1.4–15.4 for travel by car, bus, or train; OR 6.8; 95% CI 0.8–60.6 for air travel) compared to non-traveling <span class="yellow">people</span> of average height. Interestingly, the risk of venous thrombosis was also increased in short <span class="yellow">people</span> but only after air travel (OR 4.9; 95% CI 0.9–25.6), not after other modes of travel (OR 1.0; 95% CI 0.3–2.8, all relative to non-traveling <span class="yellow">people</span> of average height).<br><br>Oral contraception.
To study the association between oral contraceptive use, travel, and the risk of venous thrombosis, we performed a case-only analysis in all female <span class="yellow">patients</span> who were less than 50 y of age. As we needed only cases, it was also possible to include <span class="yellow">women</span> without a partner for this analysis, which led to a total of 1,025 <span class="yellow">women</span> aged under 50. Non-users who did not travel were used as the reference group. The case-only estimate of the SI for <span class="yellow">women</span> who traveled by car, bus, or train was 2.4 (95% CI 1.5–3.7). This indicates that the OR for the combination of travel and oral contraceptive use is 2.4 times the product of the separate ORs. As oral contraceptive use generally increases the risk of venous thrombosis about 4-fold [20], the combination with travel by car, bus, or train would lead to an estimated OR of about 20 (4 × 2 × 2.4). A clearly stronger interaction of travel by air with oral contraceptive use was found: the case-only estimate of the SI was 4.9 (95% CI 2.1– 11.4), which would result in an OR of about 40 (4 × 2 × 4.9).<br><br>
Effect of Risk Factors in DVT <span class="yellow">Patients</span> Only
Of the 1,906 cases, 1,082 were diagnosed with DVT. As the diagnosis was more unambiguous in these <span class="yellow">patients</span> (97% objectively diagnosed as compared to 78% of the PE <span class="yellow">patients</span>), we repeated the analysis in these <span class="yellow">patients</span> only.
In this analysis, the overall effect of travel on the risk of DVT was equal to the effect on all venous thrombosis (DVT and PE combined). However, here we found a stronger risk for travel by air (OR 3.0; 95% CI 1.3–7.1) then for travel by car, bus, or train (OR 1.9; 95% CI 1.1–3.2) (Table 4). Also, the analysis of the combination of other risk factors with travel resulted in more clear-cut effects, despite the smaller number of cases: the risk of DVT was still clearly synergistically increased in <span class="yellow">patients</span> with factor V Leiden who traveled, whereas the prothrombin G20210A mutation did not further increase the risk of travel (Table 4). Furthermore, a BMI of more than 30 kg/m2 in combination with travel yielded high ORs for DVT both in <span class="yellow">people</span> who traveled by car, bus, or train and in those who flew. Being more than 1.90 m tall in combination with travel resulted in higher ORs for DVT; the risk for short <span class="yellow">people</span> was more increased after travel by air (OR 6.8; 95% CI 1.1–43.5) (Table 4). The effect of oral contraceptive use in combination with travel by car, bus, or train on the risk of DVT was studied in 589 <span class="yellow">women</span> and was somewhat lower than the effect on the risk of all venous thrombosis (SI 1.9; 95% CI 0.9–4.2). In those who traveled by air it was also a bit lower (SI 3.4; 95% CI 1.3–8.8), but still indicative of a strong synergistic effect.<br><br>
Discussion
In this population-based case-control study, long-distance traveling increased the risk of venous thrombosis 2-fold. Travel by air increased the risk to the same extent as travel by car, bus, or train. The risk was highest in the first week after traveling. As venous thrombosis is a disease in which many factors (genetic and acquired) interact [21], we identified groups with additional risk factors in which the risk was further increased. This was the case for individuals with factor V Leiden, obese <span class="yellow">people</span> (BMI > 30 kg/m2), and short (only for travel by air) and tall <span class="yellow">people</span>, as well as for <span class="yellow">women</span> using oral contraceptives. Some of these synergistic effects were more apparent for air travel.
Although the studies that have been published so far have not yielded entirely consistent results, those that did report an increased risk of venous thrombosis in air travelers showed similar risk estimates of a 2- to 3-fold increased risk (even in one with asymptomatic events only [4]). The occurrence of venous thrombosis was highest in the first week after travel, and slowly declined afterwards, a pattern that was also described in a recent record-linking study from Australia [1], supporting a causal relation.
As a possible mechanism for an extra risk in travelers who <span class="yellow">fly</span>, an effect of hypobaric hypoxia on the coagulation system was postulated, which has already been studied a number of times, mainly in hypobaric chambers, with unclear results so far. Our study showed an increased risk in all types of travel, which suggests that the increased risk of flying is caused mainly by immobilization. Additionally, the risk is further increased in short and tall <span class="yellow">people</span>, who are likely to experience more immobilization and venous compression than other travelers. However, as some of our findings were more pronounced for air travel, we cannot exclude an additional effect of hypobaric hypoxia, possibly in risk groups only. This possibility is supported by a recent study of our group [22] in which we found that thrombin generation occurred in some healthy volunteers after flying for 8 h but happened to a far lesser extent after being immobilized for 8 h in a cinema. The high response in the fliers was associated with the presence of risk factors for thrombosis, i.e., oral contraceptive use, the factor V Leiden mutation, and the combination of the two. This finding indicates an effect of an additional factor in an airplane, such as hypobaric hypoxia, to which mainly individuals with risk factors respond.
None of the studies published so far have systematically studied the effect of traveling in combination with other risk factors, with the exception of the study by Martinelli et al. [3]. In an analysis of 210 <span class="yellow">patients</span>, they found a 16-fold increased risk for <span class="yellow">patients</span> who traveled by air and had some form of thrombophilia, as well as a 14-fold increased risk in <span class="yellow">women</span> who flew and used oral contraceptives, findings that confirm both the results of the present study and our finding of activated coagulation in individuals with risk factors after flying [22].
The finding that taller and shorter <span class="yellow">people</span> had an increased risk of venous thrombosis after traveling should be interpreted with some caution, as the numbers were small in these strata. On the other hand, it is biologically plausible: very tall <span class="yellow">people</span> are subjected to even more cramped seating than average-height individuals, and very short <span class="yellow">people</span>'s feet may not touch the floor, which would lead to extra compression of the popliteal veins. Interestingly, the increased risk for short <span class="yellow">people</span> was only found in <span class="yellow">people</span> who traveled by air. This may have to do with the fact that seats in cars are generally lower, and more individually adjustable, than those in airplanes.
As the diagnosis of DVT is usually more unambiguous than that of PE [23], as was the case in our study population as well, we repeated the analysis using only DVT as the outcome of interest (97% objectively diagnosed). In this analysis, despite using smaller numbers, most findings were either similar or appeared more evident, and inconsistencies that were found when using both DVT and PE as endpoints disappeared.
To our knowledge, this is the first large population-based case-control study in which the effect of travel on the risk of venous thrombosis has been studied. Because the control individuals were closely matched, being partners of the cases, and couples tend to travel together, only the cases and control individuals who had not traveled together could be used for the analysis. Also because of this design, the effect of sex and age could not be studied. It has to be noted, however, that for all other research questions on the effect of genetic and acquired risk factors on the risk of venous thrombosis, this design has no limitations and the close matching of cases and controls renders confounding by, for instance, lifestyle and socioeconomic class less likely than in previous unmatched studies (see also Protocol S1). Another advantage of this approach is the minimization of recall bias, as the cases and controls would generally fill in the questionnaire together.
Many questions are still left unanswered that necessitate more research. First of all, our study results apply only to <span class="yellow">people</span> younger than 70 y of age. Furthermore, it is likely that other characteristics exist that also increase the risk—<span class="yellow">person</span>-specific (e.g., other drug use), behavioral (e.g., use of sleeping pills or alcohol consumption), and flight-specific (e.g., class or seating)—that need to be identified. These further variables are part of our ongoing study as part of the World Health Organization Research Initiative into the Global Hazards of Travel (WRIGHT study). For those who have an increased risk, such as oral contraceptive users and individuals with factor V Leiden, prevention may be warranted. Prevention may vary from simple measures, such as exercises during the flight, to measures that carry a risk themselves, such as anticoagulants. Specific studies are needed to assess the efficacy of these measures and their risk–benefit ratio.
It can be concluded that the risk of venous thrombosis is 2-fold increased for all travelers and to the same extent for all modes of travel. In individuals who use oral contraceptives, are carriers of the factor V Leiden mutation, or are particularly tall, short, or obese, this risk is considerably higher, to such an extent that studies into the efficacy of prophylactic measures are required.<br><br>Supporting Information<br><br>
<h3>pmcA1859974</h3><span class="yellow">Human</span> growth hormone (GH1) gene polymorphism map in a normal-statured adult population
Abstract
Objective
GH1 gene presents a complex map of single nucleotide polymorphisms (SNPs) in the entire promoter, coding and noncoding regions. The aim of the study was to establish the complete map of GH1 gene SNPs in our control normal population and to analyse its association with adult height.<br><br>Design, subjects and measurements
A systematic GH1 gene analysis was designed in a control population of 307 adults of both sexes with height normally distributed within normal range for the same population: −2 standard deviation scores (SDS) to +2 SDS. An analysis was performed on individual and combined genotype associations with adult height.<br><br>Results
Twenty-five SNPs presented a frequency over 1%: 11 in the promoter (P1 to P11), three in the 5′UTR region (P12 to P14), one in exon 1 (P15), three in intron 1 (P16 to P18), two in intron 2 (P19 and P20), two in exon 4 (P21 and P22) and three in intron 4 (P23 to P25). Twenty-nine additional changes with frequencies under 1% were found in 29 subjects. P8, P19, P20 and P25 had not been previously described. P6, P12, P17 and P25 accounted for 6·2% of the variation in adult height (P = 0·0007) in this population with genotypes A/G at P6, G/G at P6 and A/G at P12 decreasing height SDS (−0·063 ± 0·031, −0·693 ± 0·350 and −0·489 ± 0·265, Mean ± SE) and genotypes A/T at P17 and T/G at P25 increasing height SDS (+1·094 ± 0·456 and +1·184 ± 0·432).<br><br>Conclusions
This study established the GH1 gene sequence variation map in a normal adult height control population confirming the high density of SNPs in a relatively small gene. Our study shows that the more frequent SNPs did not significantly contribute to height determination, while only one promoter and two intronic SNPs contributed significantly to it. Studies in larger populations will have to confirm the associations and in vitro functional studies will elucidate the mechanisms involved. Systematic GH1 gene analysis in <span class="yellow">patients</span> with growth delay and suspected GH deficiency/insufficiency will clarify whether different SNP frequencies and/or the presence of different sequence changes may be associated with phenotypes in them.<br><br><br><br>Introduction
<span class="yellow">Human</span> skeletal growth and final height attainment are a result of a multifactorial regulation involving systemic and local hormones, growth and nutritional factors, lifestyle and genetic factors. Heritability estimates1 and genome-wide linkage analysis2 have shown that genetic factors play a major role in determining stature. Among these factors, the GH-IGF-I axis plays an important role during postnatal life, and associations between structural variations in its genes and height are currently under study.3 Although growth hormone (GH) deficiency is a well-known cause of growth retardation, which responds to GH replacement therapy, the diagnosis and physiopathological mechanisms for the so-called ‘idiopathic isolated GH deficiency’ (IIGHD) require further clarification. In addition, GH secretion levels and markers of GH biological activity have been demonstrated to be specific and sensitive only in major deficiency states.4,5 Genetic causes of GH deficiency within the GH1 gene have been established; however, they are rarely recognized and only sought in major GH deficiency states during childhood and in family studies.3 GH1 gene, located at 17q22–24, is a component of the GH gene cluster in which five genes evolving from a common ancestor are 91–99% sequence conserved (paralogues).6 GH1 is more abundantly expressed in pituitary cells, while the other four genes are expressed in placental tissue. Large deletions within the GH1 gene cluster were described first followed by point mutations, the majority of which affect introns 3 or 4, provoke skipping of exon 3 product and exert a dominant effect.3,7,8 More recently, the presence of single nucleotide polymorphic points (SNPs) in the promoter region or in intron 4 of the GH1 gene have been described9–12 and associations with promoter allele activities or with GH secretion efficacy and circulating IGF-I levels in growth-retarded <span class="yellow">patients</span> have also been described.11,12 Other studies have analysed several GH1 gene SNP genotypes as related to the incidence of neoplasia, with a positive association with colorectal neoplasia for intron 4 SNP,13 a negative result for breast carcinoma14,15 or a positive one for breast cancer risk.16,17 In addition, a recent study in a cohort of adults over ages 60 years detected a significant association between genotypes at one SNP in the GH1 gene promoter region and at the intron 4 SNP described by Hasegawa et al.11 with baseline bone density and accelerated bone loss together with an interaction with weight at 1 year.18 Intron 4 SNP described by Hasegawa et al.11 has also been associated, in <span class="yellow">women</span>, with shorter body height and reduced mortality,19 whereas another intron 4 SNP (T1169A) has been associated in both sexes with a favourable metabolic profile.20 A systematic SNP study was conducted by Adkins et al.21 in GH1 promoter, coding and noncoding regions in DNAs from placental tissues, and analysis of associations between genotypes and birth weight revealed an association between an alternate nucleotide at −1 and +3 of translation initiation site and fetal growth restriction. However, no systematic GH1 gene analysis in the entire promoter, coding and noncoding regions has been conducted in adults to establish the map of structural variation and its possible association with height. The relatively short size of the entire gene permits a complete analysis which is, nevertheless, hampered by the need to avoid amplification of any other of the GH cluster genes (paralogues) and the high density of sequence variations.
To obtain normative data for subsequent analysis of GH1 gene contribution to IIGHD in <span class="yellow">children</span>, a systematic GH1 gene structural analysis was designed in a normal adult control population to establish the GH1 gene SNP map in adults from our population with heights within the normal range, determine the genotype frequencies and analyse possible associations between individual and combined SNPs with height.<br><br>Subjects and methods
Subjects
A total of 307 adult subjects of both sexes (164 <span class="yellow">women</span> and 143 <span class="blue">men</span>) were recruited from hospital personnel and parents of <span class="yellow">patients</span> with no history of growth retardation. Subjects had to fulfil the following criteria: Iberian Peninsular (except Basque) family origin and no family history of pathological short stature. A single subject per family was included. The protocol was approved by the Hospital Vall d’Hebron Ethics Committee and written informed consent was obtained from each <span class="yellow">participant</span>. Height standard deviation scores (height SDS) were calculated according to sex-specific reference growth charts for the Spanish population (Carrascosa et al.22 charts were used for subjects under ages 30 years and Hernández et al.23 for subjects aged 30–50 years). Only individuals with height SDS between −2 and +2 SDS were included in the study (mean −0·016; 32 <span class="yellow">women</span> and 28 <span class="blue">men</span> between −2·000 and −1·010; 99 <span class="yellow">women</span> and 80 <span class="blue">men</span> between −1·000 and +0·910; 33 <span class="yellow">women</span> and 35 <span class="blue">men</span> between +1·010 and +1·980) and sample size was adjusted for normal sex and height SDS distribution. Height and weight were recorded in the morning by a single observer. Height was measured with a Harpenden stadiometer. Four millilitres of peripheral venous blood were drawn into EDTA-containing tubes for molecular genetic analysis.<br><br>Genomic DNA study
Genomic DNA was obtained from peripheral blood following the method described by Lahiri and Nurnberger.24 DNA was amplified by polymerase chain reaction (PCR) using a nested strategy. Briefly, 50 ng of genomic DNA were added to a 10 µl reaction mixture of 1 mm Mg(OAc)2, 0·6 mm dNTPs, 0·3 µm of each primer, and 0·4 U r Tth DNA polymerase XL (Applied Biosystems, Foster City, CA, USA). The sense and antisense primers used corresponded to nucleotides 4156–5′ACGGTCCGCCACTACGCCCAGC-3′ and the complement of 6948–5′TGCAGTGAGCCAAGATTGTGCC-3′ of the GH gene cluster.6 The PCR reaction mix was denatured for 5 min at 94 °C and cycled 40 times (94 °C, 1 min; 72 °C, 3 min 30 s) followed by a 7-min extension at 72 °C. The resulting GH1 PCR products (2893 bp) were used as templates for five nested reactions (AN, BL, CK, DI, FP), carried out as follows: 1 µl of each GH1 PCR product was added to a 20 µl reaction mixture of 1·5 mm MgCl2, 0·2 mm dNTPs, 0·3 µm of each primer and 0·4 U Eco Taq DNA polymerase (Ecogen S.R.L., Barcelona, Spain). Reaction mixtures were denatured for 5 min at 94 °C, cycled 40 times (94 °C, 1 min; 58 °C, 1 min; and 72 °C, 1 min), followed by a 7-min extension at 72 °C. Sense and antisense primers were as follows:
Sequencing from both ends was performed by the dideoxy method using ABI PRISM BigDye Terminator version 3·1 Cycle Sequencing Kit (Applied Biosystems, Foster City, CA, USA). GH1 gene nucleotide sequence published by Chen et al.6 was used as control. For each DNA, the five segments from the nested PCR were assembled with the SeqEscape programme (Applied Biosystems) and interpretation was made visually and simultaneously by two observers. Antisense sequencing was performed to confirm each nucleotide sequence change up to the establishment of the more frequent SNP map (frequency over 1%), whereas less frequent single or multiple nucleotide changes were reconfirmed in each DNA by antisense sequence and resequencing after a new nested PCR from original DNA was performed.<br><br>Single nucleotide polymorphism (SNP) genotyping
The sequences for the five genes of the GH cluster identified by Chen et al.6 and reported as the GI sequence 183148 were aligned using the Multalin program.25 SNPs and other sequence changes identified were indicated using their position corresponding to GH1. Genotypes were deduced by the combination of genetic variation at the polymorphic positions.<br><br>Statistical analysis
Standardized height was investigated for normal distribution (Kolmogorov-Smirnov test: c2 = 2·882, P = 0·4733). Hardy–Weinberg equilibrium was tested for SNPs presenting three alternate genotypes according to standard procedures using χ2-analysis. anova test was applied to investigate individual and combined SNP association with adult height SDS; significance assessment was adjusted for multiple testing using Fisher's PLSD test setting Pcritical = 0·05 or the Bonferroni–Dunn test setting Pcritical = 0·05/n (n = number of comparisons carried out). Stepwise regression analysis was applied to predict the contribution of SNPs to adult height SDS. Statview 4·5 program (Abacus Concepts Inc., Berkeley, CA, USA) was used for statistical analyses.<br><br>
Results
GH1 gene sequence variation
GH1 gene sequence comparison with the GI-183148 sequence published by Chen et al.6 yielded a total of 54 single or multiple nucleotide changes. Twenty-five SNPs presented a frequency over 1% (genotypes and frequencies are listed in Table 1). SNPs which presented the three alternate genotypes (P2 to P4, P6, P7, P10 and P24) were in Hardy–Weinberg equilibrium (data not shown). Twenty-nine additional changes were found with a frequency under 1% or involving more than one nucleotide and thus could be considered as rare variant SNPs (R1 to R29) (Table 2). These changes were found in 29 of 307 subjects (9·4%), all in heterozygosity.<br><br>GH1-paralogue alignment
A sequence alignment was performed to study possible sequence recombinations among paralogues of the five GH1-gene cluster (Fig. 1). This alignment showed that 9 of 25 SNPs (36%) in the GH1 gene did not correspond to any of the paralogues.
Among the 29 rare SNPs found, six (20·7%) did not correspond to any of the paralogues: two were located in the 5′UTR region (R9 and R10), two in intron 1 (positions 5300 = R14 and 5302 = R17), one in intron 2 (position 5679 = R21) and one in intron 4 (position 6344 = R23) (Table 2).<br><br>Equivalence with previously reported GH1 changes
Equivalence with changes and SNPs previously reported by other authors are shown in Table 3. The majority found a high density of SNPs in the promoter and 5′UTR regions in control populations.10,12,21 Several sequence changes have been reported in <span class="yellow">patients</span> with familial or idiopathic short stature,11,26,27 whereas P8, P19, P20 and P25 (at positions 5165, 5681, 5686 and 6358, respectively, in the Genebank accession GI 183148) located in the promoter, intron 2 and intron 4 regions, respectively, had not been previously described.<br><br>GH1 genotypes and associations with height SDS
Associations between genotypes and standardized height were first studied in the subpopulation of 278 controls carrying only the 25 most frequent SNPs in the GH1 gene (c2 = 2·59; P = 0·5458 for normality of height distribution).
Three individual SNPs showed a statistically significant association with height SDS: at positions 5286 (P16), 5290 (P17) and 6358 (P25). Subjects with heterozygous genotypes presented statistically significant taller stature than the corresponding homozygous genotypes (P = 0·016 for P16, P = 0·015 for P17 and P = 0·023 for P25) (Fig. 2a,b,c). P16 and P17 were in linkage disequilibrium (LD) (r2 = 0·831), while P25 was carried by six subjects homozygous at P16 and P17.
GH1 gene genotypes were defined by genetic variation in the 25 polymorphic positions. We found 163 different combinations. Only two genotypes presented a frequency over 5% (Table 4). Height SDS in the two more frequent genotypes did not differ significantly and covered the whole height range. Genotype 1 presented four heterozygous variations and Genotype 2 was the corresponding homozygous genotype. Heterozygous positions corresponded to SNPs with the highest frequency variation (4886 (P4), 5107 (P7), 5157 (P10) and 6331 (P24)). In addition, DNAs exhibited a different genotype in each of 129 subjects (46·4%).
The 11 SNPs found in the promoter region (Table 1) were grouped in 94 genotypes and analysed for association with adult height SDS. The four more frequent combinations are listed in Table 4: height SDS of these four genotypes did not differ statistically although Genotype 3 tended to have a shorter height. Genotype 3 differed from Genotype 1 in the SNP located at position 5089 (P6), corresponding to Pit 1 proximal responsive element for GH1 gene promoter. Genotype 4 is heterozygous at positions 4856 (P2), 4863 (P3) and 5107 (P7). In addition, 19% of cases exhibited a genotype in the promoter region carried by only one subject.
Combination of the three SNPs in the 5′UTR region of GH1 gene resulted in five different genotypes. SNPs at positions 5178 (P12) and 5187 (P13) were in LD (r2 = 0·88). Mean height SDS comparison among these genotypes was not statistically significant, although mean height SDS of alternate nucleotide carriers at position 5178 (P12) tended to be shorter (Table 4).
An anova analysis was conducted to investigate the interaction between two or more SNPs and height SDS. SNPs at positions 5286 (P16) and 5290 (P17) were in LD (r2 = 0·83): the heterozygous genotype AG/AT for these SNPs was associated with taller stature (shown above). SNP at position 6358 (P25) increased the expected height SDS for individual carriers of the G allele at 5089 (P6) SNP as shown in Fig. 2(d): subjects heterozygous at 6358 (P25) were taller than the mean, and mean height SDS of subjects with GG/TG combined genotype was significantly higher than the corresponding GG/TT genotype (P = 0·0021), suggesting an interaction between these two SNPs as they were not in LD.
Analysis of height SDS association with the most frequent single and combined SNPs and with rare variant SNPs was performed in the 29 individuals carrying the rare SNPs (Table 2). None of them carried any of the three SNPs (P16, P17 and P25) related to taller stature in the population of 278 controls with only the frequent SNPs. In these 29, mean height SDS (0·000 ± 0·987, from −1·930 to +1·870) did not differ from that of the 278 controls (−0·018 ± 1·041, from −2·000 to +1·980). Analysis of associations between individual SNP genotypes and height SDS revealed that SNPs at positions 5089 (P6), 5178 (P12) and 5187 (P13) were associated with significantly shorter stature (Fig. 2e). Only two sequence changes considered as rare SNPs were carried by individuals in the lower normal height range (between −1·500 and −2·000 SDS) (Table 2): R4 (4979 C > T) in the promoter region and R14 (5300 C > T) in intron 1. Predicted single amino acid changes located in exon 5 (R25 to R27) were not associated with short stature.
In the entire population of 307 controls, stepwise regression analysis between height SDS and genotypes at the 25 SNPs showed that genotypes at 5089 (P6), 5178 (P12), 5290 (P17) and 6358 (P25) were significantly correlated with height SDS (r2 = 0·062, P = 0·0007) with genotypes A/G at P6, G/G at P6 and A/G at P12 decreasing height SDS (−0·063 ± 0·031, −0·693 ± 0·350 and −0·489 ± 0·265, respectively, Mean ± SE) and genotypes A/T at P17 and T/G at P25 increasing height SDS (+ 1·094 ± 0·456 and +1·184 ± 0·432, respectively).<br><br>
Discussion
Genetic variations within <span class="yellow">human</span> GH1 gene have been described by several authors.9–12,21 The populations described to date comprised small numbers of normal-stature individuals,9 male adults with narrow height range12 or growth-retarded <span class="yellow">patients</span> with/without GHD before achievement of adult height.9,11,12 Our study was designed to characterize the GH1 gene sequence variation in individuals within the whole range of normal adult height (between −2 and +2 SDS) according to the standards for our population. Height was normally distributed, both sexes were equally represented and the GI-183148 homozygous sequence6 was used for comparison. A nested PCR with specific primers for GH1 gene was designed, thus avoiding amplification of any other GH gene paralogue of the GH gene cluster.
Our results establish a map of 25 SNPs as present in over 1% of individuals, whereas 29 other sequence changes (single or multiple nucleotide) are present in less than 1% of subjects. More than 50% (n = 14) of SNPs are located in the promoter and 5′UTR regions, thus confirming previous reports: Giordano et al.9 reported eight SNPs in the promoter and 5′UTR regions, Wagner et al.10 16 SNPs from the promoter to intron 1 and Horan et al.12 identified 36 haplotypes in control subjects of the British population, which would result from the combination of 15 of the previously reported SNPs. Our results confirm the presence of 13 of those points; SNP at 5165 (R11 in the present study and +3 in references9,12) was present in less than 1% of subjects and a new SNP is described (P8 at 5116 in the VDR/RA/T3 responsive element sequence). The remaining SNPs (from P15 to P25, n = 11) are distributed in introns 1, 2 and 4, and among coding regions only exon 1 and exon 4 bear a total of three SNPs, two of which predict an amino acid change (P15 and P21). These two latter SNPs had been described by Millar et al.26 and the more frequent SNP in intron 4 (P24) has been described by Hasegawa et al.11 together with the two more frequent SNPs in the promoter region (P4 and P7 in our map). Three new SNPs are described (P19 and P20 in intron 2 and P25 in intron 4), all outside the splice sites. Only SNPs presenting high frequency are present in homozygous alternate state and this accounts mostly for the majority of the promoter and 5′UTR SNPs and in the intron 4 more frequent SNP (P24) described by Hasegawa et al.11 In conclusion, in the entire coding and noncoding GH1 gene sequence, only P24 is present in homozygous alternate state. Our results show that the GI 183148 homozygous sequence is present in our population except for SNP P14 in the 5′UTR region which is only present as the alternate nucleotide in homozygous or heterozygous states.
As described by several authors9,10,12,21 several promoter SNPs affected functional sequences and P6 is located in the Pit 1 proximal responsive element, P7 and P8 in the VDR/RA/T3 responsive element and P9 (G del) in the TATA box.
The mechanisms by which the high density of SNPs in the GH1 gene is generated has been proposed to be recombination and gene conversion with any other(s) of the GH cluster genes.9,12,28 Alignment of the 25 SNPs with the other GH1 gene paralogues demonstrated in our results that this mechanism is possible for 64% of SNPs. Familial SNP transmission pattern analysis will be of interest to support the hypothesis of GH gene recombination.
In addition, 29 of 307 individuals (9·4%) bore additional GH1 sequence changes with frequencies under 1%. As for SNPs, they are located along the whole gene with higher density in the promoter and 5′UTR regions. Interestingly, intron 3 and exon 5 present several of these less frequent changes. Intron 3 has been shown to carry the majority of single nucleotide mutations causing the dominant form of GH deficiency.3 The two single nucleotide changes detected in intron 3 (R15 at 6056 and R16 at 6061) are in perfect LD (r2 = 1·0) and located within the enhancer splice site element (ESE) described by Ryther et al.29,30 Studies in additional normal or growth-retarded populations will permit description of their possible clinical implications. Five single nucleotide changes are located in exon 5; of these five, three predict an amino acid change, and one of the three (Ile179Met) has been described by Lewis et al.27 in a paediatric <span class="yellow">patient</span> with familial short stature and the other two, as yet undescribed, are contiguous in a single individual (Pro133Hys and Arg134Leu). Polynucleotide changes are mostly located in the promoter region corresponding to the VDR/RA/T3 response element. As for frequent SNPs, the majority of the sequence changes with frequencies under 1% may have been generated by recombination within the GH gene cluster as 19 of 24 (79%) may correspond to one or more of the GH1 gene paralogues.
Our results now show the diversity and complexity of SNP genotypes, as previously highlighted by other authors9,10,12,21 in a normal adult height control population. Our initial aim when designing the present study was to establish the map of GH1 gene SNPs in our adult control population with heights normally distributed within the entire normal range for further comparison with genotypes in our paediatric population with growth delay, variable response to GH secretion tests and adequate response to GH therapy. Analysis of SNP association with adult height was subsequently performed to establish a body of knowledge useful for comparing <span class="yellow">patient</span> genotypes and phenotypes. This analysis was first performed in controls bearing only frequent SNPs (90·5% of the total population). We demonstrate that the four SNPs with the highest allelic variation frequencies (P4, P7, P10 and P24) do not significantly contribute to adult height determination, with the heterozygous genotype being the most frequent followed by the corresponding homozygous genotype in the whole sequence, and heights are normally distributed over the entire height range. The third most frequent combined genotype in the promoter region in our population presented, in addition, in heterozygosity, the SNP at P6 in the sequence regulated by Pit 1 and although mean height of individuals (6·1%) bearing this genotype was around −0·5 SDS, this was not statistically significant.
Analysis of single SNP genotype association with adult height yielded few clues as to the contribution of GH1 gene variation to adult height determination. Only three SNPs (P16, P17 and P25), present with low frequency and only in heterozygous state, were individually significantly associated with taller stature and none was individually associated with shorter stature. P16 and P17 (in LD, r2 = 0·83) are located in intron 1 and P25 in intron 4. The resulting sequence for the presence of P16 and P17 corresponded to the paralogue GH2 and generated a responsive element for a core-binding protein (Matinspector Programme, Geometrix Software GmbH, München, Germany) with three Kruppel-type zinc fingers which could increase the efficacy of GH1 gene transcription;31,32 moreover, Kruppel-like proteins have recently been described in the brain.33 Stepwise regression analysis demonstrated that P17 and P25 contribute, separately, to an increase of almost 1·0 height SDS. P16 and P17 had been described by Adkins et al.21 although they found no association with fetal growth, whereas P25 had not previously been described. The mechanisms by which they may determine taller final height should be established by in vitro studies analysing GH1 gene transcription and GH protein translation efficiencies.
Analysis of interaction effect between SNPs detected that variation at P25 masked an effect of P6. Individuals homozygous at P25 (TT) present a significant association between P6 genotype and height with the homozygous alternate genotype at P6 (GG) being associated with shorter stature. This was further confirmed in the subpopulation of 29 individuals bearing rare SNPs who, in the absence of heterozygous change at P25, presented significantly shorter stature in the heterozygous alternate nucleotide change at P6 (AG). P6, located at Pit 1 proximal responsive element of the GH1 gene promoter, was first described by Wagner et al.10 and Giordano et al.9 and further by Horan et al.12 Six of nine GH1 gene promoter haplotypes bearing the alternate G at P6 presented lower transcriptional activities and electrophoretic mobility shift assays (EMSA) detected differential protein binding strength, although in vitro studies were unable to identify this SNP as a major determinant of GH1 gene expression level.12 A recent study from Giordano et al.34 has shown a twofold reduced luciferase activity for the G nucleotide bearing promoter haplotype in transfected <span class="yellow">rat</span> pituitary cells. Genotypes at P6 had also been associated with decreased breast cancer risk through its association with lower GH secretion and IGF-I circulating levels.16,17
In our results, GH1 gene polymorphic structural variation accounted for only 6·2% of adult height determination in the entire adult population studied and genome-wide linkage analysis of stature in multiple populations revealed no linkage with chromosome 17 GH gene cluster.2,35 As only some of the less frequent SNPs are statistically associated with height, and in view of the high density of SNPs, our study may be hampered by selection bias36 and would ideally have required a wider sampling of some 2 000 individuals; however, this was a highly laborious strategy when the complete sequencing technique is applied. The high density of SNPs and their proximity hamper other genotyping strategies for rapid determination of the complete GH1 SNP map in large control and <span class="yellow">patient</span> populations. Individual SNP associations with height or other GH secretion-related phenotypic traits will require further confirmation by studies in larger populations and by in vitro functional studies.
In conclusion, our study established the GH1 gene sequence variation map in an adult control population with heights normally distributed within the normal range. SNPs and other sequence change contributions to skeletal growth as observed at adult height demonstrated that, despite the high frequency of variation and diversity and complexity of combinations, only some of the less frequent SNPs were associated with taller stature (P17 in intron 1 and P25 in intron 4), even masking the SNP contribution to a shorter one (P6 in the promoter and P12 in the 5′UTR regions, respectively). Systematic GH1 gene analysis in <span class="yellow">patients</span> with growth delay and suspected GH deficiency/insufficiency will clarify whether different SNP frequencies and/or the presence of different sequence changes may be associated with phenotypes in them.<br><br>
<h3>pmcA2065882</h3>Identification of Two Independent Risk Factors for Lupus within the MHC in United Kingdom Families
Abstract
The association of the major histocompatibility complex (MHC) with SLE is well established yet the causal variants arising from this region remain to be identified, largely due to inadequate study design and the strong linkage disequilibrium demonstrated by genes across this locus. The majority of studies thus far have identified strong association with classical class II alleles, in particular HLA-DRB1*0301 and HLA-DRB1*1501. Additional associations have been reported with class III alleles; specifically, complement C4 null alleles and a tumor necrosis factor promoter SNP (TNF-308G/A). However, the relative effects of these class II and class III variants have not been determined. We have thus used a family-based approach to map association signals across the MHC class II and class III regions in a cohort of 314 complete United Kingdom Caucasian SLE trios by typing tagging SNPs together with classical typing of the HLA-DRB1 locus. Using TDT and conditional regression analyses, we have demonstrated the presence of two distinct and independent association signals in SLE: HLA-DRB1*0301 (nominal p = 4.9 × 10−8, permuted p < 0.0001, OR = 2.3) and the T allele of SNP rs419788 (nominal p = 4.3 × 10−8, permuted p < 0.0001, OR = 2.0) in intron 6 of the class III region gene SKIV2L. Assessment of genotypic risk demonstrates a likely dominant model of inheritance for HLA-DRB1*0301, while rs419788-T confers susceptibility in an additive manner. Furthermore, by comparing transmitted and untransmitted parental chromosomes, we have delimited our class II signal to a 180 kb region encompassing the alleles HLA-DRB1*0301-HLA-DQA1*0501-HLA-DQB1*0201 alone. Our class III signal importantly excludes independent association at the TNF promoter polymorphism, TNF-308G/A, in our SLE cohort and provides a potentially novel locus for future genetic and functional studies.
Systemic lupus erythematosus (SLE/lupus) is a complex autoimmune disease in which the body's immune system attacks its own tissues, causing inflammation in a variety of different organs such as the skin, joints, and kidneys. The cause of lupus is not known, but genes play a significant role in the predisposition to disease. The major histocompatibility complex (MHC) on Chromosome 6 contains at least 100 different genes that affect the immune system, including the genes with the strongest effect on lupus susceptibility. Despite the importance of the MHC in SLE, the identity of the actual genes in the MHC region that cause SLE has remained elusive. In the present study, we used the latest set of genetic markers present at the MHC in lupus families to identify the actual genes that affect the disease. To our knowledge, we have shown for the first time that two separate groups of genes are involved in SLE. One group of genes alters how the immune system may inappropriately target its own tissues in the disease. How the second set of genes predisposes to SLE is the subject of ongoing study.<br><br><br><br>Introduction
Since the early 1970s, the <span class="yellow">human</span> major histocompatibility complex (MHC) has been shown to be associated with a number of autoimmune, inflammatory, and infectious diseases, and it continues to be the focus of intense research [1]. The recently defined extended MHC (xMHC) encompasses 7.6 Mb of genome on 6p21.3 and is divided into five subregions from telomere to centromere: extended class I, classical class I, classical class III, classical class II, and extended class II. In addition, the MHC contains two hypervariable regions, the RCCX module in class III (spanning complement C4) and the HLA-DRB genes in class II, that both exhibit copy number polymorphism. Examination of the sequence across the extended MHC reveals the presence of 421 genes, and over 252 (60%) are thought to be expressed [2]. Around 40% of genes expressed within the classical MHC encode proteins with putative immunomodulatory function [3]. The classical class I and class II loci encode the <span class="yellow">human</span> leucocyte antigen (HLA) proteins involved in antigen presentation to T cells, initiating the adaptive immune response. The class III region contains the greatest density of genes in the genome (58 expressed genes), which are often found in functionally related clusters [2].
A major obstacle in the identification of disease-specific causal variants within the MHC has been the strong linkage disequilibrium (LD) exhibited by certain alleles in this region, resulting in the existence of long-range, conserved, extended haplotypes [4], also known as ancestral haplotypes [5], sometimes spanning more than 2 Mb [6]. Thus, for many MHC-associated diseases, it has only been possible to delimit association signals to a particular extended haplotype or segment of one.
Systemic lupus erythematosus (SLE/lupus, [Online Mendelian Inheritance in <span class="yellow">Man</span> 152700, http://www.ncbi.nlm.nih.gov/sites/entrez?db=OMIM&TabCmd=Limits]) is a chronic, multi-system autoimmune disease affecting young <span class="yellow">women</span> ten times more commonly than <span class="blue">men</span>. The worldwide prevalence of SLE is estimated at between 12 and 124 cases per 100,000 individuals [7]. SLE is characterized by the presence of pathogenic autoantibodies to nuclear and cell-surface antigens that show affinity maturation. The consequent immune complexes deposit in tissues, causing inflammation and damage. It is well established that there is a complex genetic component to lupus aetiology, with hormonal and environmental influences also contributing to disease susceptibility [8,9].
The MHC has been the most consistently confirmed genetic risk factor for SLE, and multiple different genes within the region have been significantly implicated with disease susceptibility. For example, hereditary and acquired deficiencies of the early classical complement component C4, located within the MHC class III locus, leads to a lupus-like syndrome. A role for another class III gene, tumour necrosis factor alpha (TNF), in SLE was suggested following the observation that the lupus-prone New Zealand F1 <span class="yellow">mouse</span> hybrid exhibits constitutively low TNF expression [10]. Recently, the development of antinuclear antibodies in <span class="yellow">patients</span> treated with TNF antagonists has also stimulated interest in the possible role of TNF in SLE [11–13]. <span class="yellow">Murine</span> and <span class="yellow">human</span> candidate gene studies, together with genome-wide linkage screens, provide further support that multiple genetic loci, including the <span class="yellow">mouse</span> MHC complex H2 and the <span class="yellow">human</span> MHC locus, contribute to disease susceptibility [14–17].
It should be noted that the <span class="yellow">human</span> MHC was first associated with SLE in 1971, when studies demonstrated that lupus probands were enriched for the class I alleles HL-A8 (now known as HLA-B8) and HLA-W15 (now known as HLA-B15) when compared with healthy controls [18,19]. Further case control association studies were small, performed in ethnically diverse populations, and tested only a small number of the classical HLA and complement C4 alleles. The most consistent findings reported to date are associations with the class II alleles HLA-DR2 (DRB1*1501) and HLA-DR3 (DRB1*0301) and their respective haplotypes in Caucasian populations. The complement C4A null allele (C4A*Q0) has shown inconsistent association with lupus in a number of studies—a situation that may reflect genetic heterogeneity in disease susceptibility [20–23]. In addition, a recent study has demonstrated that low C4A copy number is a risk factor for lupus in a European American cohort [24]. However, the C4A null allele lies on the lupus-associated DR3 “autoimmune” extended haplotype (AH8.1), which exhibits extremely strong LD [6]. It therefore remains to be definitively established whether this locus constitutes a distinct susceptibility allele to that of the class II association or is merely in LD with it. Similarly, certain TNF promoter polymorphisms, including the much-studied SNP TNF-308G/A, have shown association with SLE; but again, many of these variants are carried on the highly conserved 8.1 ancestral haplotype, thus restricting interpretation of these data.
In 2002, a family-based study employing microsatellites as surrogate markers for HLA-DRB1 haplotypes in Caucasian lupus families demonstrated association with DR3-, DR2-, and DR8 (DRB1*0801)-containing haplotypes. In that study, Graham and colleagues reported that, taking advantage of recombinant chromosomes, the disease risk region could be limited to a 1 Mb region encompassing classical class II and class III [25].
We have performed a medium resolution association mapping study of the MHC in lupus families, utilizing a combination of SNPs and four-digit typing at the HLA-DRB1 locus in order to anchor haplotypes. Sixty-eight SNPs were successfully genotyped across a 2.4 Mb region of the MHC, from the class I locus KIAA1949 to the class II gene HLA-DPB2, in 314 UK Caucasian SLE trios. We used these data to perform a family-based association study in an attempt to distinguish the relative effects of the class II and class III regions of the MHC in lupus susceptibility. In addition, we employed the long-range haplotype test to search for the presence of high-frequency, extended haplotypes indicative of recent positive selection [26]. We have also used family-based and case-control strategies to examine genotypic risk at HLA-DRB1 and rs419788.<br><br>Results
Association Testing of HLA-DRB1 and MHC Region SNPs
In order to define the causal variation within the MHC region, we typed 314 complete SLE trios for the HLA-DRB1 gene as well as for 86 SNPs across a 2.4 Mb region encompassing the HLA class I locus HLA-B to HLA-DPB2. High-quality genotype data was obtained for HLA-DRB1 and 68 MHC SNPs (see Table S1 for quality control data). Association testing of the HLA-DRB1 gene revealed a significant association with HLA-DRB1*0301 (nominal p = 4.9 × 10−8, permuted p < 0.0001, T:U = 129:55) in our lupus cohort (Table 1). There was also a trend for under transmission of the HLA-DRB1*0701 allele (nominal p = 0.0013, T:U 42:77); however, this association was no longer significant after correction for multiple testing as determined by 10,000 permutations of the dataset (permuted p = 0.09). Furthermore, we did not find evidence of association with HLA-DRB1*1501 (nominal p = 1.0, T:U 70:70) or HLA-DRB1*0801 (nominal p = 1.0, T:U = 11:11) in our cohort (see Table S2 for complete HLA-DRB1 association data); alleles previously suggested by microsatellite typing of a US lupus cohort [25].
Association testing of the MHC region SNPs also identified significant evidence of association to SLE (Table 1 for associated markers and Table S3 for all MHC SNPs). The SNP with the most significant association, rs419788 (nominal p = 4.3 × 10−8, permuted p < 0.0001) was of similar strength to that of the HLA-DRB1*0301 allele, with odds ratios (ORs) and 95% confidence intervals (CIs) of 2.0 (1.6–2.6) and 2.3 (1.7–3.2), respectively. This SNP is located within intron 6 of the class III gene, superkiller viralicidic activity 2-like (<span class="yellow">Saccharomyces cerevisiae</span>) (SKIV2L), and is located approximately 500 kb telomeric to the HLA-DRB1 gene. Of the other 12 SNPs that were significantly associated with SLE (nominal p = 4.0 × 10−4 to 2.5 × 10−7; permuted p = 0.03 to <0.0001), one was located in the class I region between HLA-B and MICA, seven were located in the class III region, and four were situated in the class II region (Table 1; Figure S1). Specifically, the seven associated class III SNPs were located in or close to the following genes: the TNF promoter, BAT3, SLC44A4, EHMT2, TNXB, GPSM3, and NOTCH4. One of the four class II associated SNPs was close to HLA-DRA, two were between HLA-DRB1 and HLA-DQA1 and one was in intron 1 of HLA-DQA1. The correlation between all 68 SNPs and HLA-DRB1 in our UK SLE cohort is illustrated in Figure 1. The markers showing significant association are highlighted.<br><br>Conditional Analyses Identify Two Independent Association Signals in the MHC
In order to establish whether the two most associated signals identified in this association-mapping experiment are likely to represent a single causal allele or independent risk factors, we first examined the association data conditioned upon the presence of the HLA-DRB1*0301 allele. We found that four of the 13 associated SNPs showed evidence of signals independent of HLA-DRB1*0301 in our dataset, the strongest of which was rs419788 (Table 1). We therefore conditioned the three remaining SNPs (rs2523589, rs1052486, and rs605203) on rs419788 to assess whether these signals are truly independent of each other or show association due to LD with rs419788. In addition, we included HLA-DRB1 in stepwise conditional regression analyses performed on the SNPs showing association independent of HLA-DRB1 (unpublished data). These analyses demonstrated that the observed association signals at rs2523589, rs1052486, and rs605203 were predominantly dependent upon the association at rs419788, and suggested that there are two major independent association signals in the MHC in UK SLE: HLA-DRB1 and rs419788. The independence of the association signals at HLA-DRB1 and rs419788 is further supported by the observation that there is only modest LD between these two (r2 = 0.24). There was no association with any other HLA-DRB1 allele and the four SNPs independent of HLA-DRB1*0301 (TRANSMIT, unpublished data).
The association of the tumour necrosis factor gene promoter SNP TNF-308G/A with SLE is lost after conditioning for HLA-DRB1*0301 in our cohort. If we perform the reverse analysis and condition HLA-DRB1*0301 on the presence of the TNF promoter SNP, we find that the association remains, confirming that our TNF association is secondary to that of HLA-DRB1*0301.<br><br>Genotypic Risk for Class II and Class III Association Signals
Having established independent association at the allelic level with HLA-DRB1*0301 and rs419788-T in our UK SLE cohort, we wanted to further determine the genotypic risk conferred by these variants and hence gain insight into their underlying mode of inheritance in lupus. We used case-control and family-based analyses to assess genotypic risk at HLA-DRB1, while the family-based test alone was used for rs419788. Common family-based tests of LD, such as those used in this study (Genehunter), measure transmission distortion based on allele counts rather than genotype counts; the former has been shown to be more powerful under additive models, while the latter has greater power under recessive or dominant genetic models [27]. The genotype-pedigree disequilibrium test (geno-PDT) determines LD between a locus genotype and disease by comparing genotypes that are transmitted from parent to proband with those that are not [27]. We used the geno-PDT to assess genotypic risk for our class II and class III association signals: HLA-DRB1 and the SNP rs419788. In the case-control analysis for HLA-DRB1, ORs with 95% CI were calculated and Fisher's exact test employed to assess statistically significant differences between HLA-DRB1 genotypes in lupus probands and healthy controls. For HLA-DRB1, the alleles were coded as follows: HLA-DRB1*0301, HLA-DRB1*1501, HLA-DRB1*X where X represents all HLA-DRB1 alleles other than HLA-DRB1*0301, and HLA-DRB1*1501. We included HLA-DRB1*1501 in the analysis, even though we find no allelic association in our cohort, because previous studies have shown a greater risk for lupus in individuals who are compound heterozygotes for HLA-DRB1*0301- and HLA-DRB1*1501-containing haplotypes [25,28]. Overall the results are consistent with a dominant effect from HLA-DRB1*0301 (Table 2) and a dose-dependent (additive) effect from rs419788-T (Table 3). Specifically, both case-control and geno-PDT demonstrate that there is no dose-dependent increase in disease risk for HLA-DRB1*0301. Rather, it appears that the presence of a single copy of HLA-DRB1*0301 alone is sufficient to increase susceptibility to disease. Moreover the 0301/X genotypes constitute the greatest risk in our cohort rather than the 0301/1501 heterozygotes. Genotypes containing HLA-DRB1*1501 in the absence of HLA-DRB1*0301 revealed no significant association in our cohort.
All three rs419788 genotypes demonstrated significant association in our lupus families (Table 3). The common CC genotype was significantly under transmitted, while the rare T allele displayed dose-dependent over transmission to lupus probands.<br><br>Characterization of HLA-DRB1*0301 Risk Haplotype
Next, we wanted to further delimit the MHC class II association signal that we have detected at HLA-DRB1. We used phased parental genotype data to compare the allelic composition of HLA-DRB1*0301-bearing haplotypes that were transmitted (T) to affected probands to those that were not transmitted (or untransmitted, UT) with the aim of identifying differences that could delineate the lupus susceptibility interval(s) arising from this haplotype (summarized in Figures 2A, 2B, and S2). We observed a striking difference between transmitted and untransmitted chromosomes within the class II region: nearly all transmitted HLA-DRB1*0301 haplotypes (99%) are identical across a 180 kb region defined by eight SNPs, whereas the corresponding region within untransmitted HLA-DRB1*0301 haplotypes exhibits significant recombination. These data strongly suggest the existence of a risk haplotype that, interestingly, contains only three expressed genes: HLA-DRB1, HLA-DQA1, and HLA-DQB1. Furthermore, we can confidently define the allelic composition of this risk haplotype, as these three genes are in strong LD and occur in one common haplotype in Caucasians: HLA-DRB1*0301-HLA-DQA1*0501-HLA-DQB1*0201. Thus, we hypothesize that the specific combination of all three alleles is required to confer disease risk in lupus or that disease susceptibility lies with either HLA-DRB1*0301 or the HLA-DQ alleles. We do not have sufficient numbers of recombinant chromosomes in this risk region to further delimit this signal: 2/176 (1.1%) transmitted HLA-DRB1*0301 haplotypes are recombinant at HLA-DQA1-HLA-DQB1; 3/178 (1.7%) transmitted haplotypes identical across HLA-DQA1-HLA-DQB1 do not possess HLA-DRB1*0301.
The composite relative extended haplotype homozygosity (REHH) versus frequency plot for UK SLE; Utah residents with ancestry from northern and western Europe (CEPH); and Yoruba in Ibadan, Nigeria (Yoruba) populations is shown in Figure 3A. We can only comment on evidence for positive selection in CEPH individuals, as we have used this population alone to assess background variation on Chromosome 6. The SLE and Yoruba cohorts are shown for comparative purposes. We find no evidence of positive selection for HLA-DRB1*0301 in the CEPH population. However, this allele is enriched in our lupus cohort (21% of parental chromosomes) and displays greater extended homozygosity when compared with HLA-DRB1*0301-bearing haplotypes in CEPH and Yoruba. Hence, the HLA-DRB1*0301 allele in lupus is observed as an outlier on the plot when compared to background variation in CEPH. These data support our previous observations (outlined above) of the highly conserved nature of HLA-DRB1*0301 haplotypes in lupus. In addition, the haplotype bifurcation plots centered on HLA-DRB1*0301 for UK SLE, CEPH, and Yoruba populations in Figure 3B illustrate preservation of the common HLA-DRB1*0301 haplotype in CEPH and UK SLE, while that seen in the Yoruba is significantly different. The class II regions of all three populations are essentially identical across our chosen SNPs; the main differences lie in class III. The difference in African populations in the class III region is one possible explanation for the lack of evidence for an association between HLA-DRB1*0301 and SLE in African or African American populations. However, HLA-DRB1*0301 has a lower frequency (∼7%–10%) in African populations compared with Europeans (∼13%), and the number of HLA association studies conducted in African populations is very limited.<br><br>Characterization of Class III Region Risk Haplotype
Our data reveal a second independent signal at the MHC in SLE arising from the T allele of SNP rs419788 in intron 6 of the class III gene, SKIV2L. Further evidence supporting the independence of the rs419788-T and HLA-DRB1*0301 alleles is provided by the moderate LD between these two variants (r2 = 0.24) coupled with our data demonstrating that only 47% of rs419788-T allele-bearing haplotypes contain HLA-DRB1*0301.
The structure and composition of T and UT haplotypes anchored at rs419788-T were essentially identical (Figures 2C, 2D, and S2), and hence not informative in delimiting our class III signal. Therefore, we examined the LD structure around our associated class III SNP to better define our disease risk interval. In our lupus dataset the rs419788-T allele resides on three of seven haplotypes present within a large block of six SNPs exhibiting strong LD. This haplotype block encompasses roughly 270 kb containing class III genes from SLC44A4 to AGER, including the RCCX module. Next, we analyzed the haplotype block structure of this region in CEPH families using SNP data dumped from the International HapMap Project (http://www.hapmap.org/). The greater density of SNP typing available in the HapMap CEPH population compared to our current UK SLE map allowed us to potentially refine our signal by exploring correlations between our associated SNP and those surrounding it. Analysis of these data (Figure 4) suggests the presence of short-range LD around our associated variant, rs419788, in CEPH families, encompassing approximately 40 kb of the genome which includes the five genes: complement factor B (CFB), RD RNA binding protein (RDBP), SKIV2L, dom-3 homolg Z (<span class="yellow">C. elegans</span>) (DOM3Z), and serine/threonine kinase 19 (STK19), and does not include the complement C4 locus. Furthermore, assessment of marker association in our lupus dataset demonstrates that after conditioning for HLA-DRB1*0301, the only markers that retain association signals are telomeric of SKIV2L, suggesting that complement C4, which is centromeric to this gene, may not be responsible for our independent class III signal.<br><br>Subphenotype Analysis
In order to gain further insight into disease pathogenesis, we examined common lupus subphenotypes. Such subsets are more homogeneous than lupus per se and thus maybe enriched for specific predisposing variants. In addition, one might expect a close association between MHC class II alleles and autoantibody subsets in lupus if these are indeed causal variants, given their role in antigen presentation and subsequent humoral immunity. We therefore tested our two main MHC association signals, HLA-DRB1*0301 and rs419788, for association with renal disease and autoantibody subsets in our lupus cohort.
We found that HLA-DRB1*0301 was associated with the presence of anti-Ro and anti-La antibodies in our UK SLE cohort, with the latter showing the greatest evidence of association (anti-La nominal p < 0.001 compared with anti-Ro nominal p < 0.025). We found no association of HLA-DRB1*0301 with renal disease or any other autoantibody subsets in our dataset (see Table S4 for detailed results).
Genotypes of the SNP rs419788 were not associated with any of the tested lupus subphenotypes after controlling for the effect of HLA-DRB1*0301 (unpublished data).<br><br>
Discussion
We present the first family-based SNP association study of the MHC in SLE. We have genotyped 69 markers (HLA-DRB1 and 68 SNPs) across 2.4 Mb of the MHC, encompassing class III and class II, in a cohort of 314 UK Caucasian SLE trios. Transmission disequilibrium testing of these data has shown predominant association with the alleles HLA-DRB1*0301 and rs419788-T, together with 12 other MHC SNPs. Moreover, using conditional analyses, we have shown that the two primary signals of association at the MHC are independent of each other. Specifically, one signal arises from HLA-DRB1*0301 in class II and the other from the T allele of SNP rs419788 in the class III gene SKIV2L.
Examination of bifurcation plots for T and UT HLA-DRB1*0301-containing haplotypes has enabled delineation of our class II association signal to a 180 kb region encompassing HLA-DRB1*0301-HLA-DQA1*0501-HLA-DQB1*0201. These data substantially refine that previously published by Graham et al. in 2002 [25], where the lupus susceptibility interval within HLA-DRB1*0301-containing haplotypes could only be delimited to a 1 Mb region encompassing class II and class III. The precise causal variant(s) within this region remains to be determined, as the three implicated alleles exhibit strong LD with few recombination events separating them (two out of 176 transmitted HLA-DRB1*0301 chromosomes in our dataset). However, all three allelic variants represent attractive functional candidates in lupus susceptibility for their role in antigen presentation and stimulation of the adaptive immune response.
Our association of HLA-DRB1*0301 with lupus concurs with published data in Caucasian cohorts and is well established [16]. While our lack of association with HLA-DRB1*1501 and HLA-DRB1*0801 is consistent with previous data from the UK [29], Spain [30], the Netherlands [31], Sweden [32], Mexico [33], and the US [34], it conflicts with that of other US groups [25,35]. Interestingly, we demonstrate a trend, though not statistically significant, for undertransmission of HLA-DRB1*0701—a result also observed in prior UK and Canadian lupus studies [29,36]. Moreover, a negative association of HLA-DRB1*0701 has been reported in other autoimmune diseases including Graves disease [37,38], type 1 diabetes [39], and rheumatoid arthritis [40].
It appears that the conflicting results between UK SLE and previous US (Minnesota [MN]) [25] SLE data stem from differences in HLA-DRB1 allele frequency in the probands of each cohort. The reason for this is unclear. A comparison between UK and MN SLE cohorts (Table 4) reveals that UK SLE cases are enriched for HLA-DRB1*0301 but not HLA-DRB1*0801 or HLA-DRB1*1501 when compared to a UK control population. In contrast, MN SLE cases are enriched for HLA-DRB1*0301-DQB1*0201, DRB1*0801-DQB1*0402, and DRB1*1501-DQB1*0602 inferred haplotypes when compared to MN controls [25]. There is no statistically significant difference in the aforementioned HLA class II alleles/haplotypes between UK and MN control populations that could account for the disparity seen in the respective lupus cohorts. Differences in disease severity and subphenotype frequency between the two populations could account for the observed discrepancy. From the limited data available we found that the presence of renal disease appears to be similar in both cohorts (UK SLE 36% compared with MN SLE 40%), while the gender ratios are significantly different (female: male UK SLE 11:1 compared with MN SLE 57:1, Chi square p value < 0.001). We were unable to compare other lupus subphenotypes. Furthermore, closer inspection of these data reveals that microsatellite-inference of HLA-DRB1 alleles in the MN SLE dataset may underestimate the frequency of HLA-DRB1*0301 and overestimate that of HLA-DRB1*1501, thus diminishing the effect of the former and enhancing that of the latter. It is also possible that the MN SLE cohort shows greater racial heterogeneity in comparison to our UK SLE cohort, despite both being characterized as Caucasian.
Previous studies have demonstrated increased risk for lupus in individuals carrying particular combinations of microsatellite-inferred HLA-DRB1-HLA-DQB1 haplotypes [25,28]. The highest risk genotype was found to be the compound heterozygote HLA-DRB1*0301-DQB1*0201/HLA-DRB1*1501-DQB1*0602, while HLA-DRB1*0301-DQB1*0201-containing genotypes demonstrated a dose-dependent effect in increasing lupus susceptibility [25,28]. In the present study, we have examined genotypic risk at the classically typed HLA-DRB1 locus and in contrast to the aforementioned data of Graham et al. [25,28] we have shown a likely dominant effect of the associated allele, HLA-DRB1*0301. The case-control and family-based analyses for HLA-DRB1 also show the greater power of the former to detect significant association (Table 2). Specifically, all genotypes containing HLA-DRB1*0301 show increased transmission to lupus probands; however, homozygotes show no greater risk compared with heterozygotes, as would be expected under additive or multiplicative models. Thus, a dominant model of inheritance, requiring the presence of a single copy of the disease-predisposing variant alone, likely underlies the susceptibility conferred by HLA-DRB1*0301 in UK SLE. Such a model would fit an antigen presentation hypothesis where susceptible individuals carrying an HLA-DRB1*0301 allele are able to present auto-antigens to CD4+ lymphocytes, thus stimulating an autoimmune response. The differences between our UK SLE and the previously published US SLE data may reflect disease, ethnic, and haplotypic heterogeneity.
Interestingly, analysis of genotypic risk at the associated class III marker, rs419788, suggests an additive (dose-dependent) pattern of inheritance for the rare T allele, where one copy confers a low risk of disease and two copies results in greater susceptibility. The different inheritance patterns for our class II and class III association signals provide further evidence for their independence.
A variety of HLA-DR and HLA-DQ alleles have been associated with autoantibody subsets in ethnically diverse populations of lupus. The strongest associations have been demonstrated between anti-Ro and anti-La antibodies and HLA-DR3 and HLA-DQ2 (HLA-DQB1*0201), which are in strong LD [41–45] in case-control studies. Here, we confirm the association of HLA-DRB1*0301 with anti-Ro and anti-La antibody production in our family-based cohort.
Examination of LD structure around our second independent association, rs419788-T in class III, coupled with the results of our conditional analysis, suggests that this signal could also be delimited to a relatively narrow genomic interval of about 40 kb given further SNP mapping in our cohort. This region includes the genes CFB, RDBP, SKIV2L, DOM3Z, and STK19, but does not include complement C4. Thus, complement C4 null alleles, which have been implicated in lupus pathogenesis, may not be responsible for our class III signal. We conclude, therefore, that our family-based mapping study has potentially revealed a hitherto unknown lupus susceptibility interval in the class III region of the MHC. However, we cannot conclusively exclude association at complement C4/RCCX without direct determination of C4 polymorphism/copy number in our cohort.
With respect to the genes implicated in our study, CFB is a vital component of the alternate complement pathway and disregulation may clearly affect the inflammatory response [46]. RD and Skiv2l are proteins potentially involved in RNA processing. The RD protein forms part of a negative elongation factor (NELF) complex that represses RNA polymerase II transcript elongation, while Skiv2l is a DEAD box protein with possible function as an RNA helicase. The function of Dom3z is currently unknown, although the homologous <span class="yellow">yeast</span> protein binds nuclear exoribonuclease. Moreover, its ubiquitous expression suggests a housekeeping role. STK19 is a protein kinase of unknown function with primary nuclear localization [47]. Interestingly, RDBP and SKIV2L are found to be highly expressed in T lymphocytes, B lymphocytes, and dendritic cells (SymAtlas, http://symatlas.gnf.org/SymAtlas/).
A number of studies have demonstrated conflicting evidence for and against association with various TNF locus polymorphisms in SLE [48]. A recent meta-analysis of the TNF-308G/A promoter polymorphism in SLE [48] revealed evidence of association for the minor allele (A) in European populations; however, this study did not account for LD with class II alleles. On conditioning our dataset for HLA-DRB1*0301, we find that the TNF promoter signal is lost, suggesting that this association is not independent and is due to LD with HLA-DRB1*0301 (or another variant in LD with HLA-DRB1*0301).
In summary, we have found association with two distinct and independent variants within the class II (HLA-DRB1*0301) and class III (SKIV2L) regions of the MHC in UK SLE trios. We can delimit our class II signal in lupus to three genetic variants (HLA-DRB1*0301-HLA-DQA1*0501-HLA-DQB1*0201) that may confer disease risk in combination or as separate signals. Our class III signal importantly excludes independent association at the TNF promoter polymorphism TNF-308G/A and potentially provides a novel locus for further study.<br><br>Materials and Methods
Study cohorts.
SLE families. The cohort comprises 314 complete SLE trios (that is, mother, father, and affected lupus proband) collected as previously described [49]. All study <span class="yellow">participants</span> are European Caucasian on the basis of grandparental origin. All 314 lupus probands (288 female, 26 male) fulfill the revised American College of Rheumatology (ACR) criteria for SLE [50], 36% of whom have a diagnosis of lupus nephritis. Written consent was obtained from all study <span class="yellow">participants</span> and ethical approval for this study was obtained from the Multi-Centre Research Ethics Committee (MREC 2 June 1998).<br><br>Healthy controls.
The control population for the HLA-DRB1 genotypic risk case-control analysis constitutes 1,667 healthy males of Northern European origin. The individuals are potential hematopoietic stem cell donors and were typed to four digits for HLA-DRB1 at the Anthony Nolan Trust, UK for this purpose. The level of resolution used for the typing of HLA-DRB1*15 alleles in these healthy controls resulted in the ambiguous allele string HLA-DRB1*1501/1502/1504/1506. However, it is likely that the great majority are HLA-DRB1*1501. There is no gender bias in HLA-DRB1 allele frequencies, so although we have used a male control cohort, the frequencies would be expected to be the same in a similar female cohort (Steven Marsh, personal communication).<br><br>SNP genotyping.
Eighty-six SNPs were chosen for genotyping in our mapping study. Specifically, we selected 40 MHC class II and class III haplotype tagging SNPs from a preliminary MHC SNP map [51] that had previously shown robust genotyping efficacy. In addition, we typed 36 MHC class II tag SNPs from a subsequent high-resolution MHC study [52]. We also included the TNF-308G/A promoter SNP, together with nine further SNPs in the region of HLA-B and MICA obtained from the database, dbSNP (http://www.ncbi.nlm.nih.gov/projects/SNP/). The latter SNPs had not been well characterized. All variants were typed in the entire cohort (n = 942). The SNPs span approximately 2.4 Mb of the MHC from the class I gene, KIAA1949 to the class II pseudogene, HLA-DPB2 and thus encompass MHC class III and class II. SNP genotyping was performed at the Broad Institute of MIT and Harvard and at Imperial College London by matrix-assisted laser desorption/ionisation time-of-flight (MALDI-TOF) mass spectrometry using the Sequenom MassARRAY platform as previously described [53]. SNPs that failed Sequenom typing were retyped by KBiosciences (http://www.kbioscience.co.uk/) using their in-house SNP genotyping methodology, KASPar (http://www.kbioscience.co.uk/genotyping/index.htm), a competitive allele-specific PCR technique.<br><br>HLA-DRB1 genotyping.
HLA-DRB1 typing was performed at the Anthony Nolan Trust, UK. All samples (n = 942 UK SLE trios and n = 1,667 controls) were genotyped using LABType SSO (sequence-specific oligonucleotide) typing technology according to the manufacturer's written recommendations (http://www.onelambda.com). Briefly, a locus-specific biotinylated PCR amplicon is produced, denatured, and rehybridized to complementary oligonucleotide probes conjugated to fluorescently coded beads. The bound biotinylated PCR product can be detected using R-phycoerythrin-conjugated streptavidin. A flow analyzer identifies the fluorescent intensity of phycoerythrin on each bead. The assignment of HLA type is based on the reaction pattern compared to patterns associated with known sequences.
High resolution testing was performed using the Dynal AllSet+ SSP (sequence-specific primers) DRB1 assay according to the manufacturer's protocol (Invitrogen) for SLE families only. The presence or absence of PCR amplification was detected in a gel electrophoresis step using visualization by ethidium bromide incorporation. Genotypes were determined using SSPTool software.
Samples that could not be resolved to four digits using SSO and PCR-SSP were analyzed by DNA sequencing of exon 2 of HLA-DRB1. Primers, reagents, and protocols were provided by The Anthony Nolan Trust, UK (primer sequences are available on request). Specific HLA-DRB1 alleles were assigned by comparing the resultant sequence with reference sequence from the IMGT/HLA Database [54].<br><br>Data analysis.
Mendelian inconsistencies were removed using PedCheck [55]. Families in which more than eight markers demonstrated Mendel errors were removed from further analysis. Markers with less than 80% genotyping efficiency and markers where more than eight families showed Mendel errors were also excluded from analysis. Two markers located within the SLE associated class II region (rs2239802 in intron 4 of HLA-DRA and rs6457594 in the region between HLA-DRB9 and HLA-DRB5) show deviation from Hardy–Weinberg equilibrium (HWE), which may reflect an undetected SLE association or systematic genotyping error. HWE was assessed in parental samples in our cohort. There is currently no uniform opinion in the community regarding the inclusion or exclusion of SNPs that show deviation from HWE, hence we elected to include these markers in the final analysis.
Sixty-eight out of the total 86 SNPs passed our quality-control measures (see Table S1 for details). In summary, one SNP was monomorphic in our dataset, four SNPs yielded low genotyping efficiency, and 13 SNPs were excluded for unacceptable Mendel error rate. The mean call rate for all markers post-quality control was 94% (range 83% to 99%).
Family-based association testing was performed using Genehunter TDT (version 2.1) [56] and TRANSMIT (version 2.5) [57]. Haplotypes were constructed and permutation testing performed using Haploview (version 3.32) [58]. Significance of association signals in all analyses was based on permutation testing (10,000 permutations). The data are represented both as nominal and permuted p values. ORs with 95% CI for family-based analyses were calculated in PLINK (http://pngu.mgh.harvard.edu/purcell/plink/) [59]. Conditional regression analyses were undertaken using WHAP [60].
The geno-PDT was performed using PDT version 5.1 with default settings [27]. The HLA-DRB1 alleles were coded into three groups for the geno-PDT and the case-control analysis: HLA-DRB1*0301, HLA-DRB1*1501 and HLA-DRX where HLA-DRX includes all HLA-DRB1 alleles other than HLA-DRB1*0301 or HLA-DRB1*1501. The HLA-DRB1*1501 code in the healthy controls represents the allele string HLA-DRB1*1501/1502/1504/1506, as described previously. The HLA-DRB1*1501 code in the lupus probands represents the alleles HLA-DRB1*1501 (84 out of 91 *1501 and *1502 alleles) and HLA-DRB1*1502 (7/91 *1501 and *1502 alleles), as *1504 and *1506 were not present in this population. Fisher's exact test was used to assess significance of association in the case-control analysis.<br><br>Subphenotype analysis.
We looked for association of the HLA-DRB1*0301 allele with autoantibody subsets and renal disease in our cohort using the Chi-square test. We compared cases with and without the subphenotype of interest with DRB1*0301 homozygosity, heterozygosity, combined homozygosity and heterozygosity, and non-DRB1*0301 status. We performed the same analyses for homozygous and heterozygous genotypes of the associated SNP rs419788. The autoantibody subsets compared were anti-C1q, IgG, and IgM anti-cardiolipin antibodies (ACLG and ACLM), anti-Ro, anti-La, anti-RNP, anti-Sm, and anti-dsDNA.<br><br>Delineation of associated MHC haplotypes and evidence for positive selection.
We looked for positively selected alleles in our dataset using the long-range haplotype test as measured by extended haplotype homozygosity (EHH), previously described by Sabeti et al. [26]. Essentially, such an analysis allows assessment of positive selection by mining datasets for high frequency extended haplotypes in comparison to the other core haplotypes at a locus.
EHH is defined as the probability that two randomly chosen chromosomes carrying the core haplotype of interest will be identical by descent (homozygosity at all SNPs) for the entire interval from the core to a distance x. The REHH is the ratio of the EHH on the tested core haplotype compared with the combined EHH of all the other core haplotypes at the region excluding the tested core; as such, REHH accounts for local variation in recombination rate while EHH does not [26].
The program emphase was employed to assign the phase of parental genotype data and reconstruct missing information. Emphase is a simple phaser similar to the phaser of Excoffier and Slatkin [61]. It is very fast, especially on large datasets, and sufficiently accurate for most genetic applications. EHH analysis was performed on the phased parental data using the software program SWEEP (http://www.broad.mit.edu/mpg/sweep/index.html).<br><br>Haplotype bifurcation plots.
We represent the breakdown of LD on core haplotypes using haplotype bifurcation diagrams generated in the program TREE [62] (also explained in [52]).<br><br>REHH versus frequency plots.
Fifty-three SNPs (identified in Figure 1) are common to our dataset and the CEPH and Yoruba HapMap [63] populations. These three datasets, together with CEPH SNP data for Chromosome 6 in its entirety, were used to generate separate REHH versus frequency plots in SWEEP. The plots from the four cohorts were combined for visual, not statistical, comparison. Evidence for positive selection was quantitatively assessed in CEPH individuals, as this population alone was used to assess background variation on Chromosome 6. The UK SLE and Yoruba cohort data are shown for comparison. The 95th percentile based on total CEPH Chromosome 6 SNP data is shown.<br><br>
Supporting Information
Accession Numbers
The Online Mendelian Inheritance in <span class="yellow">Man</span> (OMIM, http://www.ncbi.nlm.nih.gov/sites/entrez?db=omim) accession numbers for the genes described in this study are as follows: AGER, 600214; BAT3, 142590; C4A, 120810; C4B, 120820; CFB, 138470; DOM3Z, 605996; DOM3Z, 605996; EHMT2, 604599; HLA-B, 142830; HLA-DPB2, 120290; HLA-DQA1, 146880; HLA-DQB1, 604305; HLA-DRA, 142860; HLA-DRB1, 142857; KIAA1949, 610990; MICA, 600169; NOTCH4, 164951; RDBP, 154040; RDBP, 154040; SKIV2L, 600478; SLC44A4, 606107; STK19, 604977; STK19, 604977; TNF, 191160; and TNXB, 600985.<br><br><br><br><h3>pmcA2538543</h3>Personal and environmental correlates of active travel and physical activity in a deprived urban population
Abstract
Background
Environmental characteristics may be associated with patterns of physical activity in general or with particular types of physical activity such as active travel (walking or cycling for transport). However, most studies in this field have been conducted in North America and Australia, and hypotheses about putative correlates should be tested in a wider range of sociospatial contexts. We therefore examined the contribution of putative personal and environmental correlates of active travel and overall physical activity in deprived urban neighbourhoods in Glasgow, Scotland as part of the baseline for a longitudinal study of the effects of opening a new urban motorway (freeway).<br><br>Methods
We conducted a postal survey of a random sample of residents (n = 1322), collecting data on socioeconomic status, perceptions of the local environment, travel behaviour, physical activity and general health and wellbeing using a new 14-item neighbourhood rating scale, a travel diary, the short form of the International Physical Activity Questionnaire (IPAQ) and the SF-8. We analysed the correlates of active travel and overall physical activity using multivariate logistic regression, first building models using personal (individual and household) explanatory variables and then adding environmental variables.<br><br>Results
Active travel was associated with being younger, living in owner-occupied accommodation, not having to travel a long distance to work and not having access to a car, whereas overall physical activity was associated with living in social rented accommodation and not being overweight. After adjusting for personal characteristics, neither perceptions of the local environment nor the objective proximity of respondents' homes to motorway or major road infrastructure explained much of the variance in active travel or overall physical activity, although we did identify a significant positive association between active travel and perceived proximity to shops.<br><br>Conclusion
Apart from access to local amenities, environmental characteristics may have limited influence on active travel in deprived urban populations characterised by a low level of car ownership, in which <span class="yellow">people</span> may have less capacity for making discretionary travel choices than the populations studied in most published research on the environmental correlates of physical activity.<br><br><br><br>Background
Until recently, research on correlates of physical activity was dominated by studies of individual demographic and psychosocial characteristics [1]. This reflected an emphasis on promoting sport, recreation or health-directed exercise using techniques to encourage individual behaviour change [2]. However, there is little evidence that such approaches are effective in increasing physical activity in the medium-to-long term [3]. If habitual patterns of behaviour are environmentally cued, sustained change is likely to require a supportive environment in which <span class="yellow">people</span> can be active [4,5]. There is therefore increasing interest in the influence of the social and physical environment on physical activity.
With respect to the physical (natural or built) environment, a growing body of evidence suggests that certain environmental characteristics may be associated with patterns of physical activity in general or with particular types of physical activity such as walking or cycling as modes of transport [4-10]. Among the correlates most frequently identified in such reviews – some ascertained using 'objective' measures, and others in terms of <span class="yellow">people</span>'s perceptions – are the aesthetic quality of the surroundings, the presence of pavements (sidewalks), the convenience of facilities for being active, the availability of green space, access to amenities (destinations) within walking or cycling distance, safety from traffic and personal attack, and the lack of heavy traffic. Some of these local characteristics reflect higher-order aspects of urban design and spatial policy such as population density, connectivity and mixed land use [6,8]. Importantly, different characteristics may be associated with different types of physical activity; for example, Owen and colleagues found that the aesthetic quality of the surroundings was associated with walking for exercise or recreation and with walking in general, but not with walking for transport, whereas perceptions of traffic were associated with walking for transport and walking in general, but not with walking for exercise or recreation [5].
Despite the growing volume of published studies in this field, many authors remain circumspect in their interpretation of the available evidence. Giles-Corti and Donovan have described access to a supportive physical environment as a necessary, but insufficient, condition for an increase in physical activity in the population [11], while Handy found 'convincing' evidence of an association between physical activity and the built environment in general but 'less convincing' evidence as to which specific environmental characteristics were most strongly associated [7]. One limitation of the available evidence is that most research has been conducted in North America and Australia [9,12], and it is not clear whether associations observed in those countries are generalisable to other settings with different aggregate socioeconomic characteristics (e.g. wealth or access to private cars) or environmental characteristics (e.g. climate, patterns of land use, or availability of public transport). For example, North American researchers are often interested in the presence or absence of pavements (sidewalks), but it is unusual for streets in the United Kingdom (UK) not to have a pavement or footpath beside them. Hypotheses about putative environmental correlates of physical activity therefore need to be tested in a wider range of settings.
A more profound limitation of the available evidence is that identifying a relationship between, for example, urban form and walking for transport is not the same thing as showing that changing the built environment will lead to a change in behaviour [13]. Few researchers have taken up the opportunity (or challenge) presented by 'natural experiments' to investigate the effects of environmental interventions on physical activity [14]. We therefore established a longitudinal study to examine changes associated with the opening of a new urban section of the M74 motorway (freeway) currently under construction in Glasgow, Scotland. The rationale and design for this study have been described previously [15]. It is claimed that the new motorway, which will mostly pass through or close to densely-populated urban neighbourhoods, will contribute to the regeneration of a region which includes some of the most deprived and least healthy working-class communities in Europe [16]. It is also claimed that the new motorway will divert traffic from local streets, reduce traffic noise and bring new local employment opportunities, thereby improving characteristics of the local environment held to be associated with active travel. Others claim that the new motorway will encourage car use, degrade the aesthetic quality of the surroundings and reduce the safety and attractiveness of routes for pedestrians and cyclists across the line of the motorway – all changes which may be expected to discourage active travel [15]. The eventual aim of the M74 study will be to assess the effects of this major modification to the urban built environment and transport infrastructure on perceptions of the local environment and on population health and health-related behaviour, the primary outcome of interest being a change in the quantity of 'active travel' (walking and cycling for transport).
In this paper, we report findings from the cross-sectional (baseline) phase of the study which contribute evidence on the environmental correlates of physical activity in this comparatively deprived urban population. We focus on two specific hypotheses: first, that levels of active travel and overall physical activity vary with demographic and socioeconomic characteristics, but not necessarily in the same way; second, that these relationships may be partly explained by the perceived characteristics of the local environment in which <span class="yellow">people</span> live and by their objectively-assessed proximity to motorway and major road infrastructure.<br><br>Methods
Delineation of study areas
We used spatially referenced census and transport infrastructure data held and analysed in a geographical information system (GIS), combined with field visits, to delineate three study areas in Glasgow with similar aggregate socioeconomic characteristics and broadly similar topographical characteristics apart from their proximity to urban motorway infrastructure (Table 1, Figure 1). All three study areas extended from inner mixed-use districts close to the city centre to residential suburbs, contained major arterial roads other than motorways, and contained a mixture of housing stock including traditional high-density tenements, high-rise flats and new housing developments (Figure 2).<br><br>Sampling and survey administration
We used the Royal Mail Postcode Address File (PAF) (version 2005.3) to identify all residential addresses whose unit postcode (zip code) was within one of the study areas (total n = 35601) and drew a random sample of 3000 households from each area. Unit postcodes (e.g. G12 8RZ) are the smallest available unit of postal geography in the UK; residential unit postcodes cover about 15 addresses on average. We sent the survey to all households (total n = 9000) between 28 September and 4 October 2005 and resent the survey to all non-responding households between 26 and 31 October 2005. We alerted households to the survey by means of a postcard sent a few days in advance, used coloured paper for some of the survey materials, and posted survey packs in white envelopes printed with the university crest; these techniques have been shown in a meta-analysis to be associated with increased response rates to postal surveys [17]. We asked householders to ensure that the questionnaire was completed by a resident aged 16 or over; if more than one resident was eligible, we asked householders to select the <span class="yellow">person</span> with the most recent birthday. Respondents who consented to follow-up were entered into a prize draw to win a £50 (€63; US$92) gift voucher. Responses received more than three months after the first mailing wave were disregarded in analysis.<br><br>Data collection
The questionnaire included items on demographic and socioeconomic characteristics, health and wellbeing (including the the SF-8 scale), perceptions of the local environment, travel behaviour and the short form of the International Physical Activity Questionnaire (IPAQ) (Additional file 1). We developed a new 'neighbourhood scale' to assess perceptions of relevant characteristics of the local environment (aesthetics, green space, access to amenities, convenience of routes, traffic, road safety and personal safety). The development, principal components analysis and reliability of the items in this scale and the derivation and reliability of summary variables are reported in an accompanying paper [18].<br><br>Data cleaning and derivation of variables
Demographic and socioeconomic characteristics
We excluded from analysis all respondents who failed to enter their age or sex. We then examined the distributions of all raw variables and carried out range and consistency checks to identify any anomalous values or variables with a high proportion of missing responses. As a consequence, we collapsed responses on distance to place of work or study, housing tenure, car access and working situation into fewer categories by merging categories with small numbers of responses; we also disregarded household composition and working situation of spouse or partner in analysis because of the large numbers of missing values for these variables.<br><br>Health and wellbeing
We calculated body mass index (BMI) by converting, where necessary, self-reported heights and weights from imperial to metric units and dividing the height in metres by the square of the weight in kilograms; we also categorised respondents into quintiles of BMI. We calculated physical (PCS-8) and mental (MCS-8) health summary scores from the SF-8 data and scaled these to population norms using the method and coefficients given in the SF-8 manual [19].<br><br>Objective environmental characteristics
We linked each record to the unit postcode of residence. We then constructed concentric buffers at 100-metre intervals up to 500 metres around the routes and access points of existing and planned motorways and around the network of other major (A- and B- class) roads, and assigned each respondent to a category of proximity to each type of road infrastructure (within 100 metres, 101–200 metres, etc.) based on the location of the centroid of their unit postcode.<br><br>Travel behaviour
For travel time analysis we included travel diaries which recorded no travel at all, but we disregarded travel data from respondents who had not been at home on the day of the travel diary, whose questionnaire had been misprinted such that the travel diary pages were unusable, who had recorded journeys without reporting valid quantitative data on the durations of those journeys, or whose completed travel diary appeared implausible. We also disregarded journeys whose purpose was not stated or was beyond the scope of the travel diary (Additional file 1, page 8). We summed the reported travel time for each mode of transport, calculated a total travel time by active modes (walking plus cycling) and by all modes combined, and calculated the proportion of total travel time contributed by each mode of transport.<br><br>Physical activity
We cleaned and analysed IPAQ data in accordance with the IPAQ scoring protocol . We therefore disregarded physical activity data from respondents who had reported more than 16 hours of physical activity per day or who had missing or internally inconsistent data on the frequency or duration of any of the three categories of physical activity (walking, moderate-intensity activity or vigorous activity). We also recoded reported durations of activity of less than ten minutes to zero, and of greater than 180 minutes to 180 minutes. We calculated the estimated total physical activity energy expenditure for each respondent (MET-min/week) and used a combination of frequency, duration and total energy expenditure to assign each respondent to a 'high', 'moderate' or 'low' category of overall physical activity in accordance with the prescribed IPAQ algorithm. The 'high' category corresponds to a sufficient level of physical activity to meet current public health recommendations for adults [20].<br><br>
Analysis
We considered it unlikely that the statistical assumptions required for linear regression could be met because the distributions of time spent walking and cycling and of estimated total physical activity energy expenditure were both strongly positively skewed and dominated by a large number of zero values which meant that the data were not amenable to log-transformation. We therefore modelled the correlates of active travel and physical activity using multivariate logistic regression. We defined 'active travel' as a binary condition achieved by any respondent who had reported at least 30 minutes of travel by walking, cycling or both in their travel diary, reflecting the current recommendation that adults should accumulate at least 30 minutes of moderate-intensity physical activity on most days of the week [20], and we defined 'physical activity' as a binary condition achieved by any respondent whose overall physical activity was categorised as 'high' using IPAQ. We then built separate multivariate models for active travel and physical activity following the method of Hosmer and Lemeshow [21], first including only 'personal' (individual or household) variables and then adding 'environmental' variables (Additional file 2).<br><br>
Results
Response
We received 1345 completed questionnaires. After subtracting from the numerator 23 completed questionnaires with missing critical demographic data (age or sex), and after subtracting from the denominator 676 addresses from which survey packs were returned as undeliverable, this left 1322 valid responses to be entered into analysis – a response rate of 1322/(9000-676) = 15.9%.<br><br>Characteristics of study <span class="yellow">participants</span>
Demographic and socioeconomic characteristics
Respondents were aged between 16 and 89 years (median age 48 years). 804 (61%) were <span class="yellow">women</span>. Only 136 (26%) of the <span class="blue">men</span> and 145 (18%) of the <span class="yellow">women</span> reported having access to a bicycle. For those who usually travelled to a place of work or study, the median reported distance was 3.5 miles (about 5.5 kilometres). Other characteristics of study <span class="yellow">participants</span> are summarised in Table 2.<br><br>Health and wellbeing
25% of respondents reported difficulty walking for a quarter of a mile, 39% reported a long-term health problem or disability, and 50% were overweight (median BMI 25.1 kg/m2). The median mental health summary score (MCS-8) was significantly lower (i.e. poorer) than the population norm (median 47.3, 95% CI 46.4 to 48.1); the median physical health summary score (PCS-8) was not significantly different from the population norm (median 50.9, 95% CI 49.6 to 51.7).<br><br>
Descriptive data on travel behaviour and physical activity
Travel behaviour
1099 travel diaries were suitable for travel time analysis. <span class="yellow">Men</span> and <span class="yellow">women</span> were equally likely to have returned usable travel time data, but respondents who were older, retired, or living in social rented accommodation or who did not have access to a car were less likely to have returned usable data. On average, respondents recorded about an hour's travel per day (mean 61.5 minutes, median 50.0 minutes), of which a minority was spent using active modes of transport (walking or cycling: mean 20.0 minutes, median 10.0 minutes) (Table 3). 304 respondents (28%) recorded at least 30 minutes of active travel, of whom 294 (97%) recorded at least 30 minutes of walking.<br><br>Physical activity
833 respondents returned complete physical activity data suitable for analysis. <span class="yellow">Women</span> and respondents who were older, retired, or living in social rented accommodation or who did not have access to a car were less likely to have returned usable data. Respondents reported a mean of 318 minutes' walking per week and a mean estimated total physical activity energy expenditure of 3000 MET-minutes per week (Table 4). Only 316 respondents (38%) were categorised as having achieved a 'high' (i.e. sufficient) level of physical activity.<br><br>
Correlates of active travel
Active travel was significantly associated with being younger, living in owner-occupied accommodation, not having to travel more than four miles to work, having access to a bicycle, not having access to a car, and the absence of any difficulty walking. The final best model of the 'personal' correlates of active travel provided satisfactory goodness-of-fit (Hosmer and Lemeshow test: χ2 = 13.04, df = 8; P = 0.11) and explained nearly one-fifth of the total variance in active travel (Nagelkerke's R2 = 18.7%) (Table 5). Adding 'environmental' variables to the model showed an additional significant positive association between active travel and perceived proximity to shops, and an additional significant negative association between active travel and perceived road safety for cyclists. The final best model of the personal and environmental correlates of active travel also provided satisfactory goodness-of-fit (Hosmer and Lemeshow test: χ2 = 10.61, df = 8; P = 0.23) and explained slightly more of the total variance in active travel than did the personal model alone (Nagelkerke's R2 = 20.1%) (Figure 3).
In order to aid interpretation, we also partitioned the dataset into two strata ('No car available' and 'Car available') and refitted the final model separately to each stratum of the dataset (Table 6). This showed that the subset of respondents with no access to a car accounted for the significant overall relationship between active travel and access to a bicycle, whereas those with access to a car accounted for the significant overall relationships with distance to place of work or study and perceptions of the local environment. The relationship with difficulty walking was also stronger in this group than in those without access to a car.<br><br>Correlates of physical activity
Physical activity was significantly associated with living in social-rented accommodation, not being overweight, and the absence of any difficulty walking. The final best model of the 'personal' correlates of physical activity provided satisfactory goodness-of-fit (Hosmer and Lemeshow test: χ2 = 3.89, df = 7; P = 0.89) and explained about one-sixth of the total variance in physical activity (Nagelkerke's R2 = 15.9%) (Table 7). Adding 'environmental' variables to the model showed an additional significant negative association between physical activity and perception of traffic volume (i.e. respondents who perceived there to be a higher volume of traffic were more likely to report physical activity). The final best model of the personal and environmental correlates of physical activity also provided satisfactory goodness-of-fit (Hosmer and Lemeshow test: χ2 = 3.86, df = 8; P = 0.87) and explained slightly more of the total variance in physical activity than did the personal model alone (Nagelkerke's 16.6%) (Figure 3).<br><br>
Discussion
Principal findings
In this deprived urban population, the likelihood of reporting active travel was associated with being younger, living in owner-occupied accommodation, not having to travel a long distance to work and not having access to a car, whereas overall physical activity was associated with living in social-rented accommodation and not being overweight. After adjusting for individual and household characteristics, neither perceptions of the local environment nor the objective proximity of respondents' homes to motorway or major road infrastructure appeared to explain much of the variance in active travel or overall physical activity, although we did find a significant positive association between active travel and perceived proximity to shops.<br><br>Representativeness and completeness of survey data
Our difficulty in obtaining a representative sample of the resident population is not unique to our study. Although our final response rate was low, it was almost identical to that achieved in a recent population-based intervention study elsewhere in Glasgow [22]. Some of the challenges of recruiting research <span class="yellow">participants</span> in areas of deprivation have been described elsewhere [23]; these are superimposed on a downward trend in participation in even the best-resourced national population surveys [24] and an upward (and socially biased) trend in opt-outs from the main alternative sampling frame, the edited electoral register [25]. Although our achieved sample contained a higher proportion of respondents from owner-occupied and car-owning households than predicted from 2001 census data for the same census output areas, these differences may be partly accounted for by an upward background trend in owner occupation and car access between 2001 and 2005. Our achieved sample is still clearly disadvantaged overall, in terms of socioeconomic and health status, compared with the country as a whole. It also contains sufficient heterogeneity to enable us to examine, in time, how the effects of the intervention are distributed between socioeconomic groups. We therefore consider our achieved sample fit for purpose.
We had to disregard a substantial proportion of cases in analysis because respondents had returned unusable travel time data or had returned physical activity data that were incomplete, internally inconsistent or included a 'Don't know' response and were therefore unacceptable according to the IPAQ scoring protocol. Most published studies using the same, short form of IPAQ have either not reported the distribution of the continuous summary measures or have not reported data for the UK separately from those for other countries where higher levels of physical activity are reported. Despite the high proportion of missing physical activity data in our dataset, however, the aggregate continuous data we obtained were broadly comparable to those reported in Rütten and colleagues' study of a random sample of UK adults [26]. We could have included more cases in physical activity analysis by, for example, imputing missing values, but the results would not have been comparable with others' owing to the substantial deviations from the scoring protocol which would have been required. The frequency of unusable responses was not reported in the international multi-centre study which originally established the validity and reliability of IPAQ [27]. It is possible that offering a 'Don't know' option in the self-completed IPAQ questionnaire encourages respondents to select this rather than to enter what may be a reasonably precise estimate of the actual time spent in physical activity; the respondent has no way of knowing that a single 'Don't know' response will result in all of their physical activity data being disregarded in analysis. This should be considered in any future revision of the IPAQ questionnaire and scoring protocol.<br><br>Contribution of active travel to overall physical activity
The explanatory variables that were significantly associated with active travel but not with physical activity (distance to place of work or study, access to a bicycle, access to a car, perceived proximity to shops, and perceived road safety for cyclists) all have an obvious intuitive relationship with the use of walking or cycling as modes of transport. That they were not significantly associated with overall physical activity suggests either that active travel contributes only a minority of respondents' overall physical activity or that other factors not measured in this study are more important correlates of overall physical activity than those which determine active travel. A crude comparision of the quantity of active travel reported in the one-day travel diaries with the quantities of physical activity reported using IPAQ suggests that on average, active travel may indeed make only a small (~15%) contribution to overall physical activity in this study population. However, the real contribution may be substantially greater than this if, as has been shown previously, respondents tend to over-report their physical activity using IPAQ [28]. There can be little doubt that active travel makes a substantial contribution to the total quantity of walking reported in this study population. Irrespective of the true contribution of active travel to overall physical activity, however, it remains likely that other unmeasured personal and social factors beyond the scope of this study may be more important correlates of overall physical activity.<br><br>Socio-spatial patterning of active travel and overall physical activity
Respondents living in owner-occupied households were more likely to report active travel than those living in social-rented accommodation, but less likely to report sufficient overall physical activity. Since neither working situation nor perceived financial situation emerged as significantly associated with active travel or overall physical activity, housing tenure and car access are the remaining explanatory variables in this dataset which can be interpreted as markers of socioeconomic status. Although having access to a car clearly reflects the possession of a material asset, it has been argued that this is a less direct marker of socioeconomic status than some other markers because, in Scotland at least, access to a car is a more-or-less essential requirement for living in many rural areas, whereas it is possible to live in a dense urban settlement such as Glasgow without using a car. In the final models in this study, therefore, housing tenure may be regarded as the primary marker of socioeconomic status. The findings consequently suggest conflicting socioeconomic gradients in prevalence: more advantaged respondents were more likely to report active travel, but more disadvantaged respondents were more likely to report sufficient overall physical activity. The higher prevalence of sufficient overall physical activity among the more disadvantaged despite their lower propensity for active travel is likely to reflect higher quantities of physical activity in other domains, particularly occupational and domestic activities, since leisure-time physical activity tends to be higher among more advantaged groups [29].<br><br>Environmental characteristics: paradoxical, unmeasured, or irrelevant?
The two environmental variables that emerged as significantly associated with active travel, particularly among those without access to a car, were perceived proximity to shops and perceived road safety for cyclists. The positive association with perceived proximity to shops suggests that for active travel to be undertaken in this population, it may be more important that <span class="yellow">people</span> live close to the amenities they need than that they live in an environment with more favourable subjective or discretionary considerations such as attractiveness or noise. This would be consistent with an understanding that walking as a mode of transport is primarily a way of undertaking journeys which have to be made anyway, as opposed to more discretionary (recreational) forms of walking which may be more susceptible to the influence of less-structural characteristics.
Although the negative association with perceived road safety for cyclists appears counter-intuitive, similar 'paradoxical inverse relationships' have been reported elsewhere, for example by Titze and colleagues in a study of the correlates of cycling among students [30] and by Humpel and colleagues in a study of correlates of walking for pleasure [31]. Titze and colleagues suggest that respondents who cycle regularly are more likely to be aware of, and report, the danger posed by traffic than non-cyclists or infrequent cyclists. A similar phenomenon could explain the negative association between physical activity and perception of traffic volume.
Overall, the influence of the putative environmental characteristics examined in this study on active travel and physical activity appeared small compared with that of the personal characteristics found to be significant, and including environmental characteristics in the models did not substantially modify the influence of personal characteristics.
On the one hand, this could reflect an artefact of the research methods (a false negative error), which could have arisen in various ways. In particular, the 'wrong' environmental exposure may have been measured, in that the environmental characteristics examined were those of the immediate surroundings of respondents' homes, whereas the propensity to choose active modes of transport may be more strongly influenced by the characteristics of the environment elsewhere on their routes [30], for example the perceived danger of cycling in the city centre – an association which may be absent, or at least diluted, when the 'exposure' examined is limited to the residential environment. It could also be argued that the apparently weak influence of environmental characteristics in this study reflects a reliance on respondents' perceptions which have not been objectively verified and may therefore be a weak proxy for the 'true' objectively-measured characteristics of their surroundings. However, as recent reviews have pointed out, the current weight of evidence for objective environmental correlates of walking is no greater than that for subjective environmental correlates [5] and it is entirely plausible that <span class="yellow">people</span>'s perceptions of their environment may be at least as important as their objective conditions in influencing their behaviour [6].
On the other hand, we may have demonstrated a real absence of any major association. Although at first sight this appears at odds with the growing body of review-level evidence for environmental correlates of physical activity, Wendel-Vos and colleagues noted that of all the environmental factors examined in all the studies included in their review, analysis showed a 'null association' in 76% of cases [9], and our finding that personal factors account for a much larger proportion of the variance in active travel or physical activity than is accounted for by environmental factors is consistent with those of some other European studies [32,33]. In the particular context of this study, residents may simply have adapted to adverse conditions in their local environment in the ways identified by Hedges in a qualitative study of <span class="yellow">people</span> living close to new roads built in the UK in the 1970s [34] – particularly by attitudinal adaptation, which Hedges characterises as developing an attitude that it is futile to resist. One can imagine that in the most deprived areas of Glasgow, <span class="yellow">people</span> may have become resigned to the nature of their surroundings, seeing them as inevitable and not amenable to change either through environmental improvement or through their moving to another area.<br><br>
Conclusion
After demographic and socioeconomic characteristics were taken into account, neither perceptions of the local environment nor objective proximity to major road infrastructure appeared to explain much of the variance in active travel or overall physical activity in this study. Our study population may be both objectively constrained by their socioeconomic circumstances (including comparatively limited access to private cars) and adapted to living in conditions which others would consider to pose a barrier to active travel. Under these circumstances, environmental characteristics which have been found to influence discretionary active travel in studies in other, more affluent populations may simply be irrelevant in a population which is more captive in its travel choices. Environmental correlates of active travel should not be assumed to be generalisable between populations; researchers should continue to test hypotheses about putative environmental correlates in different settings, and policymakers should recognise that the effects of interventions to change the environment are likely to vary between populations and between socioeconomic groups within populations.<br><br>Competing interests
This paper is based on material contained in the first author's PhD thesis.<br><br>Authors' contributions
DO had the original idea for the study, designed the study and the survey materials, applied for ethical approval, cleaned and coded the survey data, carried out all the geographical and statistical analyses and wrote the paper. MP was DO's PhD supervisor. RM, NM, MP and SP constituted the steering group for the study, contributed to and advised on the design of the study and the interpretation of the emerging findings, and contributed to the critical revision of the paper. All authors read and approved the final manuscript.<br><br>Supplementary Material<br><br>
<h3>pmcA2602716</h3>A Case-Control Study to Assess the Relationship between Poverty and Visual Impairment from Cataract in Kenya, the Philippines, and Bangladesh
Abstract
Background
The link between poverty and health is central to the Millennium Development Goals (MDGs). Poverty can be both a cause and consequence of poor health, but there are few epidemiological studies exploring this complex relationship. The aim of this study was to examine the association between visual impairment from cataract and poverty in adults in Kenya, Bangladesh, and the Philippines.<br><br>Methods and Findings
A population-based case–control study was conducted in three countries during 2005–2006. Cases were <span class="yellow">persons</span> aged 50 y or older and visually impaired due to cataract (visual acuity < 6/24 in the better eye). Controls were <span class="yellow">persons</span> age- and sex-matched to the case <span class="yellow">participants</span> with normal vision selected from the same cluster. Household expenditure was assessed through the collection of detailed consumption data, and asset ownership and self-rated wealth were also measured. In total, 596 cases and 535 controls were included in these analyses (Kenya 142 cases, 75 controls; Bangladesh 216 cases, 279 controls; Philippines 238 cases, 180 controls). Case <span class="yellow">participants</span> were more likely to be in the lowest quartile of per capita expenditure (PCE) compared to controls in Kenya (odds ratio = 2.3, 95% confidence interval 0.9–5.5), Bangladesh (1.9, 1.1–3.2), and the Philippines (3.1, 1.7–5.7), and there was significant dose–response relationship across quartiles of PCE. These associations persisted after adjustment for self-rated health and social support indicators. A similar pattern was observed for the relationship between cataract visual impairment with asset ownership and self-rated wealth. There was no consistent pattern of association between PCE and level of visual impairment due to cataract, sex, or age among the three countries.<br><br>Conclusions
Our data show that <span class="yellow">people</span> with visual impairment due to cataract were poorer than those with normal sight in all three low-income countries studied. The MDGs are committed to the eradication of extreme poverty and provision of health care to poor <span class="yellow">people</span>, and this study highlights the need for increased provision of cataract surgery to poor <span class="yellow">people</span>, as they are particularly vulnerable to visual impairment from cataract.<br><br>Background.
Globally, about 45 million <span class="yellow">people</span> are blind. As with many other conditions, avoidable blindness (preventable or curable blindness) is a particular problem for <span class="yellow">people</span> in developing countries—90% of blind <span class="yellow">people</span> live in poor regions of the world. Although various infections and disorders can cause blindness, cataract is the most common cause. In cataract, which is responsible for half of all cases of blindness in the world, the lens of the eye gradually becomes cloudy. Because the lens focuses light to produce clear, sharp images, as cataract develops, vision becomes increasingly foggy or fuzzy, colors become less intense, and the ability to see shapes against a background declines. Eventually, vision may be lost completely. Cataract can be treated with an inexpensive, simple operation in which the cloudy lens is surgically removed and an artificial lens is inserted into the eye to restore vision. In developed countries, this operation is common and easily accessible but many poor countries lack the resources to provide the operation to everyone who needs it. In addition, blind <span class="yellow">people</span> often cannot afford to travel to the hospitals where the operation, which also may come with a fee, is done.<br><br>Why Was This Study Done?
Because blindness may reduce earning potential, many experts believe that poverty and blindness (and, more generally, poor health) are inextricably linked. <span class="yellow">People</span> become ill more often in poor countries than in wealthy countries because they have insufficient food, live in substandard housing, and have limited access to health care, education, water, and sanitation. Once they are ill, their ability to earn money may be reduced, which increases their personal poverty and slows the economic development of the whole country. Because of this potential link between health and poverty, improvements in health are at the heart of the United Nations Millennium Development Goals, a set of eight goals established in 2000 with the primary aim of reducing world poverty. However, few studies have actually investigated the complex relationship between poverty and health. Here, the researchers investigate the association between visual impairment from cataract and poverty among adults living in three low-income countries.<br><br>What Did the Researchers Do and Find?
The researchers identified nearly 600 <span class="yellow">people</span> aged 50 y or more with severe cataract-induced visual impairment (“cases”) primarily through a survey of the population in Kenya, Bangladesh, and the Philippines. They matched each case to a normally sighted (“control”) <span class="yellow">person</span> of similar age and sex living nearby. They then assessed a proxy for the income level, measured as “per capita expenditure” (PCE), of all the study <span class="yellow">participants</span> (<span class="yellow">people</span> with cataracts and controls) by collecting information about what their households consumed. The <span class="yellow">participants</span>' housing conditions and other assets and their self-rated wealth were also measured. In all three countries, cases were more likely to be in the lowest quarter (quartile) of the range of PCEs for that country than controls. In the Philippines, for example, <span class="yellow">people</span> with cataract-affected vision were three times more likely than normally sighted controls to have a PCE in the lowest quartile than in the highest quartile. The risk of cataract-related visual impairment increased as PCE decreased in all three countries. Similarly, severe cataract-induced visual impairment was more common in those who owned fewer assets and those with lower self-rated wealth. However, there was no consistent association between PCE and the level of cataract-induced visual impairment.<br><br>What Do These Findings Mean?
These findings show that there is an association between visual impairment caused by cataract and poverty in Kenya, Bangladesh, and the Philippines. However, because the financial circumstances of the <span class="yellow">people</span> in this study were assessed after cataracts had impaired their sight, this study does not prove that poverty is a cause of visual impairment. A causal connection between poverty and cataract can only be shown by determining the PCEs of normally sighted <span class="yellow">people</span> and following them for several years to see who develops cataract. Nevertheless, by confirming an association between poverty and blindness, these findings highlight the need for increased provision of cataract surgery to poor <span class="yellow">people</span>, particularly since cataract surgery has the potential to improve the quality of life for many <span class="yellow">people</span> in developing countries at a relatively low cost.<br><br>Additional Information.
Please access these Web sites via the online version of this summary at http://dx.doi.org/10.1371/journal.pmed.0050244.<br><br><br><br>Introduction
Improvements in health are at the heart of the Millennium Development Goals, with the recognition that better health is central to the primary aim of reducing poverty as well as important in its own right. Empirical data are needed to back up this claim. Unravelling the relationship between blindness and poverty therefore has important implications, and may also be informative for the association between poverty and other disabilities.
Blindness is a common condition globally, affecting approximately 45 million <span class="yellow">people</span>, and more than a third of blindness is caused by cataract [1,2]. Globally, the prevalence of blindness is five-fold higher in poor than rich countries [2]. Limited data show that within countries the poor are also more likely to be blind [3,4]. It is frequently asserted that blindness is both a cause and consequence of poverty, but there are few empirical data to support this claim. Poverty may cause cataract blindness, because access to cataract surgery is limited in low-income countries [5]. Furthermore, within poor countries some evidence suggests that lack of money is a major barrier to uptake of cataract surgery by individuals [6–8]. Blindness may also cause poverty, as the blind individual, or the household members who care for them, have a reduced earning potential [4,9]. This complex problem could have serious implications; estimates from The Gambia suggest that there is a substantial economic burden from lost productivity among blind <span class="yellow">people</span> [10]. Therefore, blindness prevention may ultimately be cost saving [11]. Extrapolations on a global level indicate that a successful eye care programme could prevent more than 100 million cases of blindness between 2000 and 2020, and consequently save at least US$102 billion, which would otherwise be lost to reductions in productivity associated with blindness [12]. However, these estimates are based on extrapolations from limited data and were not based on individual-level data. It is also difficult to identify the component of productivity loss that is due to blindness, as this condition mainly affects older <span class="yellow">people</span>, who may suffer from other comorbidities that restrict their employment opportunities or make them dependent on the care of others.
The Cataract Impact Study was undertaken to assess the relationship between cataract visual impairment and “economic poverty” and quality of life, and to estimate the impact of cataract surgery on these factors in three low-income countries. The aim of the current paper is to assess the association at baseline between visual impairment from cataract and household poverty (measured through consumption, asset ownership, and self-rated wealth) in a population-based case–control study in Kenya, the Philippines, and Bangladesh.<br><br>Methods
Setting
Case and control <span class="yellow">participants</span> were recruited from Nakuru district, Kenya (January–February, 2005); Negros island (May–June, 2005) and Antique district (April–May, 2006), Philippines; and Satkhira district, Bangladesh (November–December, 2005).<br><br>Selection of Cases and Controls
<span class="yellow">Persons</span> with cataract visual impairment (cases) and <span class="yellow">persons</span> without (controls) were primarily recruited through a population-based survey of adults aged ≥ 50 y [6–8]. Clusters of 50 <span class="yellow">people</span> (regardless of visual impairment) aged ≥ 50 y were selected through probability-proportionate to size sampling, using either the census (Philippines and Bangladesh) or electoral role (Kenya) as the sampling frame. Households within clusters were selected through a modification of compact segment sampling, whereby a map was drawn of the enumeration area that was divided into segments, each including approximately 50 <span class="yellow">people</span> aged ≥ 50 y, and one segment was chosen at random [13]. Households in the segment were included sequentially until 50 <span class="yellow">people</span> aged ≥ 50 y were identified. The surveys included 3,503 (93% response rate) <span class="yellow">people</span> aged ≥ 50 y in Kenya, 4,868 (92%) in Bangladesh, 2,774 (76%) in Negros, and 3,177 (83%) in Antique.
All <span class="yellow">people</span> in the survey aged ≥ 50 y underwent visual acuity (VA) testing and ophthalmic examination. VA was measured in full daylight with available spectacle correction with a Snellen tumbling “E” chart using optotype size 6/18 (20/60) on one side and size 6/60 (20/200) on the other side at 6 or 3 metres. If the VA was <6/18 in either eye then pinhole vision was also measured. <span class="yellow">Participants</span> with pinhole vision <6/18 but >6/60 in the better eye due to age-related cataract were given a second VA test using an “E” of size 6/24. The ophthalmologist examined all eyes with a presenting VA <6/18 with a torch (i.e., flashlight), direct ophthalmoscope, and/or portable slit lamp. The principal cause of blindness or visual impairment was recorded, according to the WHO convention in which the major cause is assigned to the primary disorder or, if there are two existing primary disorders, to the one that is easiest to treat [14].
Survey <span class="yellow">participants</span> were eligible for inclusion as cases if they were aged ≥ 50 y with best corrected visual acuity <6/24 in the better eye due to cataract, as diagnosed by an ophthalmologist. All eligible cases identified from these surveys were invited to participate in the study. <span class="yellow">Participants</span> were eligible to be controls if they were aged ≥ 50 y, did not have VA <6/24 in the better eye due to cataract and did not live in the same household as a case. During the survey a list was maintained of all eligible controls, by age group (50–54, 55–59, 60–64, 65–69, and >70) and sex. Whenever a case was identified, one age- and sex-matched control was randomly selected from the list for inclusion (or up to two controls in Bangladesh). If no matching eligible controls had been identified in that cluster at that stage of the survey, then the next eligible control in the cluster was recruited.
Because of logistical and time constraints, additional cases were also included through community-based case detection. In Kenya and Negros (Philippines), clusters were randomly selected through probability proportionate to size using the same cluster sampling procedure after completion of the population-based survey. Clusters were visited in advance and asked that all <span class="yellow">people</span> ≥ 50 y with vision problems come to a central point on a specified day, and that a list be made of <span class="yellow">people</span> unable to attend (e.g., due to blindness or other physical disability). After examining <span class="yellow">patients</span> at the central point, the survey team then visited those unable to leave their houses. Any identified eligible cases that agreed to be part of the study were interviewed in their homes. In Bangladesh and Antique (Philippines), community case detection was carried out simultaneously with the survey by two of the four teams, so that controls were included for these cases. Within each cluster from the survey, one interviewer was asked to be taken to two community members aged ≥ 50 y with eye problems, living within the cluster boundaries but not from the segments selected for the survey. If VA was <6/24 with pinhole in the better eye, the ophthalmologist was called to carry out the full eye examination, and eligible cases were included in the study.
For the purposes of the present analyses, control individuals with any visual impairment (VA <6/18 in the better eye) were excluded (n = 14 in Kenya, n = 53 in Bangladesh, n = 24 in the Philippines). Case and control <span class="yellow">participants</span> who were significantly communication impaired (e.g. deafness, dementia, or psychiatric disease) were excluded (fewer than five per country), and one case was excluded in the Philippines because of missing age data. One household had two eligible cases (Kenya), and one of these <span class="yellow">participants</span> was excluded for the poverty analyses as poverty was assessed through household level indicators (see below).
In total, 147 cases (82 from the survey and 65 from case detection) and 79 controls were included in Kenya; 217 cases (162 from survey and 55 from case detection) and 280 controls in Bangladesh; and 238 cases (146 survey and 92 case detection) and 180 controls in the Philippines.<br><br>Data Collection
All case and control <span class="yellow">participants</span> were interviewed in their homes by trained interviewers in the local language. Each interview lasted approximately 1 h.
Measures of poverty.
Poverty was measured through (a) monthly per capita expenditure (PCE) to indicate consumption, (b) asset ownership, and (c) self-rated wealth. The economic part of the questionnaires was adapted through interviews, focus group discussions, and pilot testing in each country to ensure local relevance.
The <span class="yellow">person</span> primarily responsible for household finances (which may have been the case/control or another household member) was interviewed to assess PCE and assets. PCE was measured using methods based on the World Bank's Living Standards Measurement Study [15]. Items were included on food (42–52 items per country), education (three items), health (five items), household expenses (nine items), and personal expenses (21 or 22 items). In total, 85 items were included in the questionnaire in Kenya, 90 in the Philippines, and 79 in Bangladesh. The informant was asked to recall the monetary value of food that was purchased, consumed from home production, or received as payment in kind or as gifts. Consumption was assessed over a 1-wk period for frequently consumed items, and this was scaled up to estimate monthly consumption. The amount consumed monthly was assessed for items that were consumed more rarely. Monthly rent was recorded among households who rented, and households who owned their property were asked to estimate the amount that they could charge in rent per month. The consumption on all items was summed to calculate total monthly household consumption, and this was converted to United States dollars (US$) at the 2005 exchange rate ($1 = 76 Kenya shillings, 64 Bangladesh taka, 55 Philippine pesos). Total monthly household consumption was divided by the number of household members to calculate monthly PCE for the household.
The household informant was also asked about the number and type of context-specific assets owned by the household, including different types of furniture, electrical equipment, <span class="yellow">cattle</span>, and vehicles. Information was collected on household characteristics, including the building material of the floor, roof, and walls; type of toilet; and the number of rooms.
Self-rated wealth was assessed by asking the household informant to rank the household's wealth relative to others in the community on a scale from 1 (poorest) to 10 (richest).<br><br>Covariates.
Case and control individuals were interviewed about standard sociodemographic indicators, including household composition, education, and employment. Information was collected on vision-related quality of life using the World Health Organization Prevention of Blindness and Deafness 20-item Visual Functioning Questionnaire [16,17], and health-related quality of life was assessed using items from the European Quality of Life Questionnaire [18]. Detailed time-use data were collected using methods based on the World Bank's Living Standards Measurement Study [15].<br><br>
Training and Fieldwork
Interviewers were trained for 1 wk, including 2 d of pilot testing. Attempts were made to minimise measurement bias by emphasising the need for consistency in data collection among cases and controls. The questionnaires were translated into the local languages (three in Kenya, three in the Philippines, and one in Bangladesh) and back-translated by independent translators (one for each language) who were also asked to comment on appropriateness of language used for the target population. A review was held to discuss differences in translation and modify accordingly. The questionnaire was piloted in each setting and small modifications to wording of some items were made, where appropriate, to ensure local understanding. Teams were accompanied by a field supervisor at least 1 d per wk to ensure that high quality was maintained and interviews were observed randomly throughout the study.<br><br>Statistical Analysis
Microsoft Access was used for data entry, and all data were double entered and validated. Analyses were undertaken in SAS version 8.2.
The mean and range of each expenditure item was calculated to assess whether answers were plausible, and to identify and exclude gross outliers (none identified). Rental equivalents were imputed based on household characteristics and non-rent expenditure for households where these estimates were missing or unreasonably low (< $1 per mo) (four in Kenya, three in Bangladesh, 18 in the Philippines). Total monthly household consumption was divided by the number of household members to calculate per capita household expenditure. Per capita household expenditure was divided into quartiles, separately for each country, based on the distribution of the data for the case and control <span class="yellow">participants</span> combined. Households with incomplete expenditure data were excluded from analyses (five cases and four controls in Kenya; one case and one control in Bangladesh).
A relative index of household assets was derived using principal components analysis (PCA) to determine weights for a list of assets and wealth indicators [19]. Variables entered into the PCA included building materials of the house, ownership of ten household assets, animal ownership, and education of the head of the household. The derived index was divided into quartiles from poorest (lowest socioeconomic status [SES] index) to least poor (highest SES index). PCA analyses were undertaken separately for each country. The means of the poverty variables were first compared for cases recruited through the two different methods, and then from cases and controls using t-tests for continuous variables (e.g., PCE and assets). For categorical variables (e.g., household rank) we used the Mann-Whitney test and presented medians and interquartile ranges. PCE was highly skewed and therefore was log transformed for the t-tests. The two-way correlations were calculated between PCE, assets, and household rank, in turn.
Logistic regression analyses were undertaken separately for each country, assessing the association between case/control status and sociodemographic and poverty variables. Conditional logistic regression was not undertaken, since the matching was incomplete, so all analyses were adjusted for the matching variables (age, sex, and rural/urban location). Likelihood ratio tests were undertaken to assess the significance of adding covariates with more than two levels (e.g., age groups, self-rated health groups) to the model. Tests for trend were undertaken across quartiles of the poverty variables and assessed using the p-value for trend. Analyses were also conducted adjusting for the logistic regression analyses for poverty by social support indicators (marital status and household size) and self-rated health, since these variables may confound the association between cataract visual impairment and poverty. Analyses from the Philippines were also adjusted for study site, since data were obtained from two settings (Negros and Antique). An attempt was made to disentangle the relationship between poverty and cataract by stratifying the analyses by age, sex, and level of visual impairment among the cases.<br><br>Ethical Approval
Informed signed or thumb-printed consent was obtained from all cases and controls. In Kenya and Bangladesh all cases were offered free cataract surgery at the local hospital, with free transport. In the Philippines, <span class="yellow">patients</span> were referred for surgery, which was subsidised for <span class="yellow">patients</span> who could not afford the fee. Ethical approval for this study was obtained from the ethics committees of the London School of Hygiene & Tropical Medicine, the Kenya Medical Research Institute, the Bangladesh Medical Research Council, and the University of St. La Salle, Bacolod, Philippines. This study complied with the guidelines of the Declaration of Helsinki.<br><br>
Results
Sociodemographic Characteristics of Cases and Controls
Case and control <span class="yellow">participants</span> were matched reasonably closely by sex and location. However, within the age category ≥ 70 y, cases tended to be older than the controls, so that cases were over-represented in the oldest age groups (75–79 and ≥ 80 y) compared to controls (Table 1). Cases were less likely to be married than controls, in Kenya (OR 0.6, 95% CI 0.3–1.1), Bangladesh (0.6, 0.4–1.0), and the Philippines (0.7, 0.4–1.0), although this only reached statistical significance in Bangladesh (p = 0.03). There was a strong protective effect of literacy and education on cataract in Bangladesh and Kenya that was not evident in the Philippines. Cases were substantially less likely to have a job other than working in the field compared to controls in all three countries. Cases reported significantly poorer self-rated health than controls—this pattern was particularly evident in the Philippines (OR for lowest versus highest quartile of self-rated health = 5.7, 95% CI 3.0–10.7) but also apparent in Kenya (2.6, 1.1–6.2) and Bangladesh (3.3, 2.1–5.3).<br><br>Summary Wealth Measures
All three settings were poor. The mean PCE was less than US$1 per <span class="yellow">person</span> per day in all three settings: US$26.4 (standard deviation [SD] = US$34.9) in Kenya, US$21.7 (US$48.0) in Bangladesh and US$26.1 (US$23.5) in the Philippines. The biggest expense was food in all three settings, making up 55% of PCE in Kenya, 47% in Bangladesh, and 64% in the Philippines, followed by household expenses including rent (21% in Kenya, 28% Bangladesh, and 22% Philippines) (Figure 1). The majority of food consumption was from direct purchase (70% in Kenya, 75% in Bangladesh, and 77% in the Philippines) or home-grown production (24% in Kenya, 22% in Bangladesh, and 17% in the Philippines), and little was from gifts or payments.
An asset score was created through PCA in the three settings. The first principal component explained 22% of the variability in asset variables in Kenya, 25% in Bangladesh, and 24% in the Philippines. Self-perceived wealth of the household clustered around the average with a large proportion of households in Kenya (48%), Bangladesh (43%), and the Philippines (64%); households stating that they were ranked between 4 and 6, on a scale from 1 to 10, in terms of wealth in their community. The three measures of poverty were highly correlated, each showing significant correlation (p < 0.001) with the other measure.<br><br>Economic and Household Characteristics of Cases and Controls
There were no significant differences in PCE, assets, or household rank between cases recruited through the population-based survey and those recruited through case detection, with the exception that the case-detection cases had lower household rank in Kenya (mean = 3.7 versus 3.1, p = 0.02). Consequently, cases recruited through the two methods were combined in the subsequent analyses.
Cases were poorer than controls, in all three settings according to all three poverty measurements (Table 2). The mean PCE was 20%–28% lower for members of households with a case than for control households, and this difference was highly significant in Bangladesh and the Philippines; for Kenya it was lower but did not reach significance (p = 0.07). The PCA score for assets was significantly lower among cases than controls in Kenya and Bangladesh, and it was lower in the Philippines although it did not reach significance (p = 0.06). Self-perceived wealth was significantly lower for households with a case compared to control households in Kenya (3.4 versus 4.5) and Bangladesh (3.9 versus 4.6), though not in the Philippines (4.1 versus 4.3).
There was no difference in the size of the households of cases and controls in any of the three settings. The ratio of dependents (i.e., household member aged <15 or ≥ 50 y) to independents (i.e., household member aged 15–50 y) was similar between cases and controls in Bangladesh (1.4 versus 1.4), but the dependency ratio was higher for controls than cases in Kenya (2.1 versus 1.6) and the Philippines (1.7 versus 1.3), due to the smaller number of <span class="yellow">people</span> of working age.<br><br>Patterns of Expenditure in Cases and Controls
Figure 1 shows the total PCE and the allocation of expenditure within quartiles of PCE for cases and controls. Monthly PCE was similar for cases and controls within each of the quartiles of expenditure. There was a gradual increase in PCE between the first three quartiles, and then a rapid increase between the third and the richest quartile. Within the first three quartiles of PCE the majority of expenditure was on food. Substantial expenditure on non-food items was observed only in the highest quartile of expenditure, where about half of expenditure was on non-food items. Similar patterns of PCE were observed for cases and controls in Kenya, Bangladesh, and the Philippines within each quartile of expenditure. These results demonstrate that cataract visual impairment was related to reduced PCE, but not allocation of expenditure.<br><br>Multivariate Analyses of Poverty and Cataract Visual Impairment
Multivariate analyses showed that case <span class="yellow">participants</span> were consistently poorer than controls in Kenya, Bangladesh, and the Philippines, using three different measures of poverty (Table 3). Cases were more likely than controls to be in the lowest quartile of PCE rather than the highest quartile in Kenya (OR 2.3, 95% CI 0.9–5.5), Bangladesh (1.9, 1.1–3.2) and the Philippines (3.1, 1.7–5.7). In all three settings these associations showed significant dose–response as assessed by the p-value for trend across the quartiles, with decreasing PCE related to case status and these relationships persisted after adjustment for self-rated health and social support indicators. A similar pattern was observed for the relationship between case–control status and asset ownership. Cases were significantly more likely to be in the lowest quartile of asset ownership rather than the highest quartile compared to controls in Kenya (3.7, 1.4–9.6), Bangladesh (2.6, 1.5–4.4), and the Philippines (2.1, 1.1–3.8). Cases were also significantly more likely to be in the lowest quartile of household rank rather than the highest, compared to controls in Kenya (3.5, 1.5–8.0), Bangladesh (2.7, 1.6–4.7) and the Philippines (2.3, 1.1–4.8). The associations with assets and household rank also showed a significant dose–response relationship, and the associations were largely unchanged after adjustment for self-rated health and social support indicators. In Kenya and Bangladesh the relationship between PCE and case status was somewhat weaker than for the other measures of poverty, while the reverse was true in the Philippines.
Stratifying the association between PCE and cataract visual impairment by level of visual impairment showed an inconsistent pattern (Table 4). In Kenya, the association with low PCE was somewhat stronger comparing cataract blind cases to controls (OR 3.1, 95% CI 0.9–10.8) than comparing moderate visually impaired cases to controls (1.8, 0.6–5.4), while this pattern was reversed in Bangladesh (blind cases versus controls: 1.8, 1.0–3.4; moderately visually impaired cases versus controls: 3.1, 1.3–7.2). In the Philippines the association with low PCE was strongest comparing severely visually impaired cases to controls (5.9, 2.0–17.6). The association between cataract visual impairment and PCE was stronger among <span class="blue">men</span> than <span class="yellow">women</span> in Bangladesh and the Philippines, while the reverse was true in Kenya (Table 5). In Kenya and the Philippines the strongest association between cataract and PCE was among <span class="yellow">people</span> aged 70–79 y, while in Bangladesh the strongest effect was in <span class="yellow">people</span> aged over 80 y. Stratifying the association between assets and household rank with cataract by level of visual impairment, sex, or age broadly repeated these findings, and generally supported the lack of consistent pattern (unpublished data).<br><br>
Discussion
This large, multicentre population-based case–control study provides evidence that <span class="yellow">people</span> with visual impairment from cataract are poorer than control <span class="yellow">participants</span> with normal vision matched for age and sex. This pattern was evident whether poverty was measured in terms of PCE, assets, or self-rated wealth. Marital status seemed to be protective for cataract visual impairment, possibly indicating the role of social support in health-seeking behaviour. Reduced self-rated health was also strongly related to cataract visual impairment. This demonstrates the impact of poor vision on overall assessments of health and supports our previous finding of a relationship between cataract and quality of life [17].
Adjustment for marital status and self-rated health did not entirely explain the association between poverty and cataract visual impairment, suggesting that it operated through other pathways. Visual impairment could cause poverty through reduced employment opportunities. We might therefore expect to see a stronger relationship between cataract and poverty among the blind case <span class="yellow">participants</span> who may have fewer employment opportunities than among those less impaired (i.e., moderate visual impairment). Poverty may also cause visual impairment through restricted access to cataract surgery. In this case we would expect to see a stronger relationship between poverty and less severely affected cases (i.e., moderate visual impairment), as poor families may allocate money for surgery on members who are blind from cataract, so that poverty mainly restricts access to surgery among <span class="yellow">people</span> who are moderately visually impaired. The relationships that we observed between level of visual impairment and cataract were inconsistent across the three settings. Perhaps this shows that both pathways were operating or that the dynamics of the relationship between poverty and blindness vary in different settings. Levels of literacy and education were lower among cases than controls. These long-term indicators of disadvantage are unlikely to have changed after the onset of cataract. This observation provides some evidence that poverty preceded blindness in our study <span class="yellow">participants</span>.
It is frequently asserted that blindness is both a cause and consequence of poverty, but there are few empirical data to support this claim. Globally, the prevalence of blindness is five-fold higher in poor than rich countries [2], and data from Pakistan and India suggest that within countries the poor are more likely to be blind [3, 4]. Some blinding conditions are a direct consequence of poverty, notably trachoma, which thrives in poor areas lacking water and sanitation [20]. Other blinding diseases clearly contribute to poverty, such as onchocerciasis, which results in the abandonment of the fertile areas near to the rivers where the disease vector thrives [9]. A larger literature shows that poor <span class="yellow">people</span> are more likely to be ill or disabled than their richer compatriots, ranging from general disability in India, Bulgaria, and Ghana [21]; common mental disorders in Brazil, Chile, India, and Zimbabwe [22]; deafness in Brazil [23]; and tuberculosis in China [24]. There are also some exceptions such as a case-control study in Rwanda which failed to show an association between PCE and musculoskeletal impairment, perhaps because the population was almost universally poor [25].
Poverty may increase the incidence of disease, particularly preventable diseases such as tuberculosis. Poverty may also restrict access to appropriate health care and so prolong the duration of disease. A study in rural Tanzania showed that care-seeking behaviour for childhood illness is worse among poorer families than among the relatively rich families [26]. Another Tanzanian study found that <span class="yellow">people</span> with higher levels of asset ownership were more likely to obtain antimalarials even though they were less likely to be parasitaemic [27]. With respect to cataract, there is little evidence that prevention is possible, and so the main pathway from poverty to blindness is likely to be through reduced access to cataract surgical services. High health care costs may also exacerbate poverty. A study in rural China showed that ill health increases medical expenditure significantly, which detracts from expenditure on food, education, investment in farming, and participation in social activities [28]. Inability to afford cataract surgery is cited as the major barrier to the uptake of surgery in the surveys conducted in Kenya, the Philippines, and Bangladesh [6–8]. This indicates that the cost of surgery is perceived as substantial by many households, notwithstanding the problems of assessing the complex issue of barriers in the absence of in-depth qualitative interviews. Consequently, there are lower rates of cataract surgery among the poor [3].
Poverty may also limit the employment opportunities of the <span class="yellow">person</span> with disability or their household members. This pattern has been demonstrated for <span class="yellow">people</span> with <span class="yellow">HIV</span> in South Africa [29], tuberculosis in China [24], or disability in Sri Lanka [22]. An impact of blindness on reduced employment or income has been observed in Guinea [9] and India [4]. A belief that blindness reduces the employment opportunities of household members is widespread, but so far there is limited supportive evidence. There is a further complication to investigations of the relationship between cataract and poverty, as the individuals with cataract are likely to be elderly and facing multiple disabilities. Our study took account of the potential impact of multiple disabilities, as we adjusted for self-rated health, which is closely related to overall health, and this adjustment had no overall impact on our results [30].
Study Strengths
This was a large population-based case–control study, conducted in three countries, allowing international comparisons. This was the first study, to our knowledge, to relate PCE to visual impairment. We also measured assets, which reflects long-term access to resources, and self-rated wealth. We used expenditure as a proxy for income, which has aided both academic and nonacademic investigations. As one example, the notorious Chicago gangster Al Capone managed to escape prosecution for smuggling, gambling, bootlegging, and murder for years, but was eventually convicted of tax evasion, because the jury was convinced that his exorbitant expenses on clothes, furnishing, foods, and gifts were inconsistent with his claim that he had no income. Expenditure often provides a better measure of poverty than income for a number of reasons. Income may be variable by season, whereas households attempt to smooth expenditure over the year. <span class="yellow">People</span> are more comfortable sharing information about expenditure than income, and it may be a more meaningful measure than income in an agrarian society as it reflects what the household is able to command based on its current income, borrowing ability, or household savings [31]. PCE also has advantages over assets, as it may be more responsive to change, which will be important for the follow-up analyses of the study <span class="yellow">participants</span> after they have undergone cataract surgery.<br><br>Study Limitations
There are a number of limitations relating to the measurement of poverty in this study. Our analyses focus on monetary indicators of poverty, while we acknowledge that health, education, and housing are also important. We concede that it is difficult to measure expenditure accurately [32,33], but this also true for the measurement of diet and other variables, which is standard practise in many epidemiological studies. Furthermore, a large number of items were included in our measure of expenditure so that the measure was comprehensive [33]. Expenditure data were not validated through diaries or other means, although assets and self-rated wealth correlated highly with PCE. Other recent estimates of expenditure are not available from surveys conducted in these countries to allow comparison. The per capita estimates of monthly gross national income from the World Development Indicators database show somewhat higher estimates in Kenya (US$48) and Bangladesh (US$40) than our PCE derived estimates, and far higher estimates for the Philippines (US$108). This discrepancy may be reasonable, as the World Development Indicators reflect national averages, while we sampled the households with elderly <span class="yellow">people</span> in poor regions of the country, many of whom were visually impaired from cataract. PCE was calculated simply by dividing the total household expenditure by the number of household members, without inclusion of economies of scale or equivalence scales. There is no widely accepted alternative to the simple equal-sharing convention, and the majority of expenditure was on food which does not allow for economies of scale. Furthermore, there were slightly fewer <span class="yellow">people</span> of working age in the control households in Kenya and the Philippines, so adjustment for equivalence scores would be unlikely to explain the higher poverty among cases. The case and control households were of similar sizes in the three settings, so economies of scales are unlikely to have explained the differences.
There were a number of limitations relating to study design. Unfortunately, we did not record the exact numbers of cases and controls who refused to participate or were unable to communicate (believed to be fewer than five in each country), so the response rate is unknown, but was believed to be high. A variety of methods were used for case recruitment, as we were not able to obtain enough cases through the survey alone. However, cases recruited through the population-based survey and through case detection had similar poverty characteristics.<br><br>Conclusions
Our data show that <span class="yellow">people</span> with visual impairment due to cataract were poorer than controls in three low income countries, Bangladesh, Kenya, and the Philippines. The Millennium Development Goals are committed to the eradication of extreme poverty and provision of health care to poor <span class="yellow">people</span>. This study confirms an association between poverty and blindness and highlights the need for increased provision of cataract surgery to poor <span class="yellow">people</span>, particularly since cataract surgery is a highly cost-effective intervention in these settings [34].<br><br><br><br><h3>pmcA2610030</h3><span class="yellow">Human</span> genetic selection on the MTHFR 677C>T polymorphism
Abstract
Background
The prevalence of genotypes of the 677C>T polymorphism for the MTHFR gene varies among <span class="yellow">humans</span>. In previous studies, we found changes in the genotypic frequencies of this polymorphism in populations of different ages, suggesting that this could be caused by an increase in the intake of folate and multivitamins by <span class="yellow">women</span> during the periconceptional period. The aim was to analyze changes in the allelic frequencies of this polymorphism in a Spanish population, including samples from spontaneous abortions (SA).<br><br>Methods
A total of 1305 subjects born in the 20th century were genotyped for the 677C>T polymorphism using allele specific real-time PCR with Taqman® probes. A section of our population (n = 276) born in 1980–1989 was compared with fetal samples (n = 344) from SA of unknown etiology from the same period.<br><br>Results
An increase in the frequency of the T allele (0.38 vs 0.47; p < 0.001) and of the TT genotype (0.14 vs 0.24; p < 0.001) in subjects born in the last quarter of the century was observed. In the 1980–1989 period, the results show that the frequency of the wild type genotype (CC) is about tenfold lower in the SA samples than in the controls (0.03 vs 0.33; p < 0.001) and that the frequency of the TT genotype increases in the controls (0.19 to 0.27) and in the SA samples (0.20 to 0.33 (p < 0.01)); r = 0.98.<br><br>Conclusion
Selection in favor of the T allele has been detected. This selection could be due to the increased fetal viability in early stages of embryonic development, as is deduced by the increase of mutants in both living and SA populations.<br><br><br><br>Background
The methylenetetrahydrofolate reductase enzyme (MTHFR) catalyzes a reaction that produces 5-methyltetrahydrofolate (5-methylTHF), the methyl donor for homocysteine in the synthesis of methionine. The 677C>T mutation of the MTHFR gene has been associated with a thermolabile enzyme with decreased activity that may cause an increase in plasma homocysteine concentrations [1] when folate status is poor. This polymorphism is one of the most widely studied clinically relevant polymorphisms in <span class="yellow">humans</span>, as it is related to cardiovascular disease [2] and neural tube defects (NTD; 601634) [3].
A large number of studies have provided a broad overview of the prevalence of the 677C>T polymorphism in different <span class="yellow">human</span> populations, showing that the distribution of frequencies is diverse [4]. These differences have been also observed between groups of different ages in the same Spanish population (older and younger than 24 years) [5] and in a Swiss population (older and younger than 60 years) [6], as well as in a Japanese population [7].
In some populations, such the Toscanians in Italy [8] and Mexicans [9], the homozygous mutated genotype (TT) has reached frequencies greater than 30%. On the other hand, in Africans the frequency of the TT genotype is very low (less than 1%) [10,11], but, in African-Americans, it has already reached 2% [12]. Studies based on the distribution of genotypic and allelic frequencies of the 677C>T polymorphism and the 1298A>C polymorphism in the MTHFR gene in Israeli, Japanese and Ghanaian Africans populations [13] concluded that the 677T mutation in the MTHFR gene emerged as a founder haplotype with some selective advantage. Recently, preliminary evidence of genetic selection of this polymorphism related to folate intake has been reported [14].
The aim of the present study is to analyze the changes in frequencies of the 677C>T polymorphism during the 20th century and particularly the evolution of the frequencies during the decade of 1980–1989, by comparing the genotype frequencies between living subjects born in this period versus samples of spontaneous abortions (SA) that occurred during in the same time period.<br><br>Methods
Subjects
This study was approved by the Ethics Committee at the University Hospital "Virgen de la Victoria" (Málaga). One of the study groups consisted of 344 fetal tissue samples from SA, obtained from the Department of Pathology of the University Hospital Carlos Haya (Málaga). These samples were selected after checking the clinical history and by the inclusion criteria of containing histologically confirmed fetal tissue collected in the 1980s from SA at less than 3 months (11 ± 1.70 week) and of unknown etiology. These fetal samples were compared with a control population of 276 subjects born in the 1980s with an average age of 22 ± 4.58.
Another population of subjects born in the south of Spain in the 20th century were genotyped (1305 subjects, 697 <span class="yellow">women</span> and 608 <span class="blue">men</span>) and divided into four groups according to birth date: 1900 to 1925 (n = 206); 1926 to 1950 (n = 320), 1951 to 1975 (n = 408), 1976 to 2000 (n = 371). Individuals were selected randomly from different areas of the province of Malaga, in southern Spain, and from different social statuses to avoid a selection bias. All the selected individuals were Caucasian and residents of the study area. The parents of all subjects included in the study were also Caucasian and born in Spain. The possibility of a founder effect or genetic drift was investigated and rejected. All the selected individuals were also genotyped for an insertion/deletion polymorphism in the angiotensin converting enzyme (ACE) gene and/or the 2756A>G polymorphism in the methionine synthase gene (MTR), in order to determine whether or not our adult and young populations were genetically homogeneous. No significant differences were observed in allelic or genotypic frequencies for these genes between the different groups.
The population studied was randomly selected according to age. Subjects 0–12 years old were selected from dried blood spots from neonatal screening papers; subjects 10–24 years old were recruited from students in primary and secondary schools and in university; subjects 25–50 years old and >51 years old were recruited using their Andalusia Health Service identity cards. After approval by the University Hospital Ethical Committee, all the subjects were contacted, and, from those whose written consent was obtained, 10 ml of blood was taken. The investigation in this study conforms to the principles outlined in the Declaration of Helsinki.<br><br>Genetic analysis
The fetal samples were extracted from the archived formalin-fixed, paraffin-embedded tissue sections. Genomic DNA was extracted from fetal tissue using the method described by Coombs et al. (1999) [15]. Genomic DNA of the second and third groups was extracted from peripheral leukocytes using the AquaPure Genomic DNA Blood Kit (Bio-Rad).
Genotyping was performed using Real Time PCR with allele specific Taqman® probes and primers described by Ulvik et al. (2001) [16] and the following optimized protocol for 45 cycles: 10 s – 94°C, 40 s – 54°C, 15 s – 72°C. The PCR mix (25 μl total volume) consisted of 5 μl of genomic DNA, 0.5 μl of sense primer, 0.62 μl of anti-sense primer, 0.85 μl Taqman® probe FAM, 0.43 μl Taqman® probe TET, 20 μl PCR-buffer iQ-SupermixTM (Bio-Rad) (containing 100 mM KCl, 40 mM Tris-HCl, (pH 8.4) 1.6 mM dNTP (dATP, dCTP, dGTP and dTTP), iTaq® polymerase (50 units/mL) and 6 mM MgCl2) and 17.75 μl H2O.<br><br>Statistical and mathematical analysis
All samples were genotyped, and the allelic and genotypic frequencies were compared. Differences were analyzed statistically using the chi-square test or Fisher's exact test. Correlations are expressed using Pearson's coefficient (r).
Compliance of genotype distributions with Hardy-Weinberg (HW) equilibrium was evaluated by chi-square analysis. For all tests, a p-value < 0.05 was considered to be statistically significant. Values are expressed as the mean ± SD.
The genetic selection model was calculated for the evolution of the 677C>T genotypes. The genetic selection could be classified as codominant or incompletely dominant and directional with the heterozygous genotype having an intermediate fitness. For this kind of selection, the most appropriate mathematical model is dq = [spq(2hp+q-h)]/[p2 + 2pq(1-hs) + q2 × (1-s)], where dq is the change of frequency of the allele with lower fitness, s is the fraction of that genotype lost to selection, h is the degree of dominance (between 0, for no dominance and 1, for complete dominance), and p is the frequency of the allele with higher fitness.<br><br>
Results
We analyzed the genotype frequencies of the 677C>T polymorphism in a population born during the 20th century. A total of 1305 subjects were divided into four groups of 25 years according to birth date. The genotype frequencies were compared between the four quarters of the century and showed very significant changes (p < 0.001) in the group born in the last quarter of the 20th century (1976–2000), when compared to any of the other groups. The changes show a decrease of the CC genotype and an increase of the TT genotype in the last 25 years of the 20th century. (Table 1)
Considering that each 25 year period corresponds to a generation, allelic frequencies did not change during the first 75 years of the century (HW equilibrium). However, we found that allelic and genotypic frequencies for the 677C>T polymorphism in the last quarter of the century are significantly different compared to the previous generation (1951–1975). The genotype frequencies in the last quarter of the century are not the expected by a HW calculation using the allelic frequencies of the previous generation. This could be described as a consequence of genetic selection found in this population, in the absence of other causes. Applying the mathematical model described above to our population, the calculated fitness (s) is 0.5, and it can be predicted that both alleles will be approximately at a frequency of 50% in the next generation and allele T will be at 90% after seven generations (Figure 1A). Another possibility is that a scenario could be predicted in which both alleles will have frequencies of about 50% in the next generation and that they will maintain this stability while conditions remain unchanged. (Figure 1B)
The comparison of the genotype frequencies between a group of fetal samples from SA that occurred during the 1980–1989 decade and living subjects born in the same decade showed significant differences in genotype frequencies (p < 0.001). CC genotypes were almost absent in abortion samples compared to living subjects (0.03 vs 0.33), while CT and TT genotypes were overrepresented in the same group. When 3-year periods are studied in the decade, we detected a significant increase of the mutated subjects during the decade (CT p < 0.05; TT p < 0.01). Allele frequencies showed the same pattern (p < 0.05). Controls showed the same tendency but without statistical significance. (Table 2)
The evolution of genotype frequencies during the 1980–1989 decade of the TT genotypes correlates well in both living populations as well as fetal samples r = 0.98 (p = 0.11).<br><br>Discussion
Different reports show that the prevalence of the 677C>T polymorphism of the MTHFR gene differs dramatically among <span class="yellow">human</span> populations. Evidence of this dynamism can be observed in many reports: frequency variations between populations that are geographically very close, even in the same country [8]; changes found in the same race or ethnic group such as Africans [10,11] and African-Americans [12]; the high prevalence of the 677C>T poymorphism in populations with special nutritional features such as Mexicans [9] and Japanese [13]; and changes in frequencies between generations of the same population, as has been observed in Spain [5], Switzerland [6] and Japan [7].
There are numerous interpretations of this great diversity, and most tend to be related to adaptation to external conditions such as climate or nutritional status. Dependence of folate degradation on skin pigmentation [17], nutritional habits or <span class="yellow">human</span> intervention periconceptional periods could explain this genetic variation. Definitely, external factors in combination with different levels of MTHFR enzyme activity, conditioned by polymorphisms, could influence the fetal viability of certain genotypes.
In 1998, we suggested the possibility of genetic selection in Spain in favor of the mutants of the 677C>T polymorphism in the MTHFR gene based on the fact that treatment with vitamins and folates during pregnancy increased the viability of fetuses with the TT homozygous genotype. This hypothesis was based on the increase in the number of mutated individuals found in our population since the mid-1970s [5] and the coincident increased intake of vitamins and folate by pregnant <span class="yellow">women</span> in Spain [18,19]. In 2002, a new study found changes in genotype frequencies for the 677C>T and 1298A>C polymorphisms in different age groups. Total homocysteine (tHcy) levels in plasma were also analyzed according to the different genotype interactions [20]. That study hypothesized about fetal viability and about a genetic selection model on the basis of non-linkage disequilibrium between both polymorphisms. Recently, a study with fetal and control populations showed the strong influence of these polymorphisms, though mainly of the 677C>T polymorphism, on spontaneous early abortion [21]. In the present study, significant changes in allelic and genotypic frequencies are detected, as is Hardy-Weinberg disequilibrium, at the 677C>T polymorphism. We hypothesize that there is a dynamic process of genetic selection that favors the T allele. This process of selection started during the last quarter of the 20th century, during which the frequency for mutant homozygous (TT) rose significantly from 14% to 24%. We propose that this increase in mutants is due to the inclusion of an external factor that enhances mutant fetal viability.
If we apply the mathematical model for dynamic selection developed for diploid organisms with sexual reproduction, the T allele could reach to 90% in seven generations in our population (Figure 1A). However, this model assumes selection in a constant environment that applies to all individuals in the population studied. In our case, we suggest that the external factor is related to an increase in folate and vitamin intake in <span class="yellow">women</span> in periconceptional period and does not affect to all individuals [18,19]. We assume that prediction of a classic selection model in this case is only theoretical.
On the basis of a competition between alleles in which an environmental factor favors one allele versus the other, the final result would be that predicted by the previous mathematical model. However in this case, the environment is not selecting against the wild type allele but rather allowing the survival of more mutated alleles. Therefore, the expected result would be not a systematic increase of the mutated allele but the creation of an allelic balance dependent on vitamin and folate abundance conditions. In this case, the mutation would have a lower influence on fetal viability (Figure 1B).
The results showed an increase in mutated genotypes (CT and TT) and a strong protection against abortion by the wild type genotype (CC), which is practically non-existent in the SA group. The frequency of the CC genotype shows no change over the decade studied (1980–1989), which indicates that folate does not exert a visible effect on this genotype. However, the frequency of the mutated allele increases during this decade, especially in fetuses from abortions, and this increase correlated with the increase of the T allele in the control population. This finding suggests that the effect of folate is crucial to viability during the early stages of embryonic development, but, even with folate, not all embryos will survive until birth.
In this population, the mutant allele with lower enzymatic activity has higher fitness than the wild type. In the folate cycle, it can be observed that 5,10-methyleneTHF availability may be important. 5,10-methyleneTHF is the substrate for several reactions in the cycle, but two of them (5-methylTHF and thymidilate synthesis) might be essential for embryo development in folate deficiency conditions.
In both cases, complete or limited MTHFR activity will produce higher or lower 5,10-methyleneTHF availability, which might be an essential factor for embryo development, such that a greater folate levels can compensate the lower enzymatic activity of the mutant.
The implications of this polymorphism in nucleotide synthesis have not yet been determined, but certain data, such as high levels of uric acid found in mutated subjects [22,23], suggest that there are different turnover rates associated with different polymorphisms.<br><br>Conclusion
We suggest that there is genetic selection in our population for the T allele of the MTHFR – 677C>T polymorphism, whose origin could be an increase in fetal viability during the early stages of embryonic development because of an increase in folate and vitamin intake by <span class="yellow">women</span> in the periconceptional period that began to be established in Spain in the last quarter of the 20th century [18,19]. Higher frequencies for the T allele and TT genotype in our population are observed in the living and SA populations.<br><br>Competing interests
The authors declare that they have no competing interests.<br><br>Authors' contributions
AMO performed the statistical analysis, helped to draft the manuscript and revised it for publication. GC is the corresponding author, participated in the acquisition of samples and carried out the genotyping. ARP carried out the bibliographic search and helped to draft the manuscript. AJJ participated in the selection and the processing of samples. MJG coordinated the laboratory work and selected the genotyping method. AR selected the control subjects and designed the consent form. MR helped in the interpretation of data and tables performance. ARE conceived the study and is the guarantor of this work and the general coordinator. All authors read and approved the final manuscript.<br><br>Pre-publication history
The pre-publication history for this paper can be accessed here:<br><br><br><br><h3>pmcA1036069</h3>In spite of medical help: the puzzle of an eighteenth-century Prime Minister's illness.
Abstract<br><br><br><br><br><br> Medical History, 1990, 34: 178-184. <br><br> IN SPITE OF MEDICAL HELP: THE PUZZLE OF AN <br><br> EIGHTEENTH-CENTURY PRIME MINISTER'S <br><br> ILLNESS <br><br> by <br><br> MARJORIE BLOY * <br><br> Charles Watson Wentworth, second Marquis of Rockingham, died suddenly and unexpectedly on 1 July 1782, when he was only 52 years old. He had suffered-or enjoyed-ill health all his life but in 1782 appeared to be no worse than he had ever been. His death in London terminated his second period of office as Prime Minister, to which he had been appointed only 14 weeks earlier. In May he had reported to the Duke of Portland that he had "for some weeks past undergone much Pain and much inconvenience from something similar to my old Complaint in my Side and Stomach" but that he felt much better than he had.' By 17 June he was recovering from both influenza and his "old complaint".2 On 1 July he died and on the 20th he was interred in York Minster. <br><br> The first recorded bout of illness suffered by the marquis, then Lord Higham, was in July 1741 when the 11-year-old was "a little indisposed, something Feaverish I guess it proceeds from Worms and will Soon be removed".3 He also had a rash and it was thought that the cause of the problem was that the <span class="yellow">boy</span> had overheated himself.4 He was still ill at the beginning of August: he had been "much out of order" for a long time but had been recommended to take warm baths by Dr Wilmot and Mr Ranby when they were consulted in London.5 Charles's aunt, Lady Isabella Finch, was sure that the baths "and other Things They'll prescribe will in a short Time entirely Cure his Complaints w[hic]h neither of Them thought proceed from any dangerous Causes".6 In spite of Lady Isabella's hopes, Charles did not greatly improve, even though his mother believed that he continued mending every day. The main reason that Higham and his mother had gone to London to consult Dr Wilmot and Mr <br><br> *Marjorie Bloy, Ph.D., 18 Farm View Road, Kimberworth, Rotherham, S. Yorks. S61 2BA. <br><br> The Rockingham Papers are in the holdings of the Wentworth Woodhouse Muniments at Sheffield City Archives Department, Sheffield City Library. I am grateful to Dr R. S. Morton for his advice and help with the diagnostic sections of this essay. <br><br> 'WWM, RI-2094. Rockingham to Portland, 25 May 1782. <br><br> 2WWM, RI-2094. Rockingham to Charlemont, 17 June 1782. 3 WWM, M8-25. Malton to Nottingham, after 16 June 1741. 4 WWM, M8-26. Lady Finch to Lady Malton, 30 July 1741. 5 WWM, M8-28. Winchelsea to Malton, 7 August 1741. 6 WWM, M8-29. Lady Finch to Malton, 7 August 1741. <br><br> 178 <br><br> An eighteenth-century Prime Minister's illness <br><br> Ranby was his mother's concern about a "swelling in a certain part which was larger than when we left Wentworth". The doctors hoped that it would burst outwards "which they assure me will be the safest way and give the poor Monkey but very little pain' 7 <br><br> On 20 August Lord Winchelsea, Higham's uncle, surprised to see the <span class="yellow">boy</span> so well and brisk, hoped that Charles was "now safe from this complaint"-the same one from which he had suffered in 1738-39-but thought that he would never be safe "if he continues the practice of overheating himself and then drinking Cold Water". He said that Charles was of a "pretty healthy strong Constitution";8 Lady Malton was not so sure. The same day she wrote a progress report to her husband saying that Charles's swelling continued to grow, as did the pain "in that part (but not the lease [sic] trouble in making Water or going to Stool) & less Fever than c[oulJd be imagined where Matter is as they now imagine certainly gathering and must end in an operation". In spite of it all, Charles was in fine spirits.9 Lady Malton dosed the <span class="yellow">boy</span> with <span class="yellow">cinchona</span> bark, which removed the pains in his legs and reduced his fever, and she was convinced that they would soon have "a clear Stage to act in a proper manner a[bou]t his other Complaints w[hic]h the Learned assure me are to be conquered also". 10 Charles was soon allowed to eat meat and Mr Ranby still assured her that the swelling would break outwards. 1 " Three days later he decided to lance it, even though Dr Bourne disagreed. The <span class="yellow">boy</span>'s mother was puzzled because the swelling "sometimes pushes forward very fast then retires a little" but the doctor and Ranby seemed happy with his condition.'2 At this point the letters cease, presumably because Malton arrived in London with his daughters, to have them inoculated against <span class="yellow">smallpox</span>, but a later letter states that surgery to open the swelling was not undertaken. 13 <br><br> By the end of October the correspondence had recommenced. Charles was ill again. He was just the same as when he left Kensington, so John Bourne had bled him and the <span class="yellow">child</span> had started on Sir Edward Hulse's prescription, unfortunately not defined in the letter, but which was apparently as bad as the last one, if not worse. Lady Malton thought that "with such a State of Blood the Continuation of Health cannot be expected" but was hopeful that the "Cinnabar may prove a more Efficacious remedie than any than has been tryed yet""."4 That night she applied "a Blister ... without the least Symptom or tendency to anything like Strangury". He bore the treatment well, as he had done three years previously, and it seemed so successful that Lady Malton was "determined to keep it running full as long as I did last time by the help of John Borne [sic] with much ease to the Dear <span class="yellow">Child</span>".'5 She <br><br> 7 WWM, M7-51. Lady to Lord Malton, 18 August 1741. 8 WWM, M2-84. Winchelsea to Malton, 20 August 1741. 9 WWM, M7-52. Lady to Lord Malton, 20 August 1741. '0 WWM, M7-53. Lady to Lord Malton, 25 August 1741. <br><br> WWM, M7-54. Lady to Lord Malton, 29 August 1741. <br><br> WWM, M7-55. Lady to Lord Malton, 1 September 1741. <br><br> 3 WWM, R170-20. Nicol6 Scanagati of Padua, 20 July 1750. I am grateful to Fr John McMahon and Dr Stephen Bemrose for their translations of this letter. <br><br> 4 WWM, M7-14. Lady to Lord Malton, 31 October 1741. <br><br> 5 WWM, M7-19. Lady Malton to Lady Finch, 2 November 1741. <br><br> 179 <br><br> Marjorie Bloy <br><br> continued with the blister and applied "ointment with flyes", apparently some sort of irritant potion, with no sign of strangury. Charles found her treatment "not near the pain he expected" and she was "full of hopes that he will rec[eiv]e great benefit from it".1 <br><br> Apart from his other troubles, one of Charles's knees had swollen but this had much abated since the application of the blisters which Lady Malton believed "must be acting upon the whole Mass of Blood" since it had "reached the remote part". She thought that Sir Edward Hulse's powders were too slow in taking effect although the <span class="yellow">boy</span> took them very quietly.'7 Sir Edward did not "apprehend any great danger from the Siziness [thickness] of Charles' blood"; Lady Malton thought that the condition was the cause of all the <span class="yellow">child</span>'s problems, which would not end until it was set to rights. At any rate, he was fit enough to go hunting.'8 Charles continued in the same state of health. He slept well at night, ate more than his mother thought was good for him, and was able to exercise strenuously without tiring. He put on no weight though, and "as for them swellings at his throat, they are almost gone one day and rise the next". His mother did not expect a speedy recovery and "if the D[octo]rs think him in a good state of health now, I s[houl]d be glad to see him in a better".'9 He began to improve and by the end of November even she thought he was on the mend and gaining weight.20 Unfortunately, Lady Malton again had cause for concern over his health in January 1742 when he began to suffer from an intermittent hoarseness.2' Otherwise he was as well as one could expect, with no other complaints.22 It was not to last. <br><br> In May 1742 Charles and his mother were again in Bristol, taking the waters because he had been indisposed. Lady Malton thought the waters were doing them good because they were both being violently sick.23 However, Charles had had no dinner on 25 or 26 May and was hot, lazy, and inclined to stir, "from which I conclude he is not well, . . . and therefore Intend to give him a gentle Vomit ... and to let him take his old Remedie the Salt Draughts for a few Daies which I dare say will set him quite to rights".24 By 29 May Dr Boume had bled the <span class="yellow">boy</span> "which succeeded very well but ... found it [his blood] as bad as ever". The waters were not working "but there is a great deal for them to do which grant God they may effect". The weather had turned warm so Lady Malton had "shorn him ... which has display'd a most scabby head and indeed several other untoward Blotches he has out upon other parts of his Body", which made her uneasy.25 The blotches on his head were not numerous "yet they made up in quality for so virulent a Corrosive Humour is not easily conceived without seeing it". The pustules on his body were of the same sort <br><br> 16 WWM, M7-17. Lady to Lord Malton, 4 November 1741. 7 WWM, M7-18. Lady to Lord Malton, 4 November 1741. 18 WWM, M7-16. Lady to Lord Malton, 7 November 1741. '9WWM, M7-15. Lady to Lord Malton, 9 November 1741. <br><br> 20 WWM, M7-22. Lady to Lord Malton, 25 November 1741. 21 WWM, M7-1. Lady to Lord Malton, 25 January 1742. <br><br> 22 WWM, M7-4. Lady to Lord Malton, 8 February 1742 and WWM, M7-9. Lady to Lord Malton, 22 February 1742. <br><br> 23 WWM, M7-29. Lady to Lord Malton, 12 May 1742. 24 WWM, M7-35. Lady to Lord Malton, 26 May 1742. 25 WWM, M7-36. Lady to Lord Malton, 29 May 1742. <br><br> 180 <br><br> An eighteenth-century Prime Minister's illness <br><br> and his mother intended to put plasters on them to prevent them from spreading. Charles was also feverish; his glands were swollen and his pulse was erratic "but out of compassion to you I must tell you that he is with me as Brisk and lively as you ever Saw him". Lady Malton had called in two eminent Bristol <span class="blue">men</span>, Dr Logan and Mr Pye, to treat the <span class="yellow">boy</span>; Mr Pye prescribed "the Precipitate Per se" as the cure for the "hectic". Pye made it himself and said that it was the only remedy that would work. Clearly Charles was impatient to be cured because he told his mother to give him the medicine "to cure me which I am sure it will do or shoot me through the head at once". She thought that this attitude was "odd from one of his Age and [it] does not a little disturb".26 The blotches began to burst and indent but the doctor thought that all would be well in the end.27 Meanwhile, Charles was still losing weight even though "he had none to spare before" and he was inclined to be lazy which was not his natural turn. His father recommended some unknown cure which he called Gascoin's Powder-a dose of five grains made up with syrup into a pill-every night. <br><br> To make matters worse, the doctors disagreed about the treatment. "Dr Pye is Vehemently for the P. Per se, Dr Logan saies that it is a Medicine that may prove too rough in its operation for his Constitution & therefore begs a tryal of Beazor mineral [gall stones from a <span class="yellow">goat</span>] and Viper Broth". The Bristol water had not yet acted "because his case is of too obstinate a Nature" and Lady Malton herself was satisfied that since nothing else had worked to cure the <span class="yellow">boy</span>, the time had come to try mercurials, even though she knew that they were "powerful and perhaps in some cases hazardous medicines".28 She wanted to see some remedy succeed but was "afraid of violent ones and at the same time vastly distrustfull [sic] of mild ones". It would appear that the "precipitate Per se", probably mercury-based, could be a kill-or-cure remedy. Her "terrors" did not arise from any immediate danger to her son, and her "perfect Knowledge" of his disorder convinced her that whatever remedies he took, the cure was in the hands of God.29 <br><br> To add to Charles' disorders, on 12 June he developed a "very inflamed bad Eye ... the same Eye that ... he did not see so well of [as] the other ... He sais [sic] that from that eye Alone he can Scarcely distinguish anything". The doctors suggested bathing the eye: Lady Malton knew that the "frightful symptoms" which were "shocking to behold" were a result of "the Same as produces all the rest of his complaints in whichever Shape they appear". 30 The eye was very bloodshot and inflamed; the eyelid was swollen so he could hardly open it. The other eye was dull and "he had very little sight of it".31 By 14 June the eye problem had eased somewhat but Lady Malton could find no cause to attribute the improvement to any of the "cures". Charles was still being subjected to Bristol water, Beazor mineral, Viper broth, cinnabar and the precipitate per se.32 She decided to take the <span class="yellow">boy</span> home to Wentworth because he was <br><br> 26 WWM, M7-38. Lady to Lord Malton, 1 June 1742. 27 WWM, M7-39. Lady to Lord Malton, 2 June 1742. 28 WWM, M7-41. Lady to Lord Malton, 5 June 1742. 29 WWM, M7-43. Lady to Lord Malton, 7 June 1742. <br><br> 30 WWM, M7-45. Lady to Lord Malton, 12 June 1742. <br><br> 31 WWM, M7-56. Lady to Lord Malton, undated: 12 June? 1742. 32 WWM, M7-46. Lady to Lord Malton, 14 June? 1742. <br><br> 181 <br><br> Marjorie Bloy <br><br> more likely to recover there than anywhere else.33 He still ate and slept well and was "pretty cheerful but his looks are bitter bad still. The flesh he lost in the Accidental Feavour he has not Recover'd and his complexion is of the most sickly sort his hands of the same Hue his legs are tollerable [sic] well".34 <br><br> They returned to Wentworth in short stages and by 6 September Higham was "perfectly recovered . . . after the long and successful Care that Lady Malton has taken" of him.35 In May 1743 he was inoculated against <span class="yellow">smallpox</span> and made a perfect recovery after which he caught cold "by stripping when He was hot".36 Lord Higham does not seem to have been seriously ill after that until, at the age of 19, he undertook his Grand Tour in 1749. <br><br> In July 1750, by then Lord Malton, he had cause to consult Nicolo Scanagati in Padua for the treatment of gonorrhoea. Scanagati produced a lengthy medical report of Malton's treatment, presumably for his English doctor's enlightenment.37 The initial treatment was an "electuary, consisting of three ounces of emollient, three drams of powdered <span class="yellow">jalap</span>, a half [dram] of purified nitre, bound together with <span class="yellow">lemon</span> juice taken twice a day". The result was satisfactory: "The dark greenish poison was oozing slowly from his penis, which was all contracted and the sharp and constant pain extended from the perineum up to the urinary bladder, producing small swellings now in this place, now in that." There was a fierce burning sensation in the glands, which prevented him from sleeping. Because of this, it seemed reasonable to bathe that part in tepid water and milk, and to apply poultices to the areas affected by swelling and contractions, together with cold drinks and a few grains of laudanum at night. <br><br> Malton was blooded regularly besides being given purgatives; the treatment then moved on to the administration of mercury, both internal and on the gums, since it was widely believed at the time that gonorrhoea and syphilis were steps of the same disease, "the Venereal". Scanagati at this point ruled out the suggestion of syphilitic chancre because Malton's urine was fine and light with a pungent odour. Scanagati did ask if Malton had previously ever had a similar peculiarity of his urine. Malton replied that when he was very young and still inexperienced sexually, for some time following a fever he had had the same unusual urine, and indeed that on one occasion this symptom coincided with certain tumours on the testicles. It was only by chance that he had not had recourse to surgery, the reason being that he was also afflicted with a throat infection-to which he was prone-and therefore had his vein opened four times. Thereupon the inflammation subsided, and equally the tumours and sediment disappeared. <br><br> He told me that as a youth he had sometimes experienced some difficulty and a burning sensation when urinating, which subsided when his blood was let and with the application of poultices. I observed that from time to time his face and body were covered with purplish spots, which, having produced a little fluid, would disappearas indeed happened in the course of the cure, at the end of which his face was entirely <br><br> 33 WWM, M7-47. Lady to Lord Malton, 15 June 1742. 34 WWM, M7-48. Lady to Lord Malton, 16 June 1742. <br><br> 35 WWM, M2-104/5. Lady Finch to Lady Malton, 6 September 1742. 36 WWM, M2-135. Lady Finch to Malton, 18 June 1742. 37 WWM, R170-20. Nicol6 Scanagati's report. <br><br> 182 <br><br> An eighteenth-century Prime Minister's illness <br><br> free from these spots. From this observation, it seemed to me simple to deduce both the original cause and the more immediate cause of the said sediment: namely a natural complexion of humours which are exacerbated by muriatic [i.e., acidic] sourness, together with the marked inflammation of the blood and the motion of the contracted poison. <br><br> Scanagati then recommended the continuation of the electuary made of emollient, guaiacum resin, balsam, <span class="yellow">rhubarb</span>, and nitre. <br><br> What does all this add up to in terms of diagnosis? The early illness is a mystery. Did he have an inguinal hernia; or perhaps mumps or epididymitis? His was a childless marriage. He seems to have been too fit for the illness to have been rheumatic fever. Cystitis was not uncommon and this could certainly lead to "strangury". Perhaps Rockingham suffered from a congenital defect of his urinogenitary system which would result in recurrent attacks of cystitis and might cause long-term damage to the urinary tract and eventual destruction of the kidneys, precipitating sudden and unexpected death. <br><br> Another possibility might be diabetes. Rockingham had a urinary infection and certainly suffered from recurrent skin infections, although it appears from Scanagati's report that these cleared up when mercury was administered. <br><br> Certainly the marquis complained often about pains in his side and stomach and made no secret of his "old complaint". He was noticeably less physically active as he moved into his thirties and only occasionally exerted himself by riding any distance, even though he had enjoyed hunting when he was younger. He found the pains caused by his "old complaint" made him feel so ill that he was unable to concentrate on "any Manner of Business" and on occasion it seemed likely to prevent him from attending Parliament.38 He may well have suffered from a problem with gallstones from an early age.39 He appears to have suffered from a nervous disorder which manifested itself in severe palpitations, trembling, and other types of physical discomforts such as boils and headaches with which he was frequently afflicted.40 He probably had constipation too, since he was always dosing himself with purgatives. In fact in April 1772 the Duke of Richmond decided that Rockingham's real problem was a "surfeit of physick"41 although Edmund Burke noted in June 1772 that the marquis had had a long and severe illness.42 Whatever his many and varied ailments, Rockingham survived until he was 52 in spite of the attentions of both doctors and quacks and that, for the mid-eighteenth century, was a good age. The mystery still remains, however. Contemporary opinion had it that he died of pneumonia but it must have struck <br><br> 38 WWM, R153-1. Rockingham to Burke, 31 October 1767; WWM, RI-1238. Rockingham to Dowdeswell, 20 October 1769; WWM, RI-1928. Rockingham to Savile, September 1780. <br><br> 39 Ross J. S. Hoffman, The Marquis. A study of Lord Rockingham, 1730-1782, New York, Fordham University Press, 1973, p. 35. This is the only recent biography of the second Marquis of Rockingham, and does not deal with his illnesses. Although he does not give the source of his information, Hoffman asserts that Rockingham was in Bath between March and August 1761 suffering from gallstones. The marquis would then have been 31 years old. <br><br> 40 Historical Manuscripts Commission, Lindley Wood, p. 184. <br><br> 41 WWM, RI-1403. Richmond to Rockingham, 26 April 1772. <br><br> 42 Burke to James de Lancey, 30 June 1772. The correspondence of Edmund Burke, vol. 2, ed. T. W. Copeland and others, Cambridge University Press, 1958-1978, p. 311. <br><br> 183 <br><br> Marjorie Bloy <br><br> suddenly: it was only two weeks from him "recovering" to dying. Another almost contemporary account of the marquis's death came from the Earl of Albemarle. He noted that Rockingham had "for some time past been afflicted with water on the chest: and to this well-known malady was superadded the then novel disease of influenza".43 This conceivably could be an uninformed account, handed down orally by surviving members of the marquis's family, of emphysema. More fascinating than the diagnosis of the cause of death, however, is - what was wrong with him during his lifetime? Or is it yet another example of the "English disease": hypochondria? <br><br> 43Albemarle, George Thomas, Earl of, Memoirs of the Marquis of Rockingham and his contemporaries, London, Richard Bentley, 2 vols., 1852, vol. 2, p. 483. This is the only contemporary work concerning Rockingham, but does not mention his early life and illnesses. <br><br> 184 <h3>pmcA140144</h3>Gender differences in factors influencing insulin resistance in elderly hyperlipemic non-diabetic subjects
Abstract
Background
The increase in the prevalence of insulin resistance-related metabolic syndrome, a disorder that greatly increases the risk of diabetes, heart attack and stroke, is alarming. One of the most frequent and early symptoms of metabolic syndrome is hypertriglyceridemia. We examined the gender differences between various metabolic factors related to insulin resistance in elderly non-diabetic <span class="blue">men</span> and postmenopausal <span class="yellow">women</span> of comparable age suffering from hypertriglyceridemia, and compared them with healthy subjects of equal age.<br><br>Results
The indexes of insulin resistance HOMA IR and QUICKI were significantly higher in both hyperlipemic <span class="blue">men</span> and <span class="yellow">women</span> than in controls; 95% confidence limits of hyperlipemic subjects did not overlap with controls. In both normolipemic and hyperlipemic <span class="blue">men</span> and <span class="yellow">women</span> serum leptin correlated significantly with insulin resistance, while HDL-cholesterol correlated inversely with HOMA-IR only in <span class="yellow">women</span> (both normo- and hyperlipemic), and serum tumor necrosis factor α (TNFα) only in hyperlipemic <span class="yellow">women</span>. According to results of multiple regression analysis with HOMA-IR as a dependent variable, leptin played a significant role in determining insulin resistance in both genders, but – aside from leptin – triglycerides, TNFα and decreased HDL-cholesterol were significant determinants in <span class="yellow">women</span>, while body mass index and decreased HDL-cholesterol were significant determinants in <span class="blue">men</span>. The coefficient of determination (R2) of HOMA IR by above mentioned metabolic variables was in <span class="yellow">women</span> above 60%, in <span class="blue">men</span> only about 40%.<br><br>Conclusion
The significant role of serum leptin in determination of insulin resistance in both elderly <span class="blue">men</span> and postmenopausal <span class="yellow">women</span> of equal age was confirmed. However, the study also revealed significant gender differences : in <span class="yellow">women</span> a strong influence of triglycerides, TNFα and decreased HDL-cholesterol, in <span class="blue">men</span> only a mild role of BMI and decreased HDL-cholesterol.<br><br><br><br>Background
In association with pandemic obesity the prevalence of the insulin resistance-related metabolic syndrome is constantly growing [1]. As a consequence of this fact, type 2 diabetes mellitus and cardiovascular mortality occurs in much younger age groups [2]. A typical hyperlipemia, consisting of an increase of serum triglycerides and a decrease of serum HDL-cholesterol, is a characteristic and an early symptom of this syndrome [3].
With increasing age, body mass index (BMI) and adiposity, insulin sensitivity declines and the number of cardiovascular risk factors increases in both genders [4-6]. It was repeatedly demonstrated that plasma concentration of leptin – a hormone produced mainly by adipose tissue – is substantially higher in all age groups of <span class="yellow">women</span> than in <span class="blue">men</span> [7-10]. This may be caused by different size and/or distribution of fat tissue compartments influenced by hormones: estrogens stimulate, whereas testosterone inhibits leptin secretion. In <span class="yellow">women</span> subcutaneous fat mass prevails – and during augmentation of overweight it increases – while in <span class="blue">men</span> intra-abdominal fat mass prevails [11-13]. Subcutaneous fat in particular serves as a substantial source of tumor necrosis factor α (TNFα), which represents one of the factors that interfere with insulin signal transduction into the cells [14-16]. Leptin, TNFα and some other factors are abundantly expressed in adipose tissue and contribute to the insulin resistance that accompanies overweight and obesity. Leptin correlates positively with hyperinsulinemia, BMI, fat mass and hypertriglyceridemia, respectively, and correlates inversely with HDL-cholesterol and lean body mass [17-25].
The incidence and mortality of ischemic heart disease and of other consequences of atherosclerosis increases with age in both genders, especially after the age of sixty. In premenopausal <span class="yellow">women</span>, however, the incidence of these disorders is considerably less frequent than in <span class="blue">men</span> of appropriate age. After the menopause the prevalence of metabolic syndrome and cardiovascular mortality in <span class="yellow">women</span> gradually increases, attaining values comparable to <span class="blue">men</span> at about the age of 70 [2,26]. Paradoxically, it takes place at the time when serum leptin concentration in <span class="yellow">women</span> has relatively decreased [27,28].
The aim of this study was to analyze the interrelations between several metabolic variables and factors related to insulin resistance in groups of both normal and hyperlipemic postmenopausal <span class="yellow">women</span> and <span class="blue">men</span> of appropriate age, and to attempt to elucidate the gender differences and some pathophysiologic mechanisms of these differences. We compared homeostatic indexes of insulin resistance HOMA IR and QUICKI, serum lipid and insulin parameters, uric acid, leptin and TNFα between groups of subjects without apparent symptoms of metabolic syndrome, and groups showing mild hypertriglyceridemia with decreased HDL-cholesterol. In addition, serum concentration of the heart fraction of fatty acid binding protein (hFATP) was explored as a factor that might reflect the regulative role of PPAR gamma in lipid homeostasis [29,30], and serum IgG anticardiolipin (ACL-IgG) was investigated as an indirect indicator of oxidized lipid fractions related to atherosclerotic complications [31,32].<br><br>Methods
Subjects
The study was carried out on 70 out-<span class="yellow">patients</span> of the Metabolic Center at the hospital in Sternberk, Czech Republic. From these, 40 <span class="yellow">patients</span> (20 <span class="blue">men</span> and 20 <span class="yellow">women</span>) were selected with mild hyperlipidemia, i.e. with plasma triglyceride concentration exceeding 2.0 mmol/l, total cholesterol exceeding 6.0 mmol/l, LDL cholesterol exceeding 4.0 mmol/l, and with HDL cholesterol concentration in <span class="blue">men</span> under 1.0 mmol/l, and in <span class="yellow">women</span> under 1.2 mmol/l. These groups were denominated as "hyperlipemic". Two other groups (10 <span class="blue">men</span> and 20 <span class="yellow">women</span>) with approximately normal serum values of these variables were taken as "controls". The average age in <span class="blue">men</span> was 59.1 ± 10.6 y, and in <span class="yellow">women</span> 59.4 ± 10.1 y, respectively. The differences between lipid parameters of hyperlipemic and control groups were highly statistically significant, while the age differences were insignificant (see Table 1). None of the <span class="yellow">patients</span> had clinically apparent diabetes mellitus, but some of the hyperlipemic <span class="yellow">patients</span> exerted impaired glucose tolerance or impaired fasting glucose (values between 6.1 and 7.0 mmol/l, or between 6.1 and 7.8 mmol/l, respectively). None of the <span class="yellow">patients</span> was treated with insulin, peroral antidiabetics or antihyperlipemic drugs; some of them were treated with antihypertensive therapy. No signs of major clinical or laboratory symptoms of other diseases were present in any group of the explored <span class="yellow">patients</span>. Blood samples were obtained in the morning via a venipuncture after overnight fasting. After clotting the serum was separated and stored at -20° until used. An informed consent was obtained from all probands.
Body mass indexes (BMI), defined as weight in kilograms divided by the square of height in meters, were calculated.<br><br>Biochemical methods
Serum leptin concentrations were measured by a sandwich ELISA test kit (<span class="yellow">Human</span> Leptin ELISA, BioVendor Laboratory Medicine, Inc, Czech Republic). Its sensitivity limit was 0.2 ng/ml, intraassay CV 6.1% at the level of 7.5 ng/m, inter-assay CV 8.5% at the level of 4.8 ng/ml. Tetramethylbenzidine was used as a substrate; quality controls were <span class="yellow">human</span> based. Several other hormones and peptides were estimated by routine immunochemical tests: insulin, C-peptide, TNFα (IMMULITE, Diagnostic Products Corporation, Los Angeles, CA, U.S.A.), proinsulin intact (DAKO, Denmark), IgG anticardiolipin (ACL-IgG, IMMCO Diagnostics, Buffalo, NY, U.S.A.) and heart fatty acid binding protein (hFABP, Hbt HUMAN H-FABP, HyCult Biotechnology, Uden, the Netherlands). Serum concentration of glucose, total cholesterol, triglycerides, HDL-cholesterol, LDL-cholesterol, Apoprotein B and uric acid were measured on a ILAB-600 biochemical analyzer (Instrumentation Laboratory, Lexington, Ma, U.S.A.) using BioVendor sets. All samples were processed and examined according to principles of good laboratory practice and under constant intralaboratory and external quality control.
The homeostatic indexes of insulin resistance (HOMA IR and QUICKI) were calculated according to the homeostasis model of assessment [33-35] as follows:
HOMA IR = fasting insulin (μU/ml) * fasting glucose (mmol/l) / 22.5;
QUICKI = 1 / [log fasting insulin (μU/ml) + log fasting glucose (mg/100 ml)].<br><br>Statistics
Statistical analysis was performed using the Version 6 SAS/STAT software (SAS Institute, Inc., Cary, NC, U.S.A.). The Shapiro-Wilks tests were used in testing the normality of distribution. Some of the data obtained were not normally distributed. The statistical significance of differences between the means in the hyperlipemic and control groups were evaluated using the unpaired Student's T-test in the case of normal distribution of data sets, and using the Kolmogorov-Smirnov test when at least in one of the data sets the normal distribution was excluded. Spearman's rank-order correlation was used for correlation analysis. Multiple regression analysis was performed using HOMA IR indexes of insulin resistance as dependent variables, and other metabolic and hormonal factors (lipid parameters, BMI, leptin, TNFα, hFABP, ACL-IgG) as independent variables. The so-called step-down regression model was used to select dominant independent variables. Various four-member groups of independent (explanatory) variables were used for the analysis and the non-zero intercept was taken into account. The independent variables were then dropped, one at a time; at each stage one variable making the least contribution to the dependent variable (i.e. that showed the least p-value in the test of the regression coefficient being zero) was excluded. The coefficient of determination R2, which can be viewed as a percentage explaining the total variance, was simultaneously monitored. A great drop in R2 after excluding some independent variable enabled selection of those independent variables that could be thought to be the most important determinants of the dependent variable.<br><br>
Results
Table 1 demonstrates mean parameters in individual groups of subjects matched according to sex, lipid parameters and age. While the age of all four groups did not differ substantially, the concentrations of total serum cholesterol, triglycerides, HDL-cholesterol and LDL-cholesterol differ very significantly in both male and female hyperlipemic groups as compared with controls. In addition, the concentration of triglycerides in control <span class="yellow">women</span> was significantly higher than in control <span class="blue">men</span>, the concentration of triglycerides in hyperlipemic <span class="yellow">women</span> was lower than in hyperlipemic <span class="blue">men</span>, and the concentration of HDL-cholesterol in hyperlipemic <span class="yellow">women</span> was very significantly higher when compared with hyperlipemic <span class="blue">men</span>.
Table 2 shows the values of other metabolic and insulin parameters, factors related to insulin resistance and indexes of insulin resistance, respectively. Body mass indexes and uric acid concentration were significantly higher in hyperlipemic <span class="blue">men</span> as compared to controls, but not in hyperlipemic <span class="yellow">women</span>. Uric acid concentration was substantially lower in hyperlipemic <span class="yellow">women</span> than in hyperlipemic <span class="blue">men</span>. Plasma concentrations of glycemia, insulin and intact proinsulin were significantly higher in both hyperlipemic <span class="blue">men</span> and <span class="yellow">women</span> as compared with controls of identical gender, while the concentration of leptin increased only in hyperlipemic <span class="blue">men</span>. However, serum leptin concentrations of both control and hyperlipemic <span class="yellow">women</span> were significantly higher than in corresponding groups of <span class="blue">men</span>. Serum concentrations of TNFα, hFABP and ACL-IgG in hyperlipemic groups of both <span class="blue">men</span> and <span class="yellow">women</span> were not significantly different from control groups. On the other hand, the indexes of insulin resistance HOMA IR and QUICKI differed very significantly in hyperlipemic groups of both <span class="blue">men</span> and <span class="yellow">women</span> as compared with corresponding control groups, more distinctly in <span class="yellow">women</span>.
From Fig. 1, presenting 95% confidence limits of insulin resistance indexes HOMA IR and QUICKI, we concluded that in groups of hyperlipemic <span class="yellow">patients</span> of both genders the insulin resistance was substantially higher than in control groups; the groups did not overlap each other.
In Table 3 the results of Spearman's correlations between insulin resistance index HOMA IR and various metabolic parameters are presented. In the control group of <span class="blue">men</span>, positive significant correlation between HOMA IR and serum leptin concentration, and inverse significant correlation between HOMA IR and ACL IgG, respectively, were found. In the control group of <span class="yellow">women</span>, the significance of Spearman's correlation between HOMA IR and leptin was more expressive; inverse correlation between HOMA IR and HDL-cholesterol was also present.
In the hyperlipemic group of <span class="blue">men</span>, the significance of the correlation between HOMA IR was more expressive in relation to the control group, and no significant correlation between HOMA IR and ACL IgG was found. In the hyperlipemic group of <span class="yellow">women</span>, however, the significance of Spearman's correlation between HOMA IR and serum leptin concentration weakened, the inverse correlation between HOMA IR and HDL-cholesterol remained approximately unchanged, and a positive correlation between HOMA IR and serum concentration of TNFα appeared.
Table 4 shows results of multiple regression analysis, when data from both control and hyperlipemic groups of each gender were judged together. HOMA IR was considered as a dependent variable and differently changed constellations of metabolic and other factors were taken as independent variables.
In <span class="blue">men</span>, BMI and leptin seemed to play a main role in influencing the insulin resistance index HOMA IR, while TGL, ACL IgG and LDL-cholesterol didn't play any significant role (see left columns of Table 4). The decreasing of HDL-cholesterol concentration may also have some influence (see a significant drop of R2 after exclusion of this factor in Table 4A, 4B). But in the presence of leptin in the group of independent factors, the drop of R2 after exclusion of HDL-cholesterol from these factors was minimal (see Table 4C). On the other hand, after the exclusion of TNFα from the group of independent variables (see Table 4B, 4D) the value of R2 has unexpectedly risen, which could reflect the interference of TNFα with factors increasing the insulin resistance.
In <span class="yellow">women</span> (see right columns of Table 4), the maximal values of R2 were achieved with combination of independent variables containing TGL, leptin and HDL-cholesterol (about 60% influence on HOMA IR! – see Table 4A, 4B, 4C). TNFα seemed to play quite a different role than in <span class="blue">men</span>: after exclusion of this factor from the group of independent factors R2significantly decreased (see Table 4B, 4D). In contrast to <span class="blue">men</span>, the role of BMI seemed to be minimal. As in <span class="blue">men</span>, the role of ACL IgG and LDL-cholesterol in influencing HOMA IR was negligible, but in contrast to <span class="blue">men</span>, hFABP might play a certain role in this process (see Table 4D).
Generally, the insulin resistance (represented by HOMA IR) was in <span class="blue">men</span> much less influenced by metabolic variables than in <span class="yellow">women</span>; while in <span class="yellow">women</span> in some combinations of dependent variables R2 reached 64 %, in <span class="blue">men</span> the maximal value of R2 was only 39 %.<br><br>Discussion
In our previous paper [36], the mean value of HOMA IR in healthy subjects of both genders and of age comparable with our controls was 1.57 ± 0.87, and the mean value of index QUICKI 0.366 ± 0.029, respectively. These values, as well as the 95 % confidence limits, correspond to values found in controls in this study.
In accordance with many previous papers, serum concentrations of leptin in <span class="yellow">women</span> (both control and hyperlipemic) were substantially higher than in <span class="blue">men</span>. In the control group of <span class="yellow">women</span> the correlation between leptin and HOMA IR was highly significant. However, in hyperlipemic <span class="yellow">women</span> the significance of this correlation lessened, because HOMA IR increased considerably (and significantly) but serum concentration of leptin only slightly (insignificantly). In <span class="blue">men</span> the significance of correlations between serum leptin and HOMA IR was high and approximately the same in both the control and hyperlipemic groups, because the values of HOMA IR as well as serum leptin have nearly doubled in hyperlipemic in relation to control groups. In non-hyperlipemic postmenopausal <span class="yellow">women</span> the high concentration of serum leptin was not associated with higher insulin resistance: HOMA IR did not differ substantially from <span class="blue">men</span>. A significant increase of insulin resistance in hyperlipemic <span class="yellow">women</span> was associated by only slight and insignificant increase of leptin concentration. According to Spearman's correlations, an increase of serum TNFα and/or a decrease of HDL-cholesterol might also play a distinct role in this respect. (see Table 3). In contrast to <span class="yellow">women</span>, in hyperlipemic <span class="blue">men</span> the increase of insulin resistance index was approximately proportional with the increase of leptin concentration.
Multiple regression analysis affirmed the importance of leptin serum in increasing of insulin resistance in both genders. In <span class="blue">men</span>, only BMI and HDL-cholesterol from other factors studied seemed to play a certain role, but the maximal values of influencing HOMA IR reached only 39%, with leptin and BMI being the more important factors. On the other hand, in <span class="yellow">women</span> the maximal determination of HOMA IR as high as 60% was registered in combination of serum leptin, TGL and decreased HDL-cholesterol as independent factors; the role of BMI was insignificant.
It is not known how leptin is regulated. A strong correlation between plasma leptin and fasting insulin undoubtedly exists, but hyperleptinemia in both obese and lean <span class="yellow">humans</span> is not likely the result of hyperinsulinemia [37]. A relationship between leptin and insulin dependent on sex or BMI was reported, but relationship between triglyceride concentrations and leptin was independent of sex, BMI, and insulin [18,24]. Hyperleptinemia, as an early sign of obesity, was closely linked to subcutaneous fat mass [39,40]. Percentage of body fat has been shown to be the strongest predictor of leptin levels even in lean <span class="yellow">women</span> [41]. Leptin was highly correlated with percentage of body fat and with fat mass in adults irrespective of gender and age; however, the mean determinant of leptin plasma concentration in <span class="blue">men</span> and postmenopausal <span class="yellow">women</span> was BMI, while in premenopausal <span class="yellow">women</span> it was only the fat mass [42]. These findings contrast with our results showing minimal influence of BMI on HOMA IR in postmenopausal <span class="yellow">women</span>.
All factors mentioned are connected with fat tissue: leptin and TNFα are directly produced chiefly by adipocytes, BMI growth is obviously accompanied by fat mass increase, and the typical hypertriglyceridemia associated with a decrease of HDL-cholesterol goes along with obesity and fat mass growth. The gender differences in circulating leptin were best explained by percentage of body fat and – inversely – by lean body mass [25]. In both genders the intra-abdominal fat correlated with insulin resistance, while the subcutaneous fat correlated with circulating leptin [11,12]. In <span class="blue">men</span> obesity led to a prevalent increase of intra-abdominal fat, while in <span class="yellow">women</span> of subcutaneous fat [13]. Influences of different compartments of adipose tissues could elucidate the variability of correlations between insulin resistance and high leptin concentrations in lean and obese subjects of both genders [43]. In our non-hyperlipemic postmenopausal <span class="yellow">women</span> the content of subcutaneous fat mass might be higher than in non-hyperlipemic <span class="blue">men</span> of appropriate age, which indicated a higher serum concentration of leptin. However, the insulin resistance – related to intra-abdominal fat mass – did not differ from <span class="blue">men</span>. The significant increase of insulin resistance and leptin concentration in hyperlipemic <span class="blue">men</span> might reflect the growing content of both subcutaneous and intra-abdominal fat mass (see the significant increase of BMI). In hyperlipemic <span class="yellow">women</span> the significant increase of insulin resistance accompanying only minimal insignificant increase of leptin could be caused by prevalent growing of intra-abdominal fat mass.
In elderly postmenopausal <span class="yellow">women</span>, an association between leptin and plasma lipoprotein concentration was found which depended on adiposity [17], and inverse correlations between serum leptin and HDL-cholesterol were described [44]. In our study, insulin resistance in <span class="yellow">women</span> seemed to be more notably than in <span class="blue">men</span> influenced by lipid disorders, i.e. positively by serum triglycerides and inversely by HDL-cholesterol. These findings might be important in considering the concept of treatment of insulin resistance-related disorders in postmenopausal <span class="yellow">women</span>.
The significant role of TNFα in insulin resistance, caused by inhibiting the transduction of insulin signaling and by down-regulation of glucose transporter GLUT-4 and insulin receptor substrate-1, has been repeatedly confirmed [45-48]. Our results supported these findings unambiguously only in <span class="yellow">women</span>, while in <span class="blue">men</span> TNFα seemed paradoxically to interfere with other factors – mainly BMI and leptin – in influencing insulin resistance, thus playing a quite different role. Previously it was found [46] that correlation between serum TNFα on the one side, and insulin, HOMA IR, serum triglycerids, respectively, on the other side, was substantially more significant in <span class="yellow">women</span> than in <span class="blue">men</span>. Serum concentration of TNFα in <span class="yellow">patients</span> with type 2 diabetes of both genders correlated only with the quantity of intra-abdominal fat compartment [50]. Visceral obesity correlated with plasmatic aldosterone and with insulin resistance only in premenopausal <span class="yellow">women</span>, but not in <span class="blue">men</span> [51].
From all these data we might support our above mentioned conclusion – that rising of insulin resistance in hyperlipemic <span class="yellow">women</span> was associated with an increase of intra-abdominal fat, because this fat mass in particular is a source of TNFα, which interfered with insulin sensitivity only in <span class="yellow">women</span>. We came to this conclusion irrespective of the finding that the increase of serum TNFα in hyperlipemic <span class="yellow">women</span> was statistically insignificant; results of Spearman's correlation (Table 3) and multiple regression analysis confirm a distinct role of this factor. In hyperlipemic <span class="blue">men</span> not only the serum concentration of TNFα has decreased instead of increasing, but according to multiple regression analysis it played a quite different role in influencing insulin sensitivity, interfering with factors that determined insulin resistance (leptin and BMI).
In the control group of <span class="blue">men</span> IgG anticardiolipin was inversely correlated to HOMA IR. The significance of this finding is not clear. These antibodies indicate vascular and thrombotic complications and oxidative modification of lipoproteins [52,53] and may represent an increased risk of atherogenic and inflammatory complications. In this case, however, their growing might be connected with an increase in insulin sensitivity. Anyway, ACL IgG evidently did not participate significantly in influencing the increase of insulin resistance associated with hyperlipidemia, although other anti-cardiolipin correlations could be masked by the relatively large inter-individual variations in this parameter.
Neither serum concentration of hFABP, a factor ensuring transmembrane transport and oxidative metabolisation of long-chain fatty acids [54,55], was significantly changed in hyperlipemic and insulin resistant subjects of both genders. This factor was very weakly associated only with HOMA IR in <span class="yellow">women</span> (see Table 4D), indicating that enhanced metabolisation of fatty acids in cells might to some degree contribute to insulin resistance.<br><br>Conclusions
In postmenopausal <span class="yellow">women</span> as well as in <span class="blue">men</span> of approximately equal age serum leptin plays a significant role as an important determinant of insulin resistance. In addition to this factor, in <span class="yellow">women</span> the grade of insulin resistance is very considerably influenced by serum triglycerides, tumor necrosis factor alpha, and by decreased concentration of HDL-cholesterol, while in <span class="blue">men</span> only a mild influence of BMI and decreased HDL-cholesterol is observed. These findings are explained as a consequence of gender-related differences in adipose tissue composition and/or distribution in both normal-weight and over-weight subjects and should be taken into account in treatment of <span class="yellow">patients</span> with metabolic risk factors of cardiovascular diseases.<br><br>List of abbreviations
HDL-Cholesterol = high-density cholesterol
LDL-cholesterol = low-density cholesterol
HOMA IR = Homeostasis Assessment of Insulin Resistance
= fasting insulin (μU/ml) * fasting glucose (mmol/l) / 22,5
QUICKI = 1 / [log fasting insulin (μU/ml) + log fasting glucose (mg/100 ml) ]
TNFα = tumor necrosis factor alpha
BMI = body mass index
R2 = coefficient of determination
hFABP = heart fatty acid binding protein
ACL-IgG = IgG fraction of anticardiolipin
TGL = triglycerides
GLUT-4 = glucose transporter-4
PPARγ = Peroxisome Proliferator-Associated Receptor gamma
CV = coefficient of variation<br><br>Authors' contributions
Dr. Radka Lichnovská collected the clinical material, performed analysis of biochemical values and edited the manuscript.
Dr. Simona Gwozdziewiczová performed analysis of clinical and biochemical data and edited the manuscript.
Prof. Jirí Hrebícek initiated the study, participated in its design and coordination, and wrote and edited the manuscript.<br><br>
<h3>pmcA2636797</h3>Efficacy of intra-articular hyaluronan (Synvisc®) for the treatment of osteoarthritis affecting the first metatarsophalangeal joint of the foot (hallux limitus): study protocol for a randomised placebo controlled trial
Abstract
Background
Osteoarthritis of the first metatarsophalangeal joint (MPJ) of the foot, termed hallux limitus, is common and painful. Numerous non-surgical interventions have been proposed for this disorder, however there is limited evidence for their efficacy. Intra-articular injections of hyaluronan have shown beneficial effects in case-series and clinical trials for the treatment of osteoarthritis of the first metatarsophalangeal joint. However, no study has evaluated the efficacy of this form of treatment using a randomised placebo controlled trial. This article describes the design of a randomised placebo controlled trial to evaluate the efficacy of intra-articular hyaluronan (Synvisc®) to reduce pain and improve function in <span class="yellow">people</span> with hallux limitus.<br><br>Methods
One hundred and fifty community-dwelling <span class="blue">men</span> and <span class="yellow">women</span> aged 18 years and over with hallux limitus (who satisfy inclusion and exclusion criteria) will be recruited.
<span class="yellow">Participants</span> will be randomised, using a computer-generated random number sequence, to receive a single intra-articular injection of up to 1 ml hyaluronan (Synvisc®) or sterile saline (placebo) into the first MPJ. The injections will be performed by an interventional radiologist using fluoroscopy to ensure accurate deposition of the hyaluronan in the joint. <span class="yellow">Participants</span> will be given the option of a second and final intra-articular injection (of Synvisc® or sterile saline according to the treatment group they are in) either 1 or 3 months post-treatment if there is no improvement in pain and the <span class="yellow">participant</span> has not experienced severe adverse effects after the first injection. The primary outcome measures will be the pain and function subscales of the Foot Health Status Questionnaire. The secondary outcome measures will be pain at the first MPJ (during walking and at rest), stiffness at the first MPJ, passive non-weightbearing dorsiflexion of the first MPJ, plantar flexion strength of the toe-flexors of the hallux, global satisfaction with the treatment, health-related quality of life (assessed using the Short-Form-36 version two questionnaire), magnitude of symptom change, use of pain-relieving medication and changes in dynamic plantar pressure distribution (maximum force and peak pressure) during walking. Data will be collected at baseline, then 1, 3 and 6 months post-treatment. Data will be analysed using the intention to treat principle.<br><br>Discussion
This study is the first randomised placebo controlled trial to evaluate the efficacy of intra-articular hyaluronan (Synvisc®) for the treatment of osteoarthritis of the first MPJ (hallux limitus). The study has been pragmatically designed to ensure that the study findings can be implemented into clinical practice if this form of treatment is found to be an effective treatment strategy.<br><br>Trial registration
Australian New Zealand Clinical Trials Registry: ACTRN12607000654459<br><br><br><br>Background
Osteoarthritis (OA) is a degenerative joint disease that commonly presents within the first metatarsophalangeal joint (MPJ) of the foot. The terms hallux limitus and hallux rigidus have frequently been used interchangeably to describe differing severities of pain and limitation of motion associated with OA at the first MPJ [1]. Hallux limitus is a progressive osteoarthritic condition of the first MPJ that may advance to an end-stage presentation of hallux rigidus where the joint fuses and there is a complete restriction of motion [1]. First MPJ OA is the second most common disorder affecting the foot after hallux valgus [2]. The prevalence of the condition increases with age, and it has been reported that radiographic changes in the first MPJ affect are evident in approximately 46% of <span class="yellow">women</span> and 32% of <span class="blue">men</span> at 60 years of age [3]. Osteoarthritis at the first MPJ is characterised by the symptoms of pain and stiffness at the joint [1]. Secondary painful symptoms relate to compensations during gait that may occur due to the reduced motion of the first MPJ [1]. The presence of pain associated with first MPJ OA impacts on normal walking and quality of life [4].
Treatment of hallux limitus involves conservative measures (such as physical therapy, foot orthoses, footwear modification, joint manipulation and injection with corticosteroid) [5], or surgical intervention (either joint-salvage or joint-destructive procedures) [6]. Pharmacological treatment is also often undertaken as an adjunct for pain relief in the management of hallux limitus [6]. However, although non-steroidal anti-inflammatory drugs (NSAIDs) and cyclooxygenase-2 inhibitors have been found to be effective in the management of various forms of OA, gastrointestinal complications remain a concern [7]. In light of these limitations with existing treatments, an alternative treatment termed 'viscosupplementation' – the intra-articular injection of hyaluronan into arthritic joints with the aim of restoring the viscoelasticity of the synovial fluid [8] – has been proposed and has attracted considerable attention in the medical literature as a treatment for OA [9]. In particular, both the American College of Rheumatology (ACR) and European League Against Rheumatism (EULAR) recommend hyaluronan in the management of OA of the knee [10,11]. Although the results of systematic reviews investigating the effectiveness of this type of treatment for knee OA are controversial, the most recent update of the Cochrane systematic review evaluating viscosupplementation for the treatment of knee OA concluded that viscosupplementation was both safe and effective for the treatment of OA and was superior or equivalent to any form of systemic intervention or intra-articular corticosteroids [9,12].
Despite there being a large number of studies investigating the effectiveness of hyaluronan for knee OA, few studies have investigated the effects of this form of treatment for OA at the first MPJ [13]. In a case-series retrospective study, 14 <span class="yellow">patients</span> with radiographically confirmed OA at the first MPJ that received up to 3 intra-articular injections of 1 ml hyaluronan (Ostenil® Mini) (sodium hyaluronate) reported a statistically significant reduction in pain (reported using a visual analogue scale) after 6 months [14]. The treatment was well tolerated, with 3/14 (21%) <span class="yellow">participants</span> reporting mild adverse reactions at the injection site. In another study, Pons et al[13] compared a single intra-articular injection of 1 ml Ostenil® Mini (sodium hyaluronate) with 1 ml Trigon depot® (triamcinolone acetonide, a corticosteroid) for the treatment of painful, grade 1 hallux limitus (Karasick and Wapner [15] scale) in 37 <span class="yellow">participants</span> (40 feet) [13]. Both treatment groups showed statistically significant reductions in pain at rest or on palpation for up to 12 weeks post-injection. However, hyaluronan treatment resulted in a statistically significant greater reduction in pain during walking and greater improvement in the American Orthopaedic Foot and Ankle Society (AOFAS) hallux MPJ score compared to treatment with triamcinolone acetonide. The treatment with hyaluronan was well tolerated, with 2/20 (10%) <span class="yellow">participants</span> reporting mild adverse reactions at the injection site.
Although both of these studies suggest that intra-articular hyaluronan is safe and effective for the treatment of hallux limitus, neither used a placebo control group [13,14]. This limitation is significant as a placebo effect can account for 79% of the efficacy of intra-articular hyaluronan treatment [16]. Further, both studies are limited in that neither of the studies used blinding of both the <span class="yellow">participants</span> and assessors in their protocols. It is therefore possible that the positive effects of hyaluronan may have been overestimated. Accordingly, the aims of this project are to conduct a double blind randomised controlled trial to determine the effectiveness of intra-articular hyaluronan (Synvisc®) on (i) foot pain and function; (ii) the range of motion of the first MPJ; (iii) the strength of the plantarflexor muscles of the first MPJ; (iv) the health related quality of life; and (v) the use of pain-relieving medications in <span class="yellow">people</span> with hallux limitus. The study protocol is presented in this paper, consistent with the recommendations of Editorial Board of BioMed Central [17].<br><br>Methods
Design
This study is a parallel group, <span class="yellow">participant</span> and assessor blinded, randomised controlled trial with a 6 month follow-up (Figure 1). It has been developed using the principles described by Osteoarthritis Research Society International (OARSI) Clinical Trials Task Force guidelines [18]. <span class="yellow">Participants</span> will be randomised to receive a single intra-articular injection of up to 1 ml hyaluronan (Synvisc®) or sterile saline (placebo) into the first MPJ. Allocation to either the Synvisc® or placebo groups will be achieved using a computer-generated random number sequence. The allocation sequence will be generated and held by an external <span class="yellow">person</span> not directly involved in the trial. Concealment of the allocation sequence will be ensured as each <span class="yellow">participant</span>'s allocation will be contained in a sealed opaque envelope. Envelopes will be made opaque by using a sheet of aluminium foil inside the envelope. In addition, a system using carbon paper will be employed so the details (name and date of recruitment) are transferred from the outside of the envelope to the paper inside the envelope containing the allocation prior to opening the seal. Assessors and <span class="yellow">participants</span> will be blinded to group allocation. <span class="yellow">Participants</span> will be given the option of a second and final intra-articular injection (of Synvisc® or sterile saline according to the treatment group they are in) on days 30 or 90 if there is no improvement in pain and the <span class="yellow">participant</span> has not experienced severe adverse effects after the first injection).<br><br><span class="yellow">Participants</span>
The <span class="yellow">Human</span> Studies Ethics Committee at La Trobe University (Human Ethics Committee Application No. 07-45) and the Radiation Advisory Committee of the Victorian Department of <span class="yellow">Human</span> Services have given approval for the study. Written informed consent will be obtained from all <span class="yellow">participants</span> prior to their participation. <span class="yellow">People</span> with hallux limitus will be recruited from a number of sources:
(i) advertisements in relevant Melbourne (Australia) newspapers;
(ii) mail-out advertisements to health-care practitioners in Melbourne;
(iii) advertisements using relevant internet web-sites (including );
(iv) posters displayed in local retirement villages, community centres and universities located in Melbourne.
Respondents will initially be screened by telephone interview to ensure they are suitable for the study. Suitable individuals will then be invited to participate in the study and attend an initial assessment.
To be included in the study, <span class="yellow">participants</span> must meet the following inclusion criteria:
(i) be aged at least 18 years;
(ii) report having symptoms of pain, during walking or rest, in the first MPJ for at least 3 months;
(iii) report having pain rated at least 20 mm on a 100 mm visual analogue pain scale (VAPS);
(iv) have pain upon palpation of the dorsal aspect of the first MPJ;
(v) radiographic evidence of OA (score 1 or 2 for either osteophytes or joint space narrowing using a previously published radiographic classification) [19] at the first MPJ.
(vi) able to walk household distances (>50 meters) without the aid of a walker, crutches or cane;
(vii) be willing to attend the La Trobe University Medical Centre (Melbourne, Australia) for treatment with either Synvisc® or placebo (single intra-articular injection) and attend the Health Sciences Clinic at La Trobe University (Melbourne, Australia) for the initial assessment and the outcome measurements (at baseline and 1, 3 and 6 months post-treatment);
(viii) not receive other intra-articular injections into the first MPJ during the course of the study, apart from those dictated by the study;
(ix) be willing to discontinue taking all pain-relieving medications (analgesics and non-steroidal anti-inflammatory medications (NSAIDs), except paracetamol up to 4 g/day, taken by mouth or applied topically):
- for at least 14 days prior to the baseline assessment;
- during the study period (6 months after the final treatment with Synvisc®).
<span class="yellow">Participants</span> who do take paracetamol need to discontinue its use at least 24 hours prior to the baseline assessment and follow-up assessments at 1, 3 and 6 months after the treatment;
(x) be willing to not receive any physical therapy on the involved MPJ or trial of shoe modifications or foot orthoses during the study period.
Exclusion criteria for <span class="yellow">participants</span> in this study will be:
(i) Severe radiographic evidence of OA (score 3 for either osteophytes or joint space narrowing) at the first MPJ using a previously published radiographic classification [19];
(ii) previous surgery on the first MPJ;
(iii) intra-articular steroid, or any other intra-articular injection at the first MPJ in the previous 6 months;
(iv) treatment with systemic steroid (excluding inhalation or topical steroids), immunosuppressives or anticoagulants (except for acetylsalicylic acid at dosages of up to 325 mg/day);
(v) presence of joint infection(s) of the foot;
(vi) significant deformity of the first MPJ including hallux abducto valgus (grade of 3 or 4 scored using the Manchester Scale [20];
(vii) presence of peripheral vascular disease. Peripheral vascular disease will be considered to be present if any of the following are present [21];
▪ past history of, vascular surgery, Raynaud's phenomenon, vasculitis associated with connective tissue diseases, Buerger's disease, arterial emboli, deep vein thrombosis or lower limb ulcers;
▪ history of intermittent claudication or rest pain;
▪ presence of atrophy, ulcers or significant oedema;
▪ inability to palpate at least one pedal pulse;
▪ Ankle Brachial Pressure Index <0.9;
(viii) presence of one or more conditions that can confound pain and functional assessments of the first MPJ, such as metatarsalgia, plantar fasciitis, pre-dislocation syndrome, sprains of the foot, Achilles tendinopathy, degenerative joint disease of the foot (other than the first MPJ) or painful corns and callus;
(ix) planning to undergo any surgical procedure or receive any injections, apart from those dictated by the study, at the involved first MPJ during the study period;
(x) presence of systemic inflammatory condition or infection, such as inflammatory arthritis, diagnosed with rheumatoid arthritis, ankylosing spondylitis, psoriatic arthritis, reactive arthritis, septic arthritis, acute pseudogout, or any other connective tissue disease;
(xi) evidence of gout or other musculoskeletal disease other than OA within the feet. Gout will be screened for using clinical history and physical assessment (painful joint, abrupt onset, swelling), radiographic assessment (asymmetrical joint swelling, subcortical cysts without erosion and tophi) as well as serum uric acid levels (hyperuricaemia = serum uric acid > mean + 2 SD from normal population) [22];
(xii) active skin disease or infection in the area of the injection site;
(xiii) any medical condition that, in the opinion of the investigators, makes the <span class="yellow">participant</span> unsuitable for inclusion (e.g., severe progressive chronic disease, malignancy, bleeding disorder, clinically important pain in a part of the musculoskeletal system other than the first MPJ, or fibromyalgia);
(xiv) pregnant or lactating <span class="yellow">women</span>, or <span class="yellow">women</span> who are of <span class="yellow">child</span> bearing age or have not undergone menopause (Synvisc® has not been tested in pregnant <span class="yellow">women</span> or <span class="yellow">women</span> who are nursing);
(xv) cognitive impairment (defined as a score of < 7 on the Short Portable Mental Status Questionnaire) [23];
(xvi) known hypersensitivity (allergy) to hyaluronan preparations, or to avian proteins, feathers or egg products;
(xvii) involvement in any clinical research study in the previous 3 months that could be considered to affect the results of this study.<br><br>Intra-articular injections for the treatment groups
<span class="yellow">Participants</span> will be randomised to receive a single intra-articular injection of up to 1 ml of hyaluronan (Synvisc®; Genzyme Biosurgery, Genzyme Corporation, NJ, USA) or sterile saline (placebo) into the first MPJ. Each 2 ml ampoule of Synvisc® contains 16 mg of hylan G-F 20 (cross-linked hylan polymers; hylan A and B), 17 mg sodium chloride, 0.32 mg disodium hydrogen phosphate, 0.08 mg sodium dihydrogen phosphate monohydrate. The hyaluronan is extracted from <span class="yellow">chicken</span> combs and the purified material has an average molecular weight of 6,000 kDa.
The injections will be performed by the same experienced interventional radiologist (AEZ) using fluoroscopic imaging to ensure accurate deposition of the hyaluronan within the joint. As the Synvisc® is provided in ampoules that are labelled with the product name, it will not be possible to blind the injector, however this <span class="yellow">person</span> is not involved in generation of the allocation order, recruitment, assessment or data analysis. The intra-articular injection will be performed using a 21 gauge (0.80 × 19 mm) Surflo® (Terumo® Corp., Tokyo, Japan) winged infusion set under aseptic procedures. Either a dorso-lateral or dorso-medial approach for injection will be used at the discretion of the injector (depending on which approach provides minimum interference from the osteophytes at the first MPJ joint margins). No anaesthetic will be used. If the <span class="yellow">participant</span> has bilateral painful first MPJs, only one side (the most painful side) will be treated and used for data collection. The injector will record the volume of the agent that is injected.
<span class="yellow">Participants</span> will be given the option of a second and final intra-articular injection (of Synvisc® or sterile saline according to the treatment group they are in) on days 30 or 90 if there is no improvement in pain (assessed using the VAPS for pain during walking or at rest) and the <span class="yellow">participant</span> has not experienced severe adverse effects after the first injection).<br><br>Assessments
Initial assessments
An initial assessment will be performed to determine the eligibility of <span class="yellow">participants</span> for this study. Demographic data will be collected including the age, gender, height and weight of <span class="yellow">participants</span>. Data will also be obtained concerning the presentation of symptoms (foot affected, duration of symptoms). If the <span class="yellow">participant</span> has bilateral painful first MPJs, the most painful side will be used for data collection and subsequent treatment. To establish eligibility for the study, <span class="yellow">participants</span> will undergo a clinical assessment, have one set of dorso-plantar and lateral weight-bearing x-rays taken of their feet to grade the severity of first MPJ OA as well as undergo a blood test to assess serum uric acid levels (to exclude gout).
Weightbearing dorso-plantar and lateral radiographic views will be obtained from both feet with the <span class="yellow">participant</span> standing in a relaxed bipedal stance position. All x-rays will be taken by the same medical imaging department using a Shimadzu UD150LRII 50 kw/30 kHz Generator and 0.6/1.2 P18DE-80S high speed x-ray tube from a ceiling suspended tube mount. AGFA MD40 CR digital phosphor plates in a 24 cm × 30 cm cassette will be used. For dorso-plantar projections, the x-ray tube will be angled 15° cephalad and centered at the base of the third metatarsal. For lateral projections, the tube will be angled 90° and centered at the base of the third metatarsal. The film focus distance will be set at 100 cm [19].<br><br>Baseline assessments and outcome measures
<span class="yellow">Participants</span> who are eligible for the study will be invited to attend a baseline assessment. During the baseline assessment, <span class="yellow">participants</span> will undergo primary and secondary outcome measurements prior to receiving their injection. The outcome measurements have been developed in accordance of the recommendations of the OARSI Clinical Trials Task Force guidelines [18].<br><br>Primary outcome measures
Outcome measurements (primary and secondary) will occur at four time-points at baseline, 1, 3 and 6 months post-treatment (after the intra-articular injection of Synvisc® or placebo). The assessor performing the measurements will be blinded as to which treatment group <span class="yellow">participants</span> have been allocated to. <span class="yellow">Participants</span> who receive a second treatment at day 30 or 90 will be followed for a further 30 days or 90 days respectively and undergo outcome measurements at 7 or 9 months respectively.
The primary outcome measures will be the Pain and Function subscales of the Foot Health Status Questionnaire (FHSQ) [24]. The FHSQ includes 13 questions that assess four domains of foot health, Foot pain, Foot function, Footwear and General foot health. The FHSQ has been subjected to an extensive validation (content, criterion and construct validity) process. It has a high test-retest reliability (intraclass correlation coefficients ranging from 0.74 to 0.92) and a high degree of internal consistency (Cronbach's α ranging from 0.85 to 0.88) [24]. Rigorous reviews have rated it as one of the highest quality foot health status measures currently available [25-27].<br><br>Secondary outcome measures
The secondary outcome measures will be:
(i) Severity of pain
Severity of pain at the first MPJ during walking, and during rest, over the past week will be assessed using a 100 mm visual analogue pain scale. The left side of the scale (0 mm) will be labelled "no pain" and the right side of the scale (100 mm) will be labelled "worst pain possible" for each question [25,28].<br><br>(ii) Severity and duration of stiffness at the first metatarsophalangeal joint
The severity of stiffness at the first MPJ during walking over the past week will be assessed using a 100 mm visual analogue scale. The left side of the scale (0 mm) will be labelled "not stiff at all" and the right side of the scale (100 mm) will be labelled "most stiff possible". The average duration of stiffness at the first MPJ over the past week will be assessed using a four category scale response. The responses are: "none", "1–15 minutes", "16–30 minutes" and "greater than 30 minutes" [29].<br><br>(iii) Passive, non-weightbearing dorsiflexion range of motion of the first metatarsophalangeal joint
First MPJ dorsiflexion range of motion will be measured using a goniometer as the maximum angle at which the hallux cannot be passively moved into further extension in a non-weightbearing position (Figure 2) [30]. The test will be performed two times and the average will be used for analysis. This measurement technique shows high intra-reliability (ICC = 0.95, standard error of mean = 1.3°) [30].<br><br>(iv) Plantar flexion strength of the toe-flexors of the hallux
Plantar flexion strength of the toe-flexors of the hallux will be measured using the Mat Scan® plantar pressure measurement device [31]. <span class="yellow">Participants</span> will be seated with the hip, knee, and ankle at 90 degrees and their foot placed over the Mat Scan® plantar pressure measurement device (Tekscan, Boston, MA, USA) (Figure 3a). This system consists of a 5-mm thick floor mat (432 × 368 mm) incorporating 2288 resistive sensors (1.4 sensors/cm2) sampling at a rate of 40 Hz. The mat will be calibrated for each <span class="yellow">participant</span> using his or her own bodyweight before each testing session. <span class="yellow">Participants</span> will be instructed to use their toe-flexor muscles to maximally push their hallux down on the MatScan® device and forces under the hallux will be recorded (Figure 3b). The test will be performed three times for the hallux and the maximal force will be used for analysis. The test-retest reliability of this measurement technique has previously been shown to be high, with intraclass correlation coefficients (ICCs) = 0.88 (95% CI 0.81 – 0.93) [31].<br><br>(vi) Plantar pressure measurement
Plantar pressures will be recorded during level barefoot walking using the MatScan® system (Tekscan®, Boston, MA, USA). The two-step gait initiation protocol will be used to obtain foot pressure data, as it requires fewer trials than the mid-gait protocol and has similar re-test reliability [32]. Three trials will be recorded, which has been found to be sufficient to ensure adequate reliability of pressure data [32,33]. Following data collection, the Research Foot® software (version 5.24) will be used to construct individual "masks" to determine maximum force (kg) and peak pressure (kg/cm2) under seven regions of the foot: hallux, lesser toes, 1st MPJ, 2nd MPJ, 3rd to 5th MPJs, midfoot and heel (Figure 4a). For each region, the median of the three trials will be used for analysis. Typical plantar pressure recordings from a <span class="yellow">participant</span> are shown in Figure 4b.<br><br>(vi) Global satisfaction with the treatment
Global satisfaction with the treatment will be assessed using a 5-point Likert scale, as well as a dichotomous (yes/no) scale. The five point-Likert scale will ask "How satisfied are you with the treatment you received for your big-toe joint pain?", and will have the following five responses: "Dissatisfied", "Only moderately satisfied", "Fairly satisfied", "Clearly satisfied" and "Very satisfied". The dichotomous scale of satisfaction will be answered as "Yes"' or "No" in response to the question: "Would you recommend the treatment that you received to someone else with big-toe joint pain".<br><br>(vii) Health related quality of life
The Short-Form-36 (version two) (SF-36) questionnaire will be used to assess health related quality of life. The SF-36 is a 36 question survey that measures eight health concepts most affected by disease and treatment. The eight health concepts can then be used to form two summary measures: Physical health and Mental health. The Short Form-36 (SF-36) has been extensively validated and is one of the most widely used instruments to measure health status. The SF-36 shows content, concurrent, criterion, construct, and predictive evidence of validity. The reliability of the eight concepts and two summary measures has been assessed using both internal consistency and test-retest methods. Reliability statistics have exceeded 0.80 [34-37].<br><br>(viii) Self-reported magnitude of symptom change
Self-reported magnitude of symptom change will be measured using a 15-point Likert scale. The scale will ask <span class="yellow">participants</span> "how much have your symptoms in your big-toe joint have changed from the beginning of the study to now?". The fifteen responses will range from "A very great deal better" to "A very great deal worse".<br><br>(ix) Use of rescue medications to relieve pain at the first metatarsophalangeal joint
The number of <span class="yellow">participants</span> who consumed rescue medication (e.g., paracetamol) and mean consumption of rescue medication to relieve pain at the first MPJ (mean grams of paracetamol/<span class="yellow">participant</span>/month] will be assessed using a medications diary that <span class="yellow">participants</span> will self-complete [38,39]. The diary will be returned to the assessor at monthly intervals for analysis.<br><br>(x) Frequency and severity of adverse events as safety variables
The frequency (number of <span class="yellow">participants</span> affected and number of cases) and types of adverse events (including adverse drug reactions) in each treatment group during the trial will be recorded using a questionnaire that <span class="yellow">participants</span> will complete during the follow-up appointments at 1, 3 and 6 months post-treatment [40]. To classify the 'type' of adverse event, a blinded assessor will classify the adverse event as being serious or non-serious [40]. Any serious adverse events, defined as adverse events leading to serious disability, hospital admission, or prolongation of hospitalisation, life-threatening events; or death) will be further classified using the International Classification of Diseases (ICD) codes [41]. Non-serious adverse events will include both local (pain, effusion and heat, with each classified as mild, moderate, severe) and systemic adverse events. An open-response type format will also be available for <span class="yellow">participant</span> responses.<br><br><br><br>Sample size
The sample size for the study has been pre-specified using an a priori power analysis using the primary outcome measure of the pain domain of the FHSQ [42]. One hundred and forty two <span class="yellow">participants</span> (i.e. 71 per group) will provide power of 90% to detect a minimally important difference in the pain domain of the FHSQ (i.e. 14 points on the FHSQ questionnaire) with the significance level set at p < 0.05. A difference of 14 points was determined to be a clinically significant difference worth detecting [43] and a standard deviation of 25 was derived from a previous report [44]. This calculation included a 5% drop-out rate [13]. However, we will aim to recruit 150 <span class="yellow">participants</span> (~75 <span class="yellow">participants</span> per intervention group). Further, we have conservatively ignored the extra precision provided by covariate analysis when estimating the sample size.<br><br>Statistical analysis
Statistical analysis will be undertaken using SPSS version 14.0 (SPSS Corp, Chicago, Ill, USA) and STATA 8 (Stata Corp, College Station, Tex., USA) statistical software. All analyses will be conducted on an intention-to-treat principle using all randomised <span class="yellow">participants</span> [45-47]. Missing data will be replaced with the last score carried forward [48]. Standard tests for normal distribution will be used and transformation carried out if required.
Demographic characteristics (gender, age, weight, height, body mass index) will be determined for the baseline visit for each treatment group. Summary statistics will be calculated for duration of symptoms, side affected (left, right, bilateral), grade of OA at the first MPJ [19] as well as all primary and secondary outcome measurements for each treatment group.
Analyses will be conducted on 1, 3 and 6 month outcome measures. The continuously-scored outcome measures at 1, 3 and 6 months will be compared using analysis of covariance with baseline scores and intervention group entered as independent variables [49,50]. The exception to this will be the plantar pressure measurements which will be analysed at baseline, 1, 3 and 6 months using two-way repeated measures analysis of variance statistics. Post-hoc comparisons will be performed using Bonferroni-adjusted t-tests. Nominal and ordinal scaled data will be compared at 1, 3 and 6 months using Mann-Whitney U-tests and chi-square analyses (or Fisher's exact test where appropriate) respectively. Effect sizes will be determined using Cohen's d (continuous scaled data) or odds ratios (nominal scaled data and ordinal scaled data) as appropriate.
The outcome measurements obtained at 7 or 9 months for <span class="yellow">participants</span> that receive a second and final intra-articular injection (of Synvisc® or sterile saline according to the treatment group they are in) on days 30 or 90 respectively, will also be analysed as described above. These analyses will be classified as secondary outcomes.<br><br>
Discussion
This study is a randomised placebo controlled trial designed to investigate the efficacy of intra-articular hyaluronan (Synvisc®) to reduce pain and improve function in <span class="yellow">people</span> with OA of the first MPJ (hallux limitus). Two studies have previously investigated the efficacy of intra-articular hyaluronan for the treatment of first MPJ OA [13,14]. However, neither of these studies used a placebo control group. To our knowledge, this is the first randomised controlled trial using intra-articular hyaluronan for OA of the first MPJ.
The use of a placebo control group is essential for studies evaluating the effects of intra-articular therapies as there is likely to be a large placebo response related to the injection procedure and this may inflate the results in uncontrolled evaluations [51]. Indeed, a recent meta-analysis of hyaluronan for knee OA concluded that a placebo effect accounted for 79% of the efficacy of intra-articular hyaluronan [16].
The study protocol and outcome measures have been developed in accordance of the recommendations of the OARSI Clinical Trials Task Force guidelines [18]. The outcome measures are pain and function subscales of the FHSQ, pain and stiffness at the first MPJ, range of motion (dorsiflexion) of the first MPJ, plantar flexion strength of muscles of the first MPJ, generic health related quality of life (SF-36), <span class="yellow">patient</span> satisfaction with treatment, consumption of rescue medication as well as frequency and nature of adverse effects. These outcomes will be measured at baseline then at 1, 3 and 6 months after treatment. Previous research suggests that the effects of intra-articular hyaluronan persist for up to 12 months following treatment [9,38]. Thus, the use of follow-up assessments at 6 month post-treatment will allow us to determine if the effects, if any, of intra-articular hyaluronan persist in the longer term.
<span class="yellow">Participants</span> will be given the option of a second and final intra-articular injection (of Synvisc® or sterile saline according to the treatment group they are in) on days 30 or 90 if there is no improvement in their symptoms. Although this has the potential to complicate the interpretation of the results of the study, this protocol was included as it is likely to be more reflective of clinical practice [14], and this is in keeping with the pragmatic nature of this trial.
In summary, this project is the first randomised controlled trial to be conducted to evaluate the efficacy of intra-articular hyaluronan for reducing pain and improving function in <span class="yellow">people</span> with hallux limitus. The study protocol, including interventions, have been pragmatically designed to ensure that the study findings are generaliseable to clinical practice. Recruitment for the study will commence in June 2008, and we expect final results to be available in mid-2010.<br><br>Competing interests
HBM and KBL are Editor-in-Chief and Deputy Editor-in-Chief, respectively, of Journal of Foot and Ankle Research. It is journal policy that editors are removed from the peer review and editorial decision making processes for papers they have co-authored.<br><br>Authors' contributions
SEM, HBM, KBL and CJH conceived the idea and obtained funding for the study. SEM, HBM, KBL, AEZ and JDL designed the trial protocol. SEM, HBM, KBL and GVZ drafted the manuscript. All authors have read and approved the final manuscript.<br><br>
<h3>pmcA509286</h3>How can Health Behavior Theory be made more useful for intervention research?
Abstract
Background
The present paper expresses the author's views about the practical utility of Health Behavior Theory for health behavior intervention research. The views are skeptical and perhaps even a bit exaggerated. They are, however, also based on 20-plus years of in-the-trenches research focused on improving health behavior practice through research.<br><br>Discussion
The author's research has been theoretically driven and has involved measurement of varying variables considered to be important theoretical mediators and moderators of health behavior. Regretfully, much of this work has found these variables wanting in basic scientific merit. Health Behavior Theory as we have known it over the last 25 years or so has been dominated by conceptualizations of behavior change processes that highlight cognitive decision-making. Although much of health behavior practice targets what <span class="yellow">people</span> do rather than what they think, the logic of focusing on thoughts is that what <span class="yellow">people</span> think about is the key to what they will do in the future, and that interventions that can measure and harness those processes will succeed to a greater extent than those that do not. Unfortunately, in the author's experience, the premise of cognitive theories has fallen short empirically in a number of ways. The cognitive schemata favored by most health behavior theories are difficult to measure, they do not predict behavioral outcomes very well, there is little evidence that they cause behavior, and they are hard to change directly.<br><br>Summary
It is suggested that health behavior researchers reconsider their use of these theories in favor of models whose variables are more accessible to observation and experimental manipulation and that most importantly have strong empirical support.<br><br><br><br>Background
The author has been conducting research on behavioral treatment of obesity for about 25 years. During that time, the dominant conceptual models guiding intervention development have been cognitive behavior models that have their origin in psychological theory. Those most often cited include the Health Belief Model [1], Protection Motivation Theory [2], Subjective Expected Utility Theory [3], the Theory of Reasoned Action [4], Social Cognitive Theory [5], and the Transtheoretical Model [6]. All of these theories are concerned with how <span class="yellow">people</span> make behavioral choices and the general idea is that <span class="yellow">people</span> decide what to do based on the extent to which they expect that their choices will produce results that they value. Much of the content of the theories is concerned with factors that may affect value/expectancy calculations. As summarized by Weinstein in a comparative review of four social psychological theories [7], variables thought to influence value/expectancy judgments include such factors as perceived rewards of current behavior, self-efficacy, normative beliefs, motivation, and the perceived consequences of not changing behavior.
Weinstein's summary is illustrative of the fact that Health Behavior Theory has tended to be particularly interested in understanding <span class="yellow">people</span>'s motivation to change behavior rather than ability to change. Moreover, motivation is thought to be the result of a relatively complex, but logical, interpretation of large quantities of information about self and environment. The theories that Weinstein reviewed deal almost exclusively with behavioral decision processes in <span class="yellow">people</span>'s minds. They have few if any terms relating to how information gets into <span class="yellow">peoples</span> minds or how subsets of it receive more or less attention. Broader health behavior theories such as Social Cognitive Theory or the Transtheoretical model have addressed issues and variables outside the <span class="yellow">person</span> to a greater extent, but the fundamental interest in and belief in psychological variables as the key force in determining health behavior remains.
The implications of the focus of health behavior theory on psychological determinants of behavioral decision-making for my own research area of interest, obesity treatment, are several. One is the inclusion of measures of psychological characteristics in most research protocols (e.g., assessment of behavioral intentions, self-efficacy, perception of barriers to change, perception of social support, and outcome expectations). A second is the inclusion of treatment elements that specifically target psychological perceptions and processes independent of the diet and physical activity behaviors that actually produce weight change (e.g., how to deal with emotional eating, how to deal with the frustration of lapses and relapses, and how to talk to yourself to increase self-motivation). A third is the belief that psychological reactions to treatment experiences themselves are very important and deserve independent attention. Common behavioral prescriptions for weight-loss goals and frequency of self-weighing are exemplary (i.e., recommending infrequent weighing to prevent discouraging feedback about progress and encouraging smaller and thus "more attainable" behavior and weight-loss goals in the belief that they will be more motivating).
The problem with the emphasis on cognitive variables in weight-control research is that they have so far failed to meet fundamental scientific criteria for empirical verification. Thus, they also have not led to a better understanding of the weight-loss process, have not improved our ability to predict weight-loss outcomes, and have not led to improvement in treatment methods. In some cases it is even arguable that they have made treatment worse. I will illustrate these problems with results from my own research.<br><br>Discussion
Like most behavioral researchers in the obesity area, I have attempted to measure elements of health behavior theory in every obesity intervention project I have ever conducted. I have assessed weight-loss goals, behavioral and weight-loss self-efficacy, psychological well-being, perceived barriers to diet and physical activity change, stages-of-change, and perceived social support. How well have empirical examinations of these factors fared as predictors of success in weight control?
Self-efficacy
We have examined the predictive value of self-efficacy assessments in several of our studies and describe the results from three of these here in more detail [8-10]. In the first study, self-efficacy was assessed at baseline, posttreatment, and one year later in 85 <span class="blue">men</span> participating in a 15-week weight-loss program [8]. The self-efficacy instrument had subscales for emotional states (e.g., anxiety) and situations (e.g., eating away from home). Higher baseline self-efficacy on both subscales was associated with greater weight loss in treatment and at 1- and 2-year follow-up. Emotional self-efficacy at posttreatment did not predict weight loss at 1- or 2-year follow-up. Situational self-efficacy at posttreatment predicted weight loss at 1-year but not 2-year follow-up.
The second study examined mood and situational self-efficacy in 55 <span class="blue">men</span> and 58 <span class="yellow">women</span> before and after a 16-week weight-loss treatment with a 1-year follow-up [9]. <span class="yellow">Women</span> had lower pretreatment self-efficacy than <span class="blue">men</span>. Self-efficacy was predictive of weight loss and maintenance in <span class="blue">men</span> but not in <span class="yellow">women</span>. Change in self-efficacy over time was positively related to weight change in <span class="yellow">women</span> but not in <span class="blue">men</span>.
The third study examined predictors of weight change over a 2-year period in 460 <span class="blue">men</span> and 1172 <span class="yellow">women</span> who received a low-intensity weight-loss intervention delivered through their HMO [10]. The self-efficacy measure was the WEL questionnaire. <span class="yellow">Men</span> again were found to have higher baseline self-efficacy than <span class="yellow">women</span>. Self-efficacy did not predict weight change in <span class="blue">men</span> but was positively, though weakly, related to weight change at 6 months only in <span class="yellow">women</span>.
Our overall conclusion from the analyses described above, as well as others not pursued in as great detail, is that self-efficacy is a weak predictor of weight loss and is inconsistent across study populations and gender. It tends to increase with weight loss. However, treatment-induced increases in efficacy are not predictive of longer-term weight-loss success.<br><br>Barriers to Adherence
We have also attempted to measure barriers to adherence to weight-control behaviors in many of our studies [11-14]. The instruments used for this have typically been formatted similarly to efficacy questionnaires in that <span class="yellow">people</span> are asked to indicate how difficult they find situational, knowledge, and motivational challenges to achieving diet and exercise changes. The findings in these studies have been quite consistent. Baseline assessments of perceived barriers to behavior change are not predictive of weight change. Weight loss is associated with reported decreases in perceived barriers. Treatment-induced change in perceived barriers are not predictive of future weight change. In other words, barrier perceptions as we have measured them do not appear to have pragmatic significance.<br><br>Weight Goals
Goal-setting has long been of interest to health behavior theory and in recent years has attracted attention in weight-loss research when it was realized that most <span class="yellow">people</span> who enter weight-loss treatments want to lose a lot more weight than is realistic given the potency of current weight-loss methodologies [15]. When asked to describe weight losses they deem to represent "dream, happy, acceptable, and disappointing," many individuals in treatment fail to reach even "disappointing" weight losses even though in objective medical terms the results are positive. Based on the argument that failure to reach gratifying weight-loss goals leads to psychological distress that lowers weight self-efficacy and undermines weight-loss efforts, it has become popular to recommend counseling in weight-loss treatments specifically targeting the lowering of weight-loss goals. The theoretical argument is that excessive outcome expectations undermine behavioral efforts. We have now completed three sets of formal analyses examining whether weight goals are predictive of weight-loss success. In one of these analyses the relationship between weight-loss goals, weight-loss goal attainment, and long-term (30 months) weight-loss attainment and psychological well-being were assessed in 69 <span class="blue">men</span> and 61 <span class="yellow">women</span> participating in an intensive behavioral treatment program [16]. Results indicated that weight-loss goals were unrealistically high on average and that lower goals were more likely to be reached. Nevertheless, weight-loss goals did not predict either short- or long-term weight losses and were not associated with elevated psychological distress. Two more recent analyses we have conducted looking at weight-loss goals as predictors of success have produced similar results [Linde JA, Jeffery RW, Levy RL, Pronk NP and Boyle RG, unpublished data [17]]. Weight-loss goals either did not predict weight loss at all or were slightly positively related to weight-loss success.<br><br>Perceived Social Support
Perceived social support is another psychological factor thought to influence health behavior decision-making. We have measured social support in a variety of ways in our studies, ranging from single-item questions to multipaged assessments attempting to differentiate among informational, instrumental, and emotional support. The results, unfortunately, have closely paralleled those we have seen with other assessments of barriers to adherence. Assessments of social support prior to treatment do not predict weight loss. Average reports of social support tend to parallel weight loss itself. When <span class="yellow">people</span> lose weight they report more social support. When they regain, they report less. In other words, perceptions of social support are not predictive of success in weight-loss treatments.<br><br>Frequency Weight Self-monitoring
Self-monitoring of health behavior is incorporated into many health behavior theories, usually as part of a <span class="yellow">person</span>'s assessment of achieved outcomes. Although self-monitoring is usually considered a positive element in the adoption of health behavior, in obesity treatment frequent self-monitoring of weight has tended to be down-played or even discouraged on the grounds that disappointing results (i.e., less than desired weight change) may undermine motivation. This is another example in which health behavior theory may have indirectly led to incorrect treatment recommendations. In weight-loss treatments, active discouragement of frequent self-observation of weight has become popular based on the premise that more frequent weighting will cause psychological stress and lower self-efficacy. Recently, we have examined the relationship between frequency of self-weighing and body weight in both clinical and population samples and have found, somewhat to our surprise, that frequency of self-weighing is one of the strongest single predictors of body weight cross-sectionally, and change in the frequency of self-weighing is one of the strongest predictors of weight change [Linde JA, Jeffery RW and French SA, unpublished data]. The direction of predictions, however, is opposite that derived from theory. <span class="yellow">People</span> who weigh themselves more weigh less and are more successful in losing weight.<br><br>Stage-of-Change
A final failure of current health behavior theory to prove useful in weight-control research is a recent examination of the relationship between a stage-of-change measure adopted from Prochaska and short- and long-term weight loss [18]. Categories of precontemplation, contemplation, preparation, and action were defined based on questions about weight-loss intentions and recent weight-loss attempts. Despite a large sample size, excellent follow-up rates, and well-measured objective outcomes, we were unable to demonstrate that staging algorithms recommended by proponents of the Transtheoretical Model could predict weight-loss outcomes.<br><br>Experimental Modification of Expectations
Our most recent effort to utilize health behavior theory in obesity intervention research is a study that attempted to examine the effectiveness of experimentally-induced outcome expectancies on weight loss [Finch EA, Linde JA, Jeffery RW, Rothman AJ and King CM, unpublished data]. Obese <span class="blue">men</span> and <span class="yellow">women</span> participated in an 8-week weight-loss program with 18-month follow-up in which they were assigned to one of two expectancy groups. The optimistic group was told that focusing exclusively on the positive benefits of weight loss would be valuable in ensuring that they remained motivated in their weight-loss efforts and was given assignments during weekly group sessions and homework between sessions to reinforce this optimistic mindset. A "balanced" expectancy group received the instructions that focusing on both the positive and negative aspects of weight loss, a balanced approach, would be most conducive to maintaining weight-loss motivation. This group also received assignments to reinforce their message. Results of this study indicated that the expectation induction was successful initially but difficult to maintain in the face of real weight-loss experience. We were also unable to show that experimentally-induced expectations influenced weight-loss success.<br><br>
Summary and Conclusion
To summarize the findings described above, I have had considerable difficulty over the last 25 years in confirming that the psychosocial variables favored by health behavior theory are of much value for obesity intervention research. They do not predict weight loss well, either as mediators or moderators. There is little evidence to support the idea that targeting them for intervention improves weight-loss outcomes. It is, of course, arguable that the weak findings relating to health behavior theory variables are due in large part to methodological weaknesses, either in measurement tools and/or their frequency of measurement. I would argue, however, that 25 years is long enough to wait for improved methods and that it is time to look elsewhere for variables that better predict weight-change outcomes and that, therefore, may form a better basis for improving future treatments.
Implication for Weight-Loss Treatment
Given the lack of success finding support for cognitive mediators of behavior change in weight loss, one might surmise that progress in improving weight-loss interventions over the last 20 years must have been dreary indeed. Somewhat surprisingly, however, that is not the case. In fact, the short-term (6 to 12 months) success of weight-loss treatments has approximately doubled over that time and several variables have been identified that reliably enhance treatment outcomes. It has been clearly shown experimentally that increasing treatment length [19], prescribing low-energy intakes [20], prescribing high-energy expenditure [21], using a deposit contract and group-based reward systems [22], and simplifying adherence to diet through meal substitutes [23] and exercise by providing exercise equipment [24] all improve initial weight loss. From a theoretical perspective, however, one thing is noteworthy about these successful innovations. Although not incompatible with health behavior theory, none of them are specifically derived from cognitive decision-making models. Indeed, health behavior theory does not include variables like these in its models.<br><br>Where Do We Go From Here?
The argument above about the practical limitations of many popular theories of health behavior is not meant to be a call to abandon theory. Behavior scientists have amassed much useful information about the principles underlying <span class="yellow">human</span> behavior that should be valuable for health behavior interventions. Much is known about <span class="yellow">human</span> perception, learning, motivation, and responsiveness to environmental opportunities and contingencies. Health behavior intervention lies at the interface between <span class="yellow">people</span> and their environment. Interventionists change aspects of the environment (cues, information, behavioral contingencies) with the intention of producing changes in how <span class="yellow">people</span> behave. What is needed to advance health behavior intervention is theory that addresses relationships between modifiable aspects of the environment and behavior. There is no doubt that cognitive processes are involved in these relationships. However, the extent to which current theories capture this is questionable. Data now available suggest that easily obtainable information about <span class="yellow">people</span>'s cognitive processes adds little to our ability to predict the results of interventions. Thus, it may be wise to pay more attention to applied theories like classical behavior theory [25], communications theory [26], and learning theory [27] than to those coming out of the social cognitive traditions.<br><br>
Competing interests
None declared.<br><br>
<h3>pmcA1524813</h3>Comparison of age-specific cataract prevalence in two population-based surveys 6 years apart
Abstract
Background
In this study, we aimed to compare age-specific cortical, nuclear and posterior subcapsular (PSC) cataract prevalence in two surveys 6 years apart.<br><br>Methods
The Blue Mountains Eye Study examined 3654 <span class="yellow">participants</span> (82.4% of those eligible) in cross-section I (1992–4) and 3509 <span class="yellow">participants</span> (75.1% of survivors and 85.2% of newly eligible) in cross-section II (1997–2000, 66.5% overlap with cross-section I). Cataract was assessed from lens photographs following the Wisconsin Cataract Grading System. Cortical cataract was defined if cortical opacity comprised ≥ 5% of lens area. Nuclear cataract was defined if nuclear opacity ≥ Wisconsin standard 4. PSC was defined if any present. Any cataract was defined to include <span class="yellow">persons</span> who had previous cataract surgery. Weighted kappa for inter-grader reliability was 0.82, 0.55 and 0.82 for cortical, nuclear and PSC cataract, respectively. We assessed age-specific prevalence using an interval of 5 years, so that <span class="yellow">participants</span> within each age group were independent between the two surveys.<br><br>Results
Age and gender distributions were similar between the two populations. The age-specific prevalence of cortical (23.8% in 1st, 23.7% in 2nd) and PSC cataract (6.3%, 6.0%) was similar. The prevalence of nuclear cataract increased slightly from 18.7% to 23.9%. After age standardization, the similar prevalence of cortical (23.8%, 23.5%) and PSC cataract (6.3%, 5.9%), and the increased prevalence of nuclear cataract (18.7%, 24.2%) remained.<br><br>Conclusion
In two surveys of two population-based samples with similar age and gender distributions, we found a relatively stable cortical and PSC cataract prevalence over a 6-year period. The increased prevalence of nuclear cataract deserves further study.<br><br><br><br>Background
Age-related cataract is the leading cause of reversible visual impairment in older <span class="yellow">persons</span> [1-6]. In Australia, it is estimated that by the year 2021, the number of <span class="yellow">people</span> affected by cataract will increase by 63%, due to population aging [7]. Surgical intervention is an effective treatment for cataract and normal vision (> 20/40) can usually be restored with intraocular lens (IOL) implantation.
Cataract surgery with IOL implantation is currently the most commonly performed, and is, arguably, the most cost effective surgical procedure worldwide. Performance of this surgical procedure has been continuously increasing in the last two decades. Data from the Australian Health Insurance Commission has shown a steady increase in Medicare claims for cataract surgery [8]. A 2.6-fold increase in the total number of cataract procedures from 1985 to 1994 has been documented in Australia [9]. The rate of cataract surgery per thousand <span class="yellow">persons</span> aged 65 years or older has doubled in the last 20 years [8,9]. In the Blue Mountains Eye Study population, we observed a one-third increase in cataract surgery prevalence over a mean 6-year interval, from 6% to nearly 8% in two cross-sectional population-based samples with a similar age range [10]. Further increases in cataract surgery performance would be expected as a result of improved surgical skills and technique, together with extending cataract surgical benefits to a greater number of older <span class="yellow">people</span> and an increased number of <span class="yellow">persons</span> with surgery performed on both eyes.
Both the prevalence and incidence of age-related cataract link directly to the demand for, and the outcome of, cataract surgery and eye health care provision. This report aimed to assess temporal changes in the prevalence of cortical and nuclear cataract and posterior subcapsular cataract (PSC) in two cross-sectional population-based surveys 6 years apart.<br><br>Methods
The Blue Mountains Eye Study (BMES) is a population-based cohort study of common eye diseases and other health outcomes. The study involved eligible permanent residents aged 49 years and older, living in two postcode areas in the Blue Mountains, west of Sydney, Australia. <span class="yellow">Participants</span> were identified through a census and were invited to participate. The study was approved at each stage of the data collection by the <span class="yellow">Human</span> Ethics Committees of the University of Sydney and the Western Sydney Area Health Service and adhered to the recommendations of the Declaration of Helsinki. Written informed consent was obtained from each <span class="yellow">participant</span>.
Details of the methods used in this study have been described previously [11]. The baseline examinations (BMES cross-section I) were conducted during 1992–1994 and included 3654 (82.4%) of 4433 eligible residents. Follow-up examinations (BMES IIA) were conducted during 1997–1999, with 2335 (75.0% of BMES cross section I survivors) participating. A repeat census of the same area was performed in 1999 and identified 1378 newly eligible residents who moved into the area or the eligible age group. During 1999–2000, 1174 (85.2%) of this group participated in an extension study (BMES IIB). BMES cross-section II thus includes BMES IIA (66.5%) and BMES IIB (33.5%) <span class="yellow">participants</span> (n = 3509).
Similar procedures were used for all stages of data collection at both surveys. A questionnaire was administered including demographic, family and medical history. A detailed eye examination included subjective refraction, slit-lamp (Topcon SL-7e camera, Topcon Optical Co, Tokyo, Japan) and retroillumination (Neitz CT-R camera, Neitz Instrument Co, Tokyo, Japan) photography of the lens. Grading of lens photographs in the BMES has been previously described [12]. Briefly, masked grading was performed on the lens photographs using the Wisconsin Cataract Grading System [13]. Cortical cataract and PSC were assessed from the retroillumination photographs by estimating the percentage of the circular grid involved. Cortical cataract was defined when cortical opacity involved at least 5% of the total lens area. PSC was defined when opacity comprised at least 1% of the total lens area. Slit-lamp photographs were used to assess nuclear cataract using the Wisconsin standard set of four lens photographs [13]. Nuclear cataract was defined when nuclear opacity was at least as great as the standard 4 photograph. Any cataract was defined to include <span class="yellow">persons</span> who had previous cataract surgery as well as those with any of three cataract types. Inter-grader reliability was high, with weighted kappa 0.82 for cortical cataract, 0.55 (simple kappa 0.75) for nuclear cataract and 0.82 for PSC grading. The intra-grader reliability for nuclear cataract was assessed with simple kappa 0.83 for the senior grader who graded nuclear cataract at both surveys. All PSC cases were confirmed by an ophthalmologist (PM).
In cross-section I, 219 <span class="yellow">persons</span> (6.0%) had missing or ungradable Neitz photographs, leaving 3435 with photographs available for cortical cataract and PSC assessment, while 1153 (31.6%) had randomly missing or ungradable Topcon photographs due to a camera malfunction, leaving 2501 with photographs available for nuclear cataract assessment. Comparison of characteristics between <span class="yellow">participants</span> with and without Neitz or Topcon photographs in cross-section I showed no statistically significant differences between the two groups, as reported previously [12]. In cross-section II, 441 <span class="yellow">persons</span> (12.5%) had missing or ungradable Neitz photographs, leaving 3068 for cortical cataract and PSC assessment, and 648 (18.5%) had missing or ungradable Topcon photographs, leaving 2860 for nuclear cataract assessment.
Data analysis was performed using the Statistical Analysis System (SAS, SAS Institute, Cary, NC, USA). Age-adjusted prevalence was calculated using direct standardization of the cross-section II population to the cross-section I population. We assessed age-specific prevalence using an interval of 5 years, so that <span class="yellow">participants</span> within each age group were independent between the two cross-sectional surveys.<br><br>Results
Characteristics of the two survey populations have been previously compared [14] and showed that age and sex distributions were similar. Table 1 compares <span class="yellow">participant</span> characteristics between the two cross-sections. Cross-section II <span class="yellow">participants</span> generally had higher rates of diabetes, hypertension, myopia and more users of inhaled steroids.
Cataract prevalence rates in cross-sections I and II are shown in Figure 1. The overall prevalence of cortical cataract was 23.8% and 23.7% in cross-sections I and II, respectively (age-sex adjusted P = 0.81). Corresponding prevalence of PSC was 6.3% and 6.0% for the two cross-sections (age-sex adjusted P = 0.60). There was an increased prevalence of nuclear cataract, from 18.7% in cross-section I to 23.9% in cross-section II over the 6-year period (age-sex adjusted P < 0.001). Prevalence of any cataract (including <span class="yellow">persons</span> who had cataract surgery), however, was relatively stable (46.9% and 46.8% in cross-sections I and II, respectively).
After age-standardization, these prevalence rates remained stable for cortical cataract (23.8% and 23.5% in the two surveys) and PSC (6.3% and 5.9%). The slightly increased prevalence of nuclear cataract (from 18.7% to 24.2%) was not altered.
Table 2 shows the age-specific prevalence rates for cortical cataract, PSC and nuclear cataract in cross-sections I and II. A similar trend of increasing cataract prevalence with increasing age was evident for all three types of cataract in both surveys. Comparing the age-specific prevalence between the two surveys, a reduction in PSC prevalence in cross-section II was observed in the older age groups (≥ 75 years). In contrast, increased nuclear cataract prevalence in cross-section II was observed in the older age groups (≥ 70 years). Age-specific cortical cataract prevalence was relatively consistent between the two surveys, except for a reduction in prevalence observed in the 80–84 age group and an increasing prevalence in the older age groups (≥ 85 years).
Similar gender differences in cataract prevalence were observed in both surveys (Table 3). Higher prevalence of cortical and nuclear cataract in <span class="yellow">women</span> than <span class="blue">men</span> was evident but the difference was only significant for cortical cataract (age-adjusted odds ratio, OR, for <span class="yellow">women</span> 1.3, 95% confidence intervals, CI, 1.1–1.5 in cross-section I and OR 1.4, 95% CI 1.1–1.6 in cross-section II). In contrast, <span class="blue">men</span> had slightly higher PSC prevalence than <span class="yellow">women</span> in both cross-sections but the difference was not significant (OR 1.1, 95% CI 0.8–1.4 for <span class="blue">men</span> in cross-section I and OR 1.2, 95% 0.9–1.6 in cross-section II).<br><br>Discussion
Findings from two surveys of BMES cross-sectional populations with similar age and gender distribution showed that the prevalence of cortical cataract and PSC remained stable, while the prevalence of nuclear cataract appeared to have increased. Comparison of age-specific prevalence, with totally independent samples within each age group, confirmed the robustness of our findings from the two survey samples. Although lens photographs taken from the two surveys were graded for nuclear cataract by the same graders, who documented a high inter- and intra-grader reliability, we cannot exclude the possibility that variations in photography, performed by different photographers, may have contributed to the observed difference in nuclear cataract prevalence. However, the overall prevalence of any cataract (including cataract surgery) was relatively stable over the 6-year period.
Although different population-based studies used different grading systems to assess cataract [15], the overall prevalence of the three cataract types were similar across different study populations [12,16-23]. Most studies have suggested that nuclear cataract is the most prevalent type of cataract, followed by cortical cataract [16-20]. Ours and other studies reported that cortical cataract was the most prevalent type [12,21-23].
Our age-specific prevalence data show a reduction of 15.9% in cortical cataract prevalence for the 80–84 year age group, concordant with an increase in cataract surgery prevalence by 9% in those aged 80+ years observed in the same study population [10]. Although cortical cataract is thought to be the least likely cataract type leading to a cataract surgery, this may not be the case in all older <span class="yellow">persons</span>.
A relatively stable cortical cataract and PSC prevalence over the 6-year period is expected. We cannot offer a definitive explanation for the increase in nuclear cataract prevalence. A possible explanation could be that a moderate level of nuclear cataract causes less visual disturbance than the other two types of cataract, thus for the oldest age groups, <span class="yellow">persons</span> with nuclear cataract could have been less likely to have surgery unless it is very dense or co-existing with cortical cataract or PSC. Previous studies have shown that functional vision and reading performance were high in <span class="yellow">patients</span> undergoing cataract surgery who had nuclear cataract only compared to those with mixed type of cataract (nuclear and cortical) or PSC [24,25]. In addition, the overall prevalence of any cataract (including cataract surgery) was similar in the two cross-sections, which appears to support our speculation that in the oldest age group, nuclear cataract may have been less likely to be operated than the other two types of cataract. This could have resulted in an increased nuclear cataract prevalence (due to less being operated), compensated by the decreased prevalence of cortical cataract and PSC (due to these being more likely to be operated), leading to stable overall prevalence of any cataract.
Possible selection bias arising from selective survival among <span class="yellow">persons</span> without cataract could have led to underestimation of cataract prevalence in both surveys. We assume that such an underestimation occurred equally in both surveys, and thus should not have influenced our assessment of temporal changes.
Measurement error could also have partially contributed to the observed difference in nuclear cataract prevalence. Assessment of nuclear cataract from photographs is a potentially subjective process that can be influenced by variations in photography (light exposure, focus and the slit-lamp angle when the photograph was taken) and grading. Although we used the same Topcon slit-lamp camera and the same two graders who graded photos from both surveys, we are still not able to exclude the possibility of a partial influence from photographic variation on this result.
A similar gender difference (<span class="yellow">women</span> having a higher rate than <span class="blue">men</span>) in cortical cataract prevalence was observed in both surveys. Our findings are in keeping with observations from the Beaver Dam Eye Study [18], the Barbados Eye Study [22] and the Lens Opacities Case-Control Group [26]. It has been suggested that the difference could be related to hormonal factors [18,22]. A previous study on biochemical factors and cataract showed that a lower level of iron was associated with an increased risk of cortical cataract [27]. No interaction between sex and biochemical factors were detected and no gender difference was assessed in this study [27]. The gender difference seen in cortical cataract could be related to relatively low iron levels and low hemoglobin concentration usually seen in <span class="yellow">women</span> [28]. Diabetes is a known risk factor for cortical cataract but in this particular population diabetes is more prevalent in <span class="blue">men</span> than <span class="yellow">women</span> in all age groups [29]. Differential exposures to cataract risk factors or different dietary or lifestyle patterns between <span class="blue">men</span> and <span class="yellow">women</span> may also be related to these observations and warrant further study.<br><br>Conclusion
In summary, in two population-based surveys 6 years apart, we have documented a relatively stable prevalence of cortical cataract and PSC over the period. The observed overall increased nuclear cataract prevalence by 5% over a 6-year period needs confirmation by future studies, and reasons for such an increase deserve further study.<br><br>Competing interests
The author(s) declare that they have no competing interests.<br><br>Authors' contributions
AGT graded the photographs, performed literature search and wrote the first draft of the manuscript. JJW graded the photographs, critically reviewed and modified the manuscript. ER performed the statistical analysis and critically reviewed the manuscript. PM designed and directed the study, adjudicated cataract cases and critically reviewed and modified the manuscript. All authors read and approved the final manuscript.<br><br>Pre-publication history
The pre-publication history for this paper can be accessed here:<br><br><br><br></body></html>