
<!doctype html><html lang="en"> <head><meta charset="utf-8"> 
<title>s800 inconsistencies</title> 
<style>  
.yellow { background-color:rgba(50, 180, 180, 0.5); } 
.red { background-color:rgba(214, 75, 79, 0.5); } 
.blue { background-color:rgba(75, 75, 214, 0.5); } 
table { border-collapse: collapse; } 
th, td { border: 1px solid black; padding: 4px; } 
th {  cursor: pointer; } 
th:hover { background: yellow; }
</style></head><body>
<h2>person</h2><span class="red">Not tagged name</span> - <span class="blue">Tagged name</span> - <span class="yellow">Other name</span><br><hr><h3>pmcA1551914</h3>Travel-Related Venous Thrombosis: Results from a Large Population-Based Case Control Study (MEGA Study)
Abstract
Background
Recent studies have indicated an increased risk of venous thrombosis after air travel. Nevertheless, questions on the magnitude of risk, the underlying mechanism, and modifying factors remain unanswered.<br><br>Methods and Findings
We studied the effect of various modes and duration of travel on the risk of venous thrombosis in a large ongoing case-control study on risk factors for venous thrombosis in an unselected population (MEGA study). We also assessed the combined effect of travel and prothrombotic mutations, body mass index, height, and oral contraceptive use.
Since March 1999, consecutive <span class="yellow">patients</span> younger than 70 y with a first venous thrombosis have been invited to participate in the study, with their partners serving as matched control individuals. Information has been collected on acquired and genetic risk factors for venous thrombosis. Of 1,906 <span class="yellow">patients</span>, 233 had traveled for more than 4 h in the 8 wk preceding the event. Traveling in general was found to increase the risk of venous thrombosis 2-fold (odds ratio [OR] 2.1; 95% confidence interval [CI] 1.5–3.0). The risk of flying was similar to the risks of traveling by car, bus, or train. The risk was highest in the first week after traveling. Travel by car, bus, or train led to a high relative risk of thrombosis in individuals with factor V Leiden (OR 8.1; 95% CI 2.7–24.7), in those who had a body mass index of more than 30 kg/m2 (OR 9.9; 95% CI 3.6–27.6), in those who were more than 1.90 m tall (OR 4.7; 95% CI 1.4–15.4), and in those who used oral contraceptives (estimated OR > 20). For air travel these synergistic findings were more apparent, while <span class="yellow">people</span> shorter than 1.60 m had an increased risk of thrombosis after air travel (OR 4.9; 95% CI 0.9–25.6) as well.<br><br>Conclusions
The risk of venous thrombosis after travel is moderately increased for all modes of travel. Subgroups exist in which the risk is highly increased.<br><br>
Background.
Recently there has been increasing concern that blood clots (thromboses) in the leg or lungs occur with greater frequency after air travel. Several theories have been put forward to explain why this increase might happen, including the fact that air passengers tend to not move around much, or possibly that reduced amounts of oxygen in the blood make the blood more likely to clot. Understanding what causes such clots is important as it would help us come up with suggestions of ways to prevent them.<br><br>Why Was This Study Done?
It is not possible to test in a controlled trial whether travel causes an increase in blood clots, so the next best way of studying this problem is to do a case-control study, in which <span class="yellow">people</span> with blood clots (cases) are compared with similar <span class="yellow">people</span> who don't have a blood clot (controls—in this case, the partners of the cases), and the differences in a number of contributing factors are assessed.<br><br>What Did the Researchers Do and Find?
Since 1999, the MEGA (Multiple Environmental and Genetic Assessment of Risk Factors for Venous Thrombosis) study has aimed to identify all <span class="yellow">people</span> in an area of the Netherlands who develop a blood clot for the first time, by seeking out <span class="yellow">people</span> who receive treatment for blood clots. At the time of this report, 1,906 <span class="yellow">people</span> with clots had been found; of these, 233 had traveled for more than four hours in the eight weeks preceding the event. Traveling in general was found to increase the risk of clots two-fold, and the risk was highest in the week after traveling. The risk of flying was similar to the risk of traveling by car, bus, or train, and was highest in the first week after traveling. Certain other factors increased the risk of a blood clot even more, such as having a particular mutation (known as factor V Leiden) in a gene involved in blood clotting, having a body mass index of more than 30 kg/m2 (over 30 kg/m2 is defined as being obese), being more than 1.90 meters tall, and using oral contraceptives. All these factors made the risk of clots especially after air travel worse; in addition, <span class="yellow">people</span> shorter than 1.60 meters also had an increased risk of thrombosis after air travel. However, it should be borne in mind that the number of cases in each of these various groups was quite small, and the overall risk of getting a thrombosis is still low.<br><br>What Do These Findings Mean?
Since the risks of thrombosis are increased for all types of long travel, it seems that the main factor causing the thrombosis is immobility. However, since the risk is even higher for air travel, the relative lack of oxygen may also play a part. One interesting aspect of this study is that the researchers used partners as controls; in order to be sure that doing this did not make the results invalid, the researchers had to carefully adjust for differences between the cases and controls, such as the fact that partners were generally of the opposite sex. In a related Perspective (DOI: 10.1371/journal.pmed.0030300), Kenneth Rothman discusses the study further.<br><br>Additional Information.
Please access these Web sites via the online version of this summary at http://dx.doi.org/10.1371/journal.pmed.0030307.<br><br><br><br>
Introduction
Interest in the role of air travel in the pathogenesis of venous thrombosis has heightened in the past 5 y [1–5]. Venous thrombosis was first linked to air travel in 1954 [6], and as air travel has become more and more common, many case reports and case series have been published since. Several clinical studies have shown an association between air travel and the risk of venous thrombosis. In a series of individuals who died suddenly at Heathrow Airport, death occurred far more often in the arrival than in the departure area [7]. Two similar studies described a “dose-response” relation: the risk of pulmonary embolism in air travelers increased with the distance traveled [5,8]. A number of case-control studies, however, have shown conflicting results [9–11]. More recently, a 2-fold increased risk in <span class="yellow">patients</span> who had traveled by air was described in a case-control study among 210 <span class="yellow">patients</span> and 210 controls [3]. A case-crossover study based on record linking in Australia described a 4-fold increased risk of venous thrombosis in the first 2 wk after a long-haul flight [1]. In terms of absolute risk, two studies found similar results: one performed in New Zealand found a frequency of 1% of venous thrombosis in 878 individuals who had traveled by air for at least 10 h [2], and a German study found venous thrombotic events in 2.8% of 964 individuals who had traveled for more than 8 h in an airplane, as compared to 1% in 1,213 controls [4]. The events in both studies were mostly asymptomatic.
The available evidence suggests that the overall risk of venous thrombosis is moderately increased after air travel. Nevertheless, many questions remain unanswered: the exact underlying mechanism is still unknown, and, related to this, it is not clear whether the risk is increased after air travel only or after long-distance travel in general. Furthermore, the effect of the combination of other risk factors for venous thrombosis and travel has not yet been systematically studied, with the exception of a study by Martinelli et al., who found an additionally increased risk in <span class="yellow">patients</span> with thrombophilia and <span class="yellow">patients</span> who used oral contraceptives [3].
The Multiple Environmental and Genetic Assessment (MEGA) study of risk factors for venous thrombosis is a large ongoing case-control study aimed at assessing the combined effect of genetic and acquired risk factors for venous thrombosis. Cases and control individuals are questioned about—among many other items—travel that occurred shortly before the event. This provides an opportunity to assess the effect of travel on the risk of thrombosis in an unselected population, as well as the effect of the combination of travel with several other risk factors for thrombosis.<br><br>Methods
Study Design
Since March 1999, consecutive <span class="yellow">patients</span> younger than 70 y with a first deep-vein thrombosis (DVT) or pulmonary embolism (PE) have been identified at six regional anticoagulation clinics in the Netherlands. Anticoagulant clinics monitor the anticoagulant therapy of all <span class="yellow">patients</span> in a well-defined geographical area, allowing us to identify consecutive and unselected <span class="yellow">patients</span> with thrombosis. <span class="yellow">Patients</span> who were unable to fill in the questionnaire (because of language or severe psychiatric problems), as well as those who died soon after the venous thrombosis or who were in the end stage of a disease and for that reason did not participate, were not included. All others were considered eligible. Partners of these <span class="yellow">patients</span> were invited as control individuals, and the same exclusion criteria were applied.
All <span class="yellow">participants</span> filled in a detailed standardized questionnaire on general demographic and anthropomorphic characteristics, as well as risk factors for venous thrombosis. The questionnaire was sent to all <span class="yellow">participants</span> within a few weeks after the event and covered the period of 1 y prior to the date of the thrombotic event (index date). When the <span class="yellow">participant</span> was unable to fill in the questionnaire we asked questions by phone, using a standardized mini-questionnaire. Three months after the <span class="yellow">patients</span> had discontinued their oral anticoagulant therapy, they were invited with their partners to the anticoagulation clinic for a blood sample. In those <span class="yellow">patients</span> who continued to take oral anticoagulant therapy for more than 1 y after the event, blood was drawn during therapy. If <span class="yellow">participants</span> were unable to come to the clinic, a buccal swab was sent by mail to replace the blood sample for DNA extraction.
The study protocol was approved by the Ethics Committee of the Leiden University Medical Center. Written informed consent was obtained from all <span class="yellow">participants</span> [12].<br><br>Validation Study of Thrombosis Diagnosis
Discharge letters or diagnostic reports of the venous thrombotic event were obtained for a sample of 742 <span class="yellow">patients</span> who had their first thrombosis between March 1999 and March 2000. The diagnostic management of the <span class="yellow">patients</span> was compared to the diagnostic procedure as described in the Dutch consensus [13]. Diagnosis of clinically suspected DVT of the leg is based on a clinical score, serial compression ultrasonography, and D-dimer assay. Objective testing of clinically suspected pulmonary embolism is based on perfusion and ventilation scintigraphy, ultrasonography of the leg veins, pulmonary angiography, or helical computed tomography. Out of 395 <span class="yellow">patients</span> with DVT of the leg, 384 (97%) were objectively diagnosed, while out of 347 <span class="yellow">patients</span> with PE, 271 (78%) were confirmed with objective testing as certainly having PE. Since the diagnosis appears to be made by objective methods in virtually all cases of DVT, while being more ambiguous for PE, we also analyzed these two manifestations of venous thrombosis separately.<br><br>Current Analysis
For the current analysis we were interested in the effects of travel, and its combined effect with other common risk factors for venous thrombosis. <span class="yellow">Patients</span> with a solitary arm thrombosis were excluded from this analysis. Of 3,902 eligible cases, diagnosed up to May 2002, 656 did not participate for various reasons (such as not willing or not reachable), leading to a response of 83%. A further 3% responded only to the mini-questionnaire, taken by phone, which did not contain questions about travel. Of the remaining 3,111 cases, 78% had a partner, 77% of whom were willing to participate, which left 1,867 couples. Additionally, 229 partners were identified for whom the corresponding <span class="yellow">patient</span> originally participated but was later found not to be eligible (aged over 70 y, or not a first thrombotic event). These control individuals were matched on sex and 5-y age groups to one of the 557 <span class="yellow">patients</span> whose partner did not want to participate, so an extra 229 pairs were included, making a total of 4,192 <span class="yellow">participants</span> (2,096 pairs). As part of the general questionnaire, questions had been asked about whether or not respondents had traveled for more than 4 h in the 3 mo before the index date, about the travel date, and about mode and duration of travel. We assessed the occurrence of thrombosis in relation to the period of time that had passed since traveling. Travel was defined in the analysis as at least one journey with a duration of at least four uninterrupted hours during the 8-wk period before the event. During the analysis it appeared that some individuals had provided dates of travel after the event instead of before. As there was only one opportunity to fill in such a date, we had no information about the period before the event. This was the case in 88 cases and 146 controls. We excluded these individuals and their partners, which left 3,812 <span class="yellow">participants</span> (1,906 pairs) for the analysis.
Because we selected the partners of the cases as control individuals, and because it turned out, as expected, that couples tend to travel together, we performed a conditional logistic regression analysis to calculate odds ratios (ORs) for the relation between travel and venous thrombosis. This method fully takes this matching into account, and leads to unbiased estimates, with adjustment for all factors in which cases and controls tend to be similar, e.g., socioeconomic class [14]. Details of this method can be found in Protocol S1. The 95% confidence intervals (CIs) were derived from the model.
We assessed the combined effect of traveling and the following risk factors for thrombosis: factor V Leiden mutation, prothrombin G20210A mutation, body mass index (BMI, as kg/m2), and height. We were also interested in the combined effect of oral contraceptive use and travel. However, as the control individuals were nearly always of the opposite sex (partners of the cases were recruited as controls), it was not possible to perform a matched analysis for the combination of oral contraceptive use and travel. Therefore, we performed a case-only analysis [15]. This method allows one to examine the association between two exposures among case individuals only. ORs are interpreted as a synergy index (SI) on a multiplicative scale, with independence assumed between the exposures. As this analysis depends only on cases, it was possible to perform it in all consecutive cases, therefore also including those without a partner.<br><br>Laboratory Measurements
Blood was collected from the antecubital vein into vacuum tubes containing 0.106 mol/l trisodium citrate. High molecular weight DNA was isolated from leukocytes using a standard salting-out procedure [16] and stored at −20 °C. When a blood sample was not available, DNA was extracted from buccal swabs. Three large <span class="yellow">cotton</span> swabs in a total of 6 ml of SDS–proteinase K solution (100 mM NaCl, 10 mM EDTA, 10 mM Tris-HCl [pH 8.0], 0.5% SDS, 0.1 mg/ml proteinase K) were obtained. Upon arrival, the proteinase K concentration was raised to 0.2 mg/ml, and the sample was incubated for 2 h at 65 °C. Subsequently, the solute was recovered by centrifugation. Potassium acetate was added to the supernatant to a final concentration of 1.6 M. After 15 min incubation on ice, proteins were removed using chloroform/isomylalcohol (24:1) treatment. The DNA in the water phase was subsequently ethanol precipitated. After centrifugation, the pellet was resuspended in 200 μl of 10 mM Tris-HCl and 10 mM EDTA (pH 8.0), and frozen at −20 °C until further analysis. The factor V Leiden mutation (G1691A) and the prothrombin mutation (G20210A) were simultaneously detected by duplex polymerase chain reaction [17,18]. The technician was blinded concerning the origin of the sample, i.e., whether it was from a <span class="yellow">patient</span> or from a control individual.<br><br>
Results
Venous Thrombosis in Relation to Travel
Table 1 shows general characteristics of the 1,906 <span class="yellow">patients</span>. They ranged in age from 18 to 69 y (median 50.4 y); 51% were <span class="yellow">men</span>. Diagnosis was DVT in 57% of the cases, PE in 32%, and both in 11%. As partners of the cases were included as control individuals, the sex distribution of the control individuals was the opposite; the age distribution differed only trivially.
Of the <span class="yellow">patients</span>, 233 individuals (12%) had traveled for at least 4 h by air, bus, car, or train within the 8 wk preceding the index date, as compared to 182 of the control individuals (9.5%). As the cases and control individuals were selected as couples, many pairs (135) had traveled together and were uninformative: as a consequence, 145 pairs in which either the <span class="yellow">patient</span> (98) or the control (47) had traveled could be used for the matched analysis (Table 2). This analysis showed a 2-fold increased risk of venous thrombosis for all modes of travel combined (OR 2.1; 95% CI 1.5–3.0) compared to not traveling. For air travel alone, 49 individuals (31 cases and 18 controls) had traveled without their partner, and the analysis yielded an OR of 1.7 (95% CI 1.0–3.1). For the other modes of travel (car, bus, and train) the relative risks were essentially similar to each other and to that of air travel (Table 2).
The risk of venous thrombosis was not clearly related to increased duration of travel (Table 2). Of the 233 events that occurred within 8 wk after traveling, 68 (29%) were diagnosed in the first week, after which the incidence gradually decreased (Figure 1).<br><br>The Effect of Other Risk Factors Combined with Travel
Prothrombotic mutations.
Information on the factor V Leiden mutation and prothrombin G20210A genotype was available for 1,713 <span class="yellow">patients</span> (90%) and for 1,629 of the control individuals (85%). Factor V Leiden was present in 259 cases (14%) and 84 control individuals (4%) (OR 3.1; 95% CI 2.4–4.1).
The risk of venous thrombosis was 8-fold increased in <span class="yellow">people</span> with factor V Leiden who had traveled by bus, car, or train (modes combined) as compared to noncarriers who did not travel (OR 8.1; 95% CI 2.7–24.7). For the combined effect of air travel and factor V Leiden, the risk seemed even slightly higher (OR 13.6; 95% CI 2.9–64.2).
The prothrombin G20210A mutation was found in 83 cases (4%) and in 29 control individuals (2%) (OR 2.7; 95% CI 1.7–4.2). The risk in individuals with this mutation who had traveled was difficult to interpret because of the small numbers but appeared not to increase more than additively (Table 3).<br><br>BMI.
The effect of BMI was studied by dividing individuals into three categories with the following BMI values: <25, 25–30, and >30 kg/m2 [19]. A BMI of 25–30 kg/m2 was associated with an increased risk of venous thrombosis (OR 1.4; 95% CI 1.2–1.7), and the risk was slightly higher in <span class="yellow">patients</span> with a BMI of 30 kg/m2 or more (OR 1.7; 95% CI 1.4–2.1).
The combined effect of a higher BMI and travel was the sum of the individual risks (Table 3), with the exception of <span class="yellow">people</span> with a BMI of more than 30 kg/m2 who traveled by car, bus, or train, for whom the risk was 10-fold increased (OR 9.9; 95% CI 3.6–27.6). This increase in risk was not found in <span class="yellow">people</span> who traveled by air.<br><br>Height.
Particularly short or tall <span class="yellow">people</span> may be subjected during travel to even more unnatural sitting positions than individuals with average height. Therefore, we assessed the effect of extremes of heights in combination with travel on the risk of venous thrombosis by comparing short (less than 1.60 m) and tall individuals (more than 1.90 m) with <span class="yellow">people</span> of average height (1.60–1.90 m). Compared to <span class="yellow">people</span> of average height, the risk of venous thrombosis was lower for short <span class="yellow">people</span> (OR 0.7; 95% CI 0.5–0.9) and did not differ for very tall individuals (OR 0.9; 95% CI 0.7–1.1). The risk was found to be increased in <span class="yellow">people</span> of more than 1.90 m who traveled (OR 4.7; 95% CI 1.4–15.4 for travel by car, bus, or train; OR 6.8; 95% CI 0.8–60.6 for air travel) compared to non-traveling <span class="yellow">people</span> of average height. Interestingly, the risk of venous thrombosis was also increased in short <span class="yellow">people</span> but only after air travel (OR 4.9; 95% CI 0.9–25.6), not after other modes of travel (OR 1.0; 95% CI 0.3–2.8, all relative to non-traveling <span class="yellow">people</span> of average height).<br><br>Oral contraception.
To study the association between oral contraceptive use, travel, and the risk of venous thrombosis, we performed a case-only analysis in all female <span class="yellow">patients</span> who were less than 50 y of age. As we needed only cases, it was also possible to include <span class="yellow">women</span> without a partner for this analysis, which led to a total of 1,025 <span class="yellow">women</span> aged under 50. Non-users who did not travel were used as the reference group. The case-only estimate of the SI for <span class="yellow">women</span> who traveled by car, bus, or train was 2.4 (95% CI 1.5–3.7). This indicates that the OR for the combination of travel and oral contraceptive use is 2.4 times the product of the separate ORs. As oral contraceptive use generally increases the risk of venous thrombosis about 4-fold [20], the combination with travel by car, bus, or train would lead to an estimated OR of about 20 (4 × 2 × 2.4). A clearly stronger interaction of travel by air with oral contraceptive use was found: the case-only estimate of the SI was 4.9 (95% CI 2.1– 11.4), which would result in an OR of about 40 (4 × 2 × 4.9).<br><br>
Effect of Risk Factors in DVT <span class="yellow">Patients</span> Only
Of the 1,906 cases, 1,082 were diagnosed with DVT. As the diagnosis was more unambiguous in these <span class="yellow">patients</span> (97% objectively diagnosed as compared to 78% of the PE <span class="yellow">patients</span>), we repeated the analysis in these <span class="yellow">patients</span> only.
In this analysis, the overall effect of travel on the risk of DVT was equal to the effect on all venous thrombosis (DVT and PE combined). However, here we found a stronger risk for travel by air (OR 3.0; 95% CI 1.3–7.1) then for travel by car, bus, or train (OR 1.9; 95% CI 1.1–3.2) (Table 4). Also, the analysis of the combination of other risk factors with travel resulted in more clear-cut effects, despite the smaller number of cases: the risk of DVT was still clearly synergistically increased in <span class="yellow">patients</span> with factor V Leiden who traveled, whereas the prothrombin G20210A mutation did not further increase the risk of travel (Table 4). Furthermore, a BMI of more than 30 kg/m2 in combination with travel yielded high ORs for DVT both in <span class="yellow">people</span> who traveled by car, bus, or train and in those who flew. Being more than 1.90 m tall in combination with travel resulted in higher ORs for DVT; the risk for short <span class="yellow">people</span> was more increased after travel by air (OR 6.8; 95% CI 1.1–43.5) (Table 4). The effect of oral contraceptive use in combination with travel by car, bus, or train on the risk of DVT was studied in 589 <span class="yellow">women</span> and was somewhat lower than the effect on the risk of all venous thrombosis (SI 1.9; 95% CI 0.9–4.2). In those who traveled by air it was also a bit lower (SI 3.4; 95% CI 1.3–8.8), but still indicative of a strong synergistic effect.<br><br>
Discussion
In this population-based case-control study, long-distance traveling increased the risk of venous thrombosis 2-fold. Travel by air increased the risk to the same extent as travel by car, bus, or train. The risk was highest in the first week after traveling. As venous thrombosis is a disease in which many factors (genetic and acquired) interact [21], we identified groups with additional risk factors in which the risk was further increased. This was the case for individuals with factor V Leiden, obese <span class="yellow">people</span> (BMI > 30 kg/m2), and short (only for travel by air) and tall <span class="yellow">people</span>, as well as for <span class="yellow">women</span> using oral contraceptives. Some of these synergistic effects were more apparent for air travel.
Although the studies that have been published so far have not yielded entirely consistent results, those that did report an increased risk of venous thrombosis in air travelers showed similar risk estimates of a 2- to 3-fold increased risk (even in one with asymptomatic events only [4]). The occurrence of venous thrombosis was highest in the first week after travel, and slowly declined afterwards, a pattern that was also described in a recent record-linking study from Australia [1], supporting a causal relation.
As a possible mechanism for an extra risk in travelers who <span class="yellow">fly</span>, an effect of hypobaric hypoxia on the coagulation system was postulated, which has already been studied a number of times, mainly in hypobaric chambers, with unclear results so far. Our study showed an increased risk in all types of travel, which suggests that the increased risk of flying is caused mainly by immobilization. Additionally, the risk is further increased in short and tall <span class="yellow">people</span>, who are likely to experience more immobilization and venous compression than other travelers. However, as some of our findings were more pronounced for air travel, we cannot exclude an additional effect of hypobaric hypoxia, possibly in risk groups only. This possibility is supported by a recent study of our group [22] in which we found that thrombin generation occurred in some healthy volunteers after flying for 8 h but happened to a far lesser extent after being immobilized for 8 h in a cinema. The high response in the fliers was associated with the presence of risk factors for thrombosis, i.e., oral contraceptive use, the factor V Leiden mutation, and the combination of the two. This finding indicates an effect of an additional factor in an airplane, such as hypobaric hypoxia, to which mainly individuals with risk factors respond.
None of the studies published so far have systematically studied the effect of traveling in combination with other risk factors, with the exception of the study by Martinelli et al. [3]. In an analysis of 210 <span class="yellow">patients</span>, they found a 16-fold increased risk for <span class="yellow">patients</span> who traveled by air and had some form of thrombophilia, as well as a 14-fold increased risk in <span class="yellow">women</span> who flew and used oral contraceptives, findings that confirm both the results of the present study and our finding of activated coagulation in individuals with risk factors after flying [22].
The finding that taller and shorter <span class="yellow">people</span> had an increased risk of venous thrombosis after traveling should be interpreted with some caution, as the numbers were small in these strata. On the other hand, it is biologically plausible: very tall <span class="yellow">people</span> are subjected to even more cramped seating than average-height individuals, and very short <span class="yellow">people</span>'s feet may not touch the floor, which would lead to extra compression of the popliteal veins. Interestingly, the increased risk for short <span class="yellow">people</span> was only found in <span class="yellow">people</span> who traveled by air. This may have to do with the fact that seats in cars are generally lower, and more individually adjustable, than those in airplanes.
As the diagnosis of DVT is usually more unambiguous than that of PE [23], as was the case in our study population as well, we repeated the analysis using only DVT as the outcome of interest (97% objectively diagnosed). In this analysis, despite using smaller numbers, most findings were either similar or appeared more evident, and inconsistencies that were found when using both DVT and PE as endpoints disappeared.
To our knowledge, this is the first large population-based case-control study in which the effect of travel on the risk of venous thrombosis has been studied. Because the control individuals were closely matched, being partners of the cases, and couples tend to travel together, only the cases and control individuals who had not traveled together could be used for the analysis. Also because of this design, the effect of sex and age could not be studied. It has to be noted, however, that for all other research questions on the effect of genetic and acquired risk factors on the risk of venous thrombosis, this design has no limitations and the close matching of cases and controls renders confounding by, for instance, lifestyle and socioeconomic class less likely than in previous unmatched studies (see also Protocol S1). Another advantage of this approach is the minimization of recall bias, as the cases and controls would generally fill in the questionnaire together.
Many questions are still left unanswered that necessitate more research. First of all, our study results apply only to <span class="yellow">people</span> younger than 70 y of age. Furthermore, it is likely that other characteristics exist that also increase the risk—<span class="blue">person</span>-specific (e.g., other drug use), behavioral (e.g., use of sleeping pills or alcohol consumption), and flight-specific (e.g., class or seating)—that need to be identified. These further variables are part of our ongoing study as part of the World Health Organization Research Initiative into the Global Hazards of Travel (WRIGHT study). For those who have an increased risk, such as oral contraceptive users and individuals with factor V Leiden, prevention may be warranted. Prevention may vary from simple measures, such as exercises during the flight, to measures that carry a risk themselves, such as anticoagulants. Specific studies are needed to assess the efficacy of these measures and their risk–benefit ratio.
It can be concluded that the risk of venous thrombosis is 2-fold increased for all travelers and to the same extent for all modes of travel. In individuals who use oral contraceptives, are carriers of the factor V Leiden mutation, or are particularly tall, short, or obese, this risk is considerably higher, to such an extent that studies into the efficacy of prophylactic measures are required.<br><br>Supporting Information<br><br>
<h3>pmcA2538543</h3>Personal and environmental correlates of active travel and physical activity in a deprived urban population
Abstract
Background
Environmental characteristics may be associated with patterns of physical activity in general or with particular types of physical activity such as active travel (walking or cycling for transport). However, most studies in this field have been conducted in North America and Australia, and hypotheses about putative correlates should be tested in a wider range of sociospatial contexts. We therefore examined the contribution of putative personal and environmental correlates of active travel and overall physical activity in deprived urban neighbourhoods in Glasgow, Scotland as part of the baseline for a longitudinal study of the effects of opening a new urban motorway (freeway).<br><br>Methods
We conducted a postal survey of a random sample of residents (n = 1322), collecting data on socioeconomic status, perceptions of the local environment, travel behaviour, physical activity and general health and wellbeing using a new 14-item neighbourhood rating scale, a travel diary, the short form of the International Physical Activity Questionnaire (IPAQ) and the SF-8. We analysed the correlates of active travel and overall physical activity using multivariate logistic regression, first building models using personal (individual and household) explanatory variables and then adding environmental variables.<br><br>Results
Active travel was associated with being younger, living in owner-occupied accommodation, not having to travel a long distance to work and not having access to a car, whereas overall physical activity was associated with living in social rented accommodation and not being overweight. After adjusting for personal characteristics, neither perceptions of the local environment nor the objective proximity of respondents' homes to motorway or major road infrastructure explained much of the variance in active travel or overall physical activity, although we did identify a significant positive association between active travel and perceived proximity to shops.<br><br>Conclusion
Apart from access to local amenities, environmental characteristics may have limited influence on active travel in deprived urban populations characterised by a low level of car ownership, in which <span class="yellow">people</span> may have less capacity for making discretionary travel choices than the populations studied in most published research on the environmental correlates of physical activity.<br><br><br><br>Background
Until recently, research on correlates of physical activity was dominated by studies of individual demographic and psychosocial characteristics [1]. This reflected an emphasis on promoting sport, recreation or health-directed exercise using techniques to encourage individual behaviour change [2]. However, there is little evidence that such approaches are effective in increasing physical activity in the medium-to-long term [3]. If habitual patterns of behaviour are environmentally cued, sustained change is likely to require a supportive environment in which <span class="yellow">people</span> can be active [4,5]. There is therefore increasing interest in the influence of the social and physical environment on physical activity.
With respect to the physical (natural or built) environment, a growing body of evidence suggests that certain environmental characteristics may be associated with patterns of physical activity in general or with particular types of physical activity such as walking or cycling as modes of transport [4-10]. Among the correlates most frequently identified in such reviews – some ascertained using 'objective' measures, and others in terms of <span class="yellow">people</span>'s perceptions – are the aesthetic quality of the surroundings, the presence of pavements (sidewalks), the convenience of facilities for being active, the availability of green space, access to amenities (destinations) within walking or cycling distance, safety from traffic and personal attack, and the lack of heavy traffic. Some of these local characteristics reflect higher-order aspects of urban design and spatial policy such as population density, connectivity and mixed land use [6,8]. Importantly, different characteristics may be associated with different types of physical activity; for example, Owen and colleagues found that the aesthetic quality of the surroundings was associated with walking for exercise or recreation and with walking in general, but not with walking for transport, whereas perceptions of traffic were associated with walking for transport and walking in general, but not with walking for exercise or recreation [5].
Despite the growing volume of published studies in this field, many authors remain circumspect in their interpretation of the available evidence. Giles-Corti and Donovan have described access to a supportive physical environment as a necessary, but insufficient, condition for an increase in physical activity in the population [11], while Handy found 'convincing' evidence of an association between physical activity and the built environment in general but 'less convincing' evidence as to which specific environmental characteristics were most strongly associated [7]. One limitation of the available evidence is that most research has been conducted in North America and Australia [9,12], and it is not clear whether associations observed in those countries are generalisable to other settings with different aggregate socioeconomic characteristics (e.g. wealth or access to private cars) or environmental characteristics (e.g. climate, patterns of land use, or availability of public transport). For example, North American researchers are often interested in the presence or absence of pavements (sidewalks), but it is unusual for streets in the United Kingdom (UK) not to have a pavement or footpath beside them. Hypotheses about putative environmental correlates of physical activity therefore need to be tested in a wider range of settings.
A more profound limitation of the available evidence is that identifying a relationship between, for example, urban form and walking for transport is not the same thing as showing that changing the built environment will lead to a change in behaviour [13]. Few researchers have taken up the opportunity (or challenge) presented by 'natural experiments' to investigate the effects of environmental interventions on physical activity [14]. We therefore established a longitudinal study to examine changes associated with the opening of a new urban section of the M74 motorway (freeway) currently under construction in Glasgow, Scotland. The rationale and design for this study have been described previously [15]. It is claimed that the new motorway, which will mostly pass through or close to densely-populated urban neighbourhoods, will contribute to the regeneration of a region which includes some of the most deprived and least healthy working-class communities in Europe [16]. It is also claimed that the new motorway will divert traffic from local streets, reduce traffic noise and bring new local employment opportunities, thereby improving characteristics of the local environment held to be associated with active travel. Others claim that the new motorway will encourage car use, degrade the aesthetic quality of the surroundings and reduce the safety and attractiveness of routes for pedestrians and cyclists across the line of the motorway – all changes which may be expected to discourage active travel [15]. The eventual aim of the M74 study will be to assess the effects of this major modification to the urban built environment and transport infrastructure on perceptions of the local environment and on population health and health-related behaviour, the primary outcome of interest being a change in the quantity of 'active travel' (walking and cycling for transport).
In this paper, we report findings from the cross-sectional (baseline) phase of the study which contribute evidence on the environmental correlates of physical activity in this comparatively deprived urban population. We focus on two specific hypotheses: first, that levels of active travel and overall physical activity vary with demographic and socioeconomic characteristics, but not necessarily in the same way; second, that these relationships may be partly explained by the perceived characteristics of the local environment in which <span class="yellow">people</span> live and by their objectively-assessed proximity to motorway and major road infrastructure.<br><br>Methods
Delineation of study areas
We used spatially referenced census and transport infrastructure data held and analysed in a geographical information system (GIS), combined with field visits, to delineate three study areas in Glasgow with similar aggregate socioeconomic characteristics and broadly similar topographical characteristics apart from their proximity to urban motorway infrastructure (Table 1, Figure 1). All three study areas extended from inner mixed-use districts close to the city centre to residential suburbs, contained major arterial roads other than motorways, and contained a mixture of housing stock including traditional high-density tenements, high-rise flats and new housing developments (Figure 2).<br><br>Sampling and survey administration
We used the Royal Mail Postcode Address File (PAF) (version 2005.3) to identify all residential addresses whose unit postcode (zip code) was within one of the study areas (total n = 35601) and drew a random sample of 3000 households from each area. Unit postcodes (e.g. G12 8RZ) are the smallest available unit of postal geography in the UK; residential unit postcodes cover about 15 addresses on average. We sent the survey to all households (total n = 9000) between 28 September and 4 October 2005 and resent the survey to all non-responding households between 26 and 31 October 2005. We alerted households to the survey by means of a postcard sent a few days in advance, used coloured paper for some of the survey materials, and posted survey packs in white envelopes printed with the university crest; these techniques have been shown in a meta-analysis to be associated with increased response rates to postal surveys [17]. We asked householders to ensure that the questionnaire was completed by a resident aged 16 or over; if more than one resident was eligible, we asked householders to select the <span class="blue">person</span> with the most recent birthday. Respondents who consented to follow-up were entered into a prize draw to win a £50 (€63; US$92) gift voucher. Responses received more than three months after the first mailing wave were disregarded in analysis.<br><br>Data collection
The questionnaire included items on demographic and socioeconomic characteristics, health and wellbeing (including the the SF-8 scale), perceptions of the local environment, travel behaviour and the short form of the International Physical Activity Questionnaire (IPAQ) (Additional file 1). We developed a new 'neighbourhood scale' to assess perceptions of relevant characteristics of the local environment (aesthetics, green space, access to amenities, convenience of routes, traffic, road safety and personal safety). The development, principal components analysis and reliability of the items in this scale and the derivation and reliability of summary variables are reported in an accompanying paper [18].<br><br>Data cleaning and derivation of variables
Demographic and socioeconomic characteristics
We excluded from analysis all respondents who failed to enter their age or sex. We then examined the distributions of all raw variables and carried out range and consistency checks to identify any anomalous values or variables with a high proportion of missing responses. As a consequence, we collapsed responses on distance to place of work or study, housing tenure, car access and working situation into fewer categories by merging categories with small numbers of responses; we also disregarded household composition and working situation of spouse or partner in analysis because of the large numbers of missing values for these variables.<br><br>Health and wellbeing
We calculated body mass index (BMI) by converting, where necessary, self-reported heights and weights from imperial to metric units and dividing the height in metres by the square of the weight in kilograms; we also categorised respondents into quintiles of BMI. We calculated physical (PCS-8) and mental (MCS-8) health summary scores from the SF-8 data and scaled these to population norms using the method and coefficients given in the SF-8 manual [19].<br><br>Objective environmental characteristics
We linked each record to the unit postcode of residence. We then constructed concentric buffers at 100-metre intervals up to 500 metres around the routes and access points of existing and planned motorways and around the network of other major (A- and B- class) roads, and assigned each respondent to a category of proximity to each type of road infrastructure (within 100 metres, 101–200 metres, etc.) based on the location of the centroid of their unit postcode.<br><br>Travel behaviour
For travel time analysis we included travel diaries which recorded no travel at all, but we disregarded travel data from respondents who had not been at home on the day of the travel diary, whose questionnaire had been misprinted such that the travel diary pages were unusable, who had recorded journeys without reporting valid quantitative data on the durations of those journeys, or whose completed travel diary appeared implausible. We also disregarded journeys whose purpose was not stated or was beyond the scope of the travel diary (Additional file 1, page 8). We summed the reported travel time for each mode of transport, calculated a total travel time by active modes (walking plus cycling) and by all modes combined, and calculated the proportion of total travel time contributed by each mode of transport.<br><br>Physical activity
We cleaned and analysed IPAQ data in accordance with the IPAQ scoring protocol . We therefore disregarded physical activity data from respondents who had reported more than 16 hours of physical activity per day or who had missing or internally inconsistent data on the frequency or duration of any of the three categories of physical activity (walking, moderate-intensity activity or vigorous activity). We also recoded reported durations of activity of less than ten minutes to zero, and of greater than 180 minutes to 180 minutes. We calculated the estimated total physical activity energy expenditure for each respondent (MET-min/week) and used a combination of frequency, duration and total energy expenditure to assign each respondent to a 'high', 'moderate' or 'low' category of overall physical activity in accordance with the prescribed IPAQ algorithm. The 'high' category corresponds to a sufficient level of physical activity to meet current public health recommendations for adults [20].<br><br>
Analysis
We considered it unlikely that the statistical assumptions required for linear regression could be met because the distributions of time spent walking and cycling and of estimated total physical activity energy expenditure were both strongly positively skewed and dominated by a large number of zero values which meant that the data were not amenable to log-transformation. We therefore modelled the correlates of active travel and physical activity using multivariate logistic regression. We defined 'active travel' as a binary condition achieved by any respondent who had reported at least 30 minutes of travel by walking, cycling or both in their travel diary, reflecting the current recommendation that adults should accumulate at least 30 minutes of moderate-intensity physical activity on most days of the week [20], and we defined 'physical activity' as a binary condition achieved by any respondent whose overall physical activity was categorised as 'high' using IPAQ. We then built separate multivariate models for active travel and physical activity following the method of Hosmer and Lemeshow [21], first including only 'personal' (individual or household) variables and then adding 'environmental' variables (Additional file 2).<br><br>
Results
Response
We received 1345 completed questionnaires. After subtracting from the numerator 23 completed questionnaires with missing critical demographic data (age or sex), and after subtracting from the denominator 676 addresses from which survey packs were returned as undeliverable, this left 1322 valid responses to be entered into analysis – a response rate of 1322/(9000-676) = 15.9%.<br><br>Characteristics of study <span class="yellow">participants</span>
Demographic and socioeconomic characteristics
Respondents were aged between 16 and 89 years (median age 48 years). 804 (61%) were <span class="yellow">women</span>. Only 136 (26%) of the <span class="yellow">men</span> and 145 (18%) of the <span class="yellow">women</span> reported having access to a bicycle. For those who usually travelled to a place of work or study, the median reported distance was 3.5 miles (about 5.5 kilometres). Other characteristics of study <span class="yellow">participants</span> are summarised in Table 2.<br><br>Health and wellbeing
25% of respondents reported difficulty walking for a quarter of a mile, 39% reported a long-term health problem or disability, and 50% were overweight (median BMI 25.1 kg/m2). The median mental health summary score (MCS-8) was significantly lower (i.e. poorer) than the population norm (median 47.3, 95% CI 46.4 to 48.1); the median physical health summary score (PCS-8) was not significantly different from the population norm (median 50.9, 95% CI 49.6 to 51.7).<br><br>
Descriptive data on travel behaviour and physical activity
Travel behaviour
1099 travel diaries were suitable for travel time analysis. <span class="yellow">Men</span> and <span class="yellow">women</span> were equally likely to have returned usable travel time data, but respondents who were older, retired, or living in social rented accommodation or who did not have access to a car were less likely to have returned usable data. On average, respondents recorded about an hour's travel per day (mean 61.5 minutes, median 50.0 minutes), of which a minority was spent using active modes of transport (walking or cycling: mean 20.0 minutes, median 10.0 minutes) (Table 3). 304 respondents (28%) recorded at least 30 minutes of active travel, of whom 294 (97%) recorded at least 30 minutes of walking.<br><br>Physical activity
833 respondents returned complete physical activity data suitable for analysis. <span class="yellow">Women</span> and respondents who were older, retired, or living in social rented accommodation or who did not have access to a car were less likely to have returned usable data. Respondents reported a mean of 318 minutes' walking per week and a mean estimated total physical activity energy expenditure of 3000 MET-minutes per week (Table 4). Only 316 respondents (38%) were categorised as having achieved a 'high' (i.e. sufficient) level of physical activity.<br><br>
Correlates of active travel
Active travel was significantly associated with being younger, living in owner-occupied accommodation, not having to travel more than four miles to work, having access to a bicycle, not having access to a car, and the absence of any difficulty walking. The final best model of the 'personal' correlates of active travel provided satisfactory goodness-of-fit (Hosmer and Lemeshow test: χ2 = 13.04, df = 8; P = 0.11) and explained nearly one-fifth of the total variance in active travel (Nagelkerke's R2 = 18.7%) (Table 5). Adding 'environmental' variables to the model showed an additional significant positive association between active travel and perceived proximity to shops, and an additional significant negative association between active travel and perceived road safety for cyclists. The final best model of the personal and environmental correlates of active travel also provided satisfactory goodness-of-fit (Hosmer and Lemeshow test: χ2 = 10.61, df = 8; P = 0.23) and explained slightly more of the total variance in active travel than did the personal model alone (Nagelkerke's R2 = 20.1%) (Figure 3).
In order to aid interpretation, we also partitioned the dataset into two strata ('No car available' and 'Car available') and refitted the final model separately to each stratum of the dataset (Table 6). This showed that the subset of respondents with no access to a car accounted for the significant overall relationship between active travel and access to a bicycle, whereas those with access to a car accounted for the significant overall relationships with distance to place of work or study and perceptions of the local environment. The relationship with difficulty walking was also stronger in this group than in those without access to a car.<br><br>Correlates of physical activity
Physical activity was significantly associated with living in social-rented accommodation, not being overweight, and the absence of any difficulty walking. The final best model of the 'personal' correlates of physical activity provided satisfactory goodness-of-fit (Hosmer and Lemeshow test: χ2 = 3.89, df = 7; P = 0.89) and explained about one-sixth of the total variance in physical activity (Nagelkerke's R2 = 15.9%) (Table 7). Adding 'environmental' variables to the model showed an additional significant negative association between physical activity and perception of traffic volume (i.e. respondents who perceived there to be a higher volume of traffic were more likely to report physical activity). The final best model of the personal and environmental correlates of physical activity also provided satisfactory goodness-of-fit (Hosmer and Lemeshow test: χ2 = 3.86, df = 8; P = 0.87) and explained slightly more of the total variance in physical activity than did the personal model alone (Nagelkerke's 16.6%) (Figure 3).<br><br>
Discussion
Principal findings
In this deprived urban population, the likelihood of reporting active travel was associated with being younger, living in owner-occupied accommodation, not having to travel a long distance to work and not having access to a car, whereas overall physical activity was associated with living in social-rented accommodation and not being overweight. After adjusting for individual and household characteristics, neither perceptions of the local environment nor the objective proximity of respondents' homes to motorway or major road infrastructure appeared to explain much of the variance in active travel or overall physical activity, although we did find a significant positive association between active travel and perceived proximity to shops.<br><br>Representativeness and completeness of survey data
Our difficulty in obtaining a representative sample of the resident population is not unique to our study. Although our final response rate was low, it was almost identical to that achieved in a recent population-based intervention study elsewhere in Glasgow [22]. Some of the challenges of recruiting research <span class="yellow">participants</span> in areas of deprivation have been described elsewhere [23]; these are superimposed on a downward trend in participation in even the best-resourced national population surveys [24] and an upward (and socially biased) trend in opt-outs from the main alternative sampling frame, the edited electoral register [25]. Although our achieved sample contained a higher proportion of respondents from owner-occupied and car-owning households than predicted from 2001 census data for the same census output areas, these differences may be partly accounted for by an upward background trend in owner occupation and car access between 2001 and 2005. Our achieved sample is still clearly disadvantaged overall, in terms of socioeconomic and health status, compared with the country as a whole. It also contains sufficient heterogeneity to enable us to examine, in time, how the effects of the intervention are distributed between socioeconomic groups. We therefore consider our achieved sample fit for purpose.
We had to disregard a substantial proportion of cases in analysis because respondents had returned unusable travel time data or had returned physical activity data that were incomplete, internally inconsistent or included a 'Don't know' response and were therefore unacceptable according to the IPAQ scoring protocol. Most published studies using the same, short form of IPAQ have either not reported the distribution of the continuous summary measures or have not reported data for the UK separately from those for other countries where higher levels of physical activity are reported. Despite the high proportion of missing physical activity data in our dataset, however, the aggregate continuous data we obtained were broadly comparable to those reported in Rütten and colleagues' study of a random sample of UK adults [26]. We could have included more cases in physical activity analysis by, for example, imputing missing values, but the results would not have been comparable with others' owing to the substantial deviations from the scoring protocol which would have been required. The frequency of unusable responses was not reported in the international multi-centre study which originally established the validity and reliability of IPAQ [27]. It is possible that offering a 'Don't know' option in the self-completed IPAQ questionnaire encourages respondents to select this rather than to enter what may be a reasonably precise estimate of the actual time spent in physical activity; the respondent has no way of knowing that a single 'Don't know' response will result in all of their physical activity data being disregarded in analysis. This should be considered in any future revision of the IPAQ questionnaire and scoring protocol.<br><br>Contribution of active travel to overall physical activity
The explanatory variables that were significantly associated with active travel but not with physical activity (distance to place of work or study, access to a bicycle, access to a car, perceived proximity to shops, and perceived road safety for cyclists) all have an obvious intuitive relationship with the use of walking or cycling as modes of transport. That they were not significantly associated with overall physical activity suggests either that active travel contributes only a minority of respondents' overall physical activity or that other factors not measured in this study are more important correlates of overall physical activity than those which determine active travel. A crude comparision of the quantity of active travel reported in the one-day travel diaries with the quantities of physical activity reported using IPAQ suggests that on average, active travel may indeed make only a small (~15%) contribution to overall physical activity in this study population. However, the real contribution may be substantially greater than this if, as has been shown previously, respondents tend to over-report their physical activity using IPAQ [28]. There can be little doubt that active travel makes a substantial contribution to the total quantity of walking reported in this study population. Irrespective of the true contribution of active travel to overall physical activity, however, it remains likely that other unmeasured personal and social factors beyond the scope of this study may be more important correlates of overall physical activity.<br><br>Socio-spatial patterning of active travel and overall physical activity
Respondents living in owner-occupied households were more likely to report active travel than those living in social-rented accommodation, but less likely to report sufficient overall physical activity. Since neither working situation nor perceived financial situation emerged as significantly associated with active travel or overall physical activity, housing tenure and car access are the remaining explanatory variables in this dataset which can be interpreted as markers of socioeconomic status. Although having access to a car clearly reflects the possession of a material asset, it has been argued that this is a less direct marker of socioeconomic status than some other markers because, in Scotland at least, access to a car is a more-or-less essential requirement for living in many rural areas, whereas it is possible to live in a dense urban settlement such as Glasgow without using a car. In the final models in this study, therefore, housing tenure may be regarded as the primary marker of socioeconomic status. The findings consequently suggest conflicting socioeconomic gradients in prevalence: more advantaged respondents were more likely to report active travel, but more disadvantaged respondents were more likely to report sufficient overall physical activity. The higher prevalence of sufficient overall physical activity among the more disadvantaged despite their lower propensity for active travel is likely to reflect higher quantities of physical activity in other domains, particularly occupational and domestic activities, since leisure-time physical activity tends to be higher among more advantaged groups [29].<br><br>Environmental characteristics: paradoxical, unmeasured, or irrelevant?
The two environmental variables that emerged as significantly associated with active travel, particularly among those without access to a car, were perceived proximity to shops and perceived road safety for cyclists. The positive association with perceived proximity to shops suggests that for active travel to be undertaken in this population, it may be more important that <span class="yellow">people</span> live close to the amenities they need than that they live in an environment with more favourable subjective or discretionary considerations such as attractiveness or noise. This would be consistent with an understanding that walking as a mode of transport is primarily a way of undertaking journeys which have to be made anyway, as opposed to more discretionary (recreational) forms of walking which may be more susceptible to the influence of less-structural characteristics.
Although the negative association with perceived road safety for cyclists appears counter-intuitive, similar 'paradoxical inverse relationships' have been reported elsewhere, for example by Titze and colleagues in a study of the correlates of cycling among students [30] and by Humpel and colleagues in a study of correlates of walking for pleasure [31]. Titze and colleagues suggest that respondents who cycle regularly are more likely to be aware of, and report, the danger posed by traffic than non-cyclists or infrequent cyclists. A similar phenomenon could explain the negative association between physical activity and perception of traffic volume.
Overall, the influence of the putative environmental characteristics examined in this study on active travel and physical activity appeared small compared with that of the personal characteristics found to be significant, and including environmental characteristics in the models did not substantially modify the influence of personal characteristics.
On the one hand, this could reflect an artefact of the research methods (a false negative error), which could have arisen in various ways. In particular, the 'wrong' environmental exposure may have been measured, in that the environmental characteristics examined were those of the immediate surroundings of respondents' homes, whereas the propensity to choose active modes of transport may be more strongly influenced by the characteristics of the environment elsewhere on their routes [30], for example the perceived danger of cycling in the city centre – an association which may be absent, or at least diluted, when the 'exposure' examined is limited to the residential environment. It could also be argued that the apparently weak influence of environmental characteristics in this study reflects a reliance on respondents' perceptions which have not been objectively verified and may therefore be a weak proxy for the 'true' objectively-measured characteristics of their surroundings. However, as recent reviews have pointed out, the current weight of evidence for objective environmental correlates of walking is no greater than that for subjective environmental correlates [5] and it is entirely plausible that <span class="yellow">people</span>'s perceptions of their environment may be at least as important as their objective conditions in influencing their behaviour [6].
On the other hand, we may have demonstrated a real absence of any major association. Although at first sight this appears at odds with the growing body of review-level evidence for environmental correlates of physical activity, Wendel-Vos and colleagues noted that of all the environmental factors examined in all the studies included in their review, analysis showed a 'null association' in 76% of cases [9], and our finding that personal factors account for a much larger proportion of the variance in active travel or physical activity than is accounted for by environmental factors is consistent with those of some other European studies [32,33]. In the particular context of this study, residents may simply have adapted to adverse conditions in their local environment in the ways identified by Hedges in a qualitative study of <span class="yellow">people</span> living close to new roads built in the UK in the 1970s [34] – particularly by attitudinal adaptation, which Hedges characterises as developing an attitude that it is futile to resist. One can imagine that in the most deprived areas of Glasgow, <span class="yellow">people</span> may have become resigned to the nature of their surroundings, seeing them as inevitable and not amenable to change either through environmental improvement or through their moving to another area.<br><br>
Conclusion
After demographic and socioeconomic characteristics were taken into account, neither perceptions of the local environment nor objective proximity to major road infrastructure appeared to explain much of the variance in active travel or overall physical activity in this study. Our study population may be both objectively constrained by their socioeconomic circumstances (including comparatively limited access to private cars) and adapted to living in conditions which others would consider to pose a barrier to active travel. Under these circumstances, environmental characteristics which have been found to influence discretionary active travel in studies in other, more affluent populations may simply be irrelevant in a population which is more captive in its travel choices. Environmental correlates of active travel should not be assumed to be generalisable between populations; researchers should continue to test hypotheses about putative environmental correlates in different settings, and policymakers should recognise that the effects of interventions to change the environment are likely to vary between populations and between socioeconomic groups within populations.<br><br>Competing interests
This paper is based on material contained in the first author's PhD thesis.<br><br>Authors' contributions
DO had the original idea for the study, designed the study and the survey materials, applied for ethical approval, cleaned and coded the survey data, carried out all the geographical and statistical analyses and wrote the paper. MP was DO's PhD supervisor. RM, NM, MP and SP constituted the steering group for the study, contributed to and advised on the design of the study and the interpretation of the emerging findings, and contributed to the critical revision of the paper. All authors read and approved the final manuscript.<br><br>Supplementary Material<br><br>
<h3>pmcA2602716</h3>A Case-Control Study to Assess the Relationship between Poverty and Visual Impairment from Cataract in Kenya, the Philippines, and Bangladesh
Abstract
Background
The link between poverty and health is central to the Millennium Development Goals (MDGs). Poverty can be both a cause and consequence of poor health, but there are few epidemiological studies exploring this complex relationship. The aim of this study was to examine the association between visual impairment from cataract and poverty in adults in Kenya, Bangladesh, and the Philippines.<br><br>Methods and Findings
A population-based case–control study was conducted in three countries during 2005–2006. Cases were <span class="yellow">persons</span> aged 50 y or older and visually impaired due to cataract (visual acuity < 6/24 in the better eye). Controls were <span class="yellow">persons</span> age- and sex-matched to the case <span class="yellow">participants</span> with normal vision selected from the same cluster. Household expenditure was assessed through the collection of detailed consumption data, and asset ownership and self-rated wealth were also measured. In total, 596 cases and 535 controls were included in these analyses (Kenya 142 cases, 75 controls; Bangladesh 216 cases, 279 controls; Philippines 238 cases, 180 controls). Case <span class="yellow">participants</span> were more likely to be in the lowest quartile of per capita expenditure (PCE) compared to controls in Kenya (odds ratio = 2.3, 95% confidence interval 0.9–5.5), Bangladesh (1.9, 1.1–3.2), and the Philippines (3.1, 1.7–5.7), and there was significant dose–response relationship across quartiles of PCE. These associations persisted after adjustment for self-rated health and social support indicators. A similar pattern was observed for the relationship between cataract visual impairment with asset ownership and self-rated wealth. There was no consistent pattern of association between PCE and level of visual impairment due to cataract, sex, or age among the three countries.<br><br>Conclusions
Our data show that <span class="yellow">people</span> with visual impairment due to cataract were poorer than those with normal sight in all three low-income countries studied. The MDGs are committed to the eradication of extreme poverty and provision of health care to poor <span class="yellow">people</span>, and this study highlights the need for increased provision of cataract surgery to poor <span class="yellow">people</span>, as they are particularly vulnerable to visual impairment from cataract.<br><br>Background.
Globally, about 45 million <span class="yellow">people</span> are blind. As with many other conditions, avoidable blindness (preventable or curable blindness) is a particular problem for <span class="yellow">people</span> in developing countries—90% of blind <span class="yellow">people</span> live in poor regions of the world. Although various infections and disorders can cause blindness, cataract is the most common cause. In cataract, which is responsible for half of all cases of blindness in the world, the lens of the eye gradually becomes cloudy. Because the lens focuses light to produce clear, sharp images, as cataract develops, vision becomes increasingly foggy or fuzzy, colors become less intense, and the ability to see shapes against a background declines. Eventually, vision may be lost completely. Cataract can be treated with an inexpensive, simple operation in which the cloudy lens is surgically removed and an artificial lens is inserted into the eye to restore vision. In developed countries, this operation is common and easily accessible but many poor countries lack the resources to provide the operation to everyone who needs it. In addition, blind <span class="yellow">people</span> often cannot afford to travel to the hospitals where the operation, which also may come with a fee, is done.<br><br>Why Was This Study Done?
Because blindness may reduce earning potential, many experts believe that poverty and blindness (and, more generally, poor health) are inextricably linked. <span class="yellow">People</span> become ill more often in poor countries than in wealthy countries because they have insufficient food, live in substandard housing, and have limited access to health care, education, water, and sanitation. Once they are ill, their ability to earn money may be reduced, which increases their personal poverty and slows the economic development of the whole country. Because of this potential link between health and poverty, improvements in health are at the heart of the United Nations Millennium Development Goals, a set of eight goals established in 2000 with the primary aim of reducing world poverty. However, few studies have actually investigated the complex relationship between poverty and health. Here, the researchers investigate the association between visual impairment from cataract and poverty among adults living in three low-income countries.<br><br>What Did the Researchers Do and Find?
The researchers identified nearly 600 <span class="yellow">people</span> aged 50 y or more with severe cataract-induced visual impairment (“cases”) primarily through a survey of the population in Kenya, Bangladesh, and the Philippines. They matched each case to a normally sighted (“control”) <span class="blue">person</span> of similar age and sex living nearby. They then assessed a proxy for the income level, measured as “per capita expenditure” (PCE), of all the study <span class="yellow">participants</span> (<span class="yellow">people</span> with cataracts and controls) by collecting information about what their households consumed. The <span class="yellow">participants</span>' housing conditions and other assets and their self-rated wealth were also measured. In all three countries, cases were more likely to be in the lowest quarter (quartile) of the range of PCEs for that country than controls. In the Philippines, for example, <span class="yellow">people</span> with cataract-affected vision were three times more likely than normally sighted controls to have a PCE in the lowest quartile than in the highest quartile. The risk of cataract-related visual impairment increased as PCE decreased in all three countries. Similarly, severe cataract-induced visual impairment was more common in those who owned fewer assets and those with lower self-rated wealth. However, there was no consistent association between PCE and the level of cataract-induced visual impairment.<br><br>What Do These Findings Mean?
These findings show that there is an association between visual impairment caused by cataract and poverty in Kenya, Bangladesh, and the Philippines. However, because the financial circumstances of the <span class="yellow">people</span> in this study were assessed after cataracts had impaired their sight, this study does not prove that poverty is a cause of visual impairment. A causal connection between poverty and cataract can only be shown by determining the PCEs of normally sighted <span class="yellow">people</span> and following them for several years to see who develops cataract. Nevertheless, by confirming an association between poverty and blindness, these findings highlight the need for increased provision of cataract surgery to poor <span class="yellow">people</span>, particularly since cataract surgery has the potential to improve the quality of life for many <span class="yellow">people</span> in developing countries at a relatively low cost.<br><br>Additional Information.
Please access these Web sites via the online version of this summary at http://dx.doi.org/10.1371/journal.pmed.0050244.<br><br><br><br>Introduction
Improvements in health are at the heart of the Millennium Development Goals, with the recognition that better health is central to the primary aim of reducing poverty as well as important in its own right. Empirical data are needed to back up this claim. Unravelling the relationship between blindness and poverty therefore has important implications, and may also be informative for the association between poverty and other disabilities.
Blindness is a common condition globally, affecting approximately 45 million <span class="yellow">people</span>, and more than a third of blindness is caused by cataract [1,2]. Globally, the prevalence of blindness is five-fold higher in poor than rich countries [2]. Limited data show that within countries the poor are also more likely to be blind [3,4]. It is frequently asserted that blindness is both a cause and consequence of poverty, but there are few empirical data to support this claim. Poverty may cause cataract blindness, because access to cataract surgery is limited in low-income countries [5]. Furthermore, within poor countries some evidence suggests that lack of money is a major barrier to uptake of cataract surgery by individuals [6–8]. Blindness may also cause poverty, as the blind individual, or the household members who care for them, have a reduced earning potential [4,9]. This complex problem could have serious implications; estimates from The Gambia suggest that there is a substantial economic burden from lost productivity among blind <span class="yellow">people</span> [10]. Therefore, blindness prevention may ultimately be cost saving [11]. Extrapolations on a global level indicate that a successful eye care programme could prevent more than 100 million cases of blindness between 2000 and 2020, and consequently save at least US$102 billion, which would otherwise be lost to reductions in productivity associated with blindness [12]. However, these estimates are based on extrapolations from limited data and were not based on individual-level data. It is also difficult to identify the component of productivity loss that is due to blindness, as this condition mainly affects older <span class="yellow">people</span>, who may suffer from other comorbidities that restrict their employment opportunities or make them dependent on the care of others.
The Cataract Impact Study was undertaken to assess the relationship between cataract visual impairment and “economic poverty” and quality of life, and to estimate the impact of cataract surgery on these factors in three low-income countries. The aim of the current paper is to assess the association at baseline between visual impairment from cataract and household poverty (measured through consumption, asset ownership, and self-rated wealth) in a population-based case–control study in Kenya, the Philippines, and Bangladesh.<br><br>Methods
Setting
Case and control <span class="yellow">participants</span> were recruited from Nakuru district, Kenya (January–February, 2005); Negros island (May–June, 2005) and Antique district (April–May, 2006), Philippines; and Satkhira district, Bangladesh (November–December, 2005).<br><br>Selection of Cases and Controls
<span class="yellow">Persons</span> with cataract visual impairment (cases) and <span class="yellow">persons</span> without (controls) were primarily recruited through a population-based survey of adults aged ≥ 50 y [6–8]. Clusters of 50 <span class="yellow">people</span> (regardless of visual impairment) aged ≥ 50 y were selected through probability-proportionate to size sampling, using either the census (Philippines and Bangladesh) or electoral role (Kenya) as the sampling frame. Households within clusters were selected through a modification of compact segment sampling, whereby a map was drawn of the enumeration area that was divided into segments, each including approximately 50 <span class="yellow">people</span> aged ≥ 50 y, and one segment was chosen at random [13]. Households in the segment were included sequentially until 50 <span class="yellow">people</span> aged ≥ 50 y were identified. The surveys included 3,503 (93% response rate) <span class="yellow">people</span> aged ≥ 50 y in Kenya, 4,868 (92%) in Bangladesh, 2,774 (76%) in Negros, and 3,177 (83%) in Antique.
All <span class="yellow">people</span> in the survey aged ≥ 50 y underwent visual acuity (VA) testing and ophthalmic examination. VA was measured in full daylight with available spectacle correction with a Snellen tumbling “E” chart using optotype size 6/18 (20/60) on one side and size 6/60 (20/200) on the other side at 6 or 3 metres. If the VA was <6/18 in either eye then pinhole vision was also measured. <span class="yellow">Participants</span> with pinhole vision <6/18 but >6/60 in the better eye due to age-related cataract were given a second VA test using an “E” of size 6/24. The ophthalmologist examined all eyes with a presenting VA <6/18 with a torch (i.e., flashlight), direct ophthalmoscope, and/or portable slit lamp. The principal cause of blindness or visual impairment was recorded, according to the WHO convention in which the major cause is assigned to the primary disorder or, if there are two existing primary disorders, to the one that is easiest to treat [14].
Survey <span class="yellow">participants</span> were eligible for inclusion as cases if they were aged ≥ 50 y with best corrected visual acuity <6/24 in the better eye due to cataract, as diagnosed by an ophthalmologist. All eligible cases identified from these surveys were invited to participate in the study. <span class="yellow">Participants</span> were eligible to be controls if they were aged ≥ 50 y, did not have VA <6/24 in the better eye due to cataract and did not live in the same household as a case. During the survey a list was maintained of all eligible controls, by age group (50–54, 55–59, 60–64, 65–69, and >70) and sex. Whenever a case was identified, one age- and sex-matched control was randomly selected from the list for inclusion (or up to two controls in Bangladesh). If no matching eligible controls had been identified in that cluster at that stage of the survey, then the next eligible control in the cluster was recruited.
Because of logistical and time constraints, additional cases were also included through community-based case detection. In Kenya and Negros (Philippines), clusters were randomly selected through probability proportionate to size using the same cluster sampling procedure after completion of the population-based survey. Clusters were visited in advance and asked that all <span class="yellow">people</span> ≥ 50 y with vision problems come to a central point on a specified day, and that a list be made of <span class="yellow">people</span> unable to attend (e.g., due to blindness or other physical disability). After examining <span class="yellow">patients</span> at the central point, the survey team then visited those unable to leave their houses. Any identified eligible cases that agreed to be part of the study were interviewed in their homes. In Bangladesh and Antique (Philippines), community case detection was carried out simultaneously with the survey by two of the four teams, so that controls were included for these cases. Within each cluster from the survey, one interviewer was asked to be taken to two community members aged ≥ 50 y with eye problems, living within the cluster boundaries but not from the segments selected for the survey. If VA was <6/24 with pinhole in the better eye, the ophthalmologist was called to carry out the full eye examination, and eligible cases were included in the study.
For the purposes of the present analyses, control individuals with any visual impairment (VA <6/18 in the better eye) were excluded (n = 14 in Kenya, n = 53 in Bangladesh, n = 24 in the Philippines). Case and control <span class="yellow">participants</span> who were significantly communication impaired (e.g. deafness, dementia, or psychiatric disease) were excluded (fewer than five per country), and one case was excluded in the Philippines because of missing age data. One household had two eligible cases (Kenya), and one of these <span class="yellow">participants</span> was excluded for the poverty analyses as poverty was assessed through household level indicators (see below).
In total, 147 cases (82 from the survey and 65 from case detection) and 79 controls were included in Kenya; 217 cases (162 from survey and 55 from case detection) and 280 controls in Bangladesh; and 238 cases (146 survey and 92 case detection) and 180 controls in the Philippines.<br><br>Data Collection
All case and control <span class="yellow">participants</span> were interviewed in their homes by trained interviewers in the local language. Each interview lasted approximately 1 h.
Measures of poverty.
Poverty was measured through (a) monthly per capita expenditure (PCE) to indicate consumption, (b) asset ownership, and (c) self-rated wealth. The economic part of the questionnaires was adapted through interviews, focus group discussions, and pilot testing in each country to ensure local relevance.
The <span class="blue">person</span> primarily responsible for household finances (which may have been the case/control or another household member) was interviewed to assess PCE and assets. PCE was measured using methods based on the World Bank's Living Standards Measurement Study [15]. Items were included on food (42–52 items per country), education (three items), health (five items), household expenses (nine items), and personal expenses (21 or 22 items). In total, 85 items were included in the questionnaire in Kenya, 90 in the Philippines, and 79 in Bangladesh. The informant was asked to recall the monetary value of food that was purchased, consumed from home production, or received as payment in kind or as gifts. Consumption was assessed over a 1-wk period for frequently consumed items, and this was scaled up to estimate monthly consumption. The amount consumed monthly was assessed for items that were consumed more rarely. Monthly rent was recorded among households who rented, and households who owned their property were asked to estimate the amount that they could charge in rent per month. The consumption on all items was summed to calculate total monthly household consumption, and this was converted to United States dollars (US$) at the 2005 exchange rate ($1 = 76 Kenya shillings, 64 Bangladesh taka, 55 Philippine pesos). Total monthly household consumption was divided by the number of household members to calculate monthly PCE for the household.
The household informant was also asked about the number and type of context-specific assets owned by the household, including different types of furniture, electrical equipment, <span class="yellow">cattle</span>, and vehicles. Information was collected on household characteristics, including the building material of the floor, roof, and walls; type of toilet; and the number of rooms.
Self-rated wealth was assessed by asking the household informant to rank the household's wealth relative to others in the community on a scale from 1 (poorest) to 10 (richest).<br><br>Covariates.
Case and control individuals were interviewed about standard sociodemographic indicators, including household composition, education, and employment. Information was collected on vision-related quality of life using the World Health Organization Prevention of Blindness and Deafness 20-item Visual Functioning Questionnaire [16,17], and health-related quality of life was assessed using items from the European Quality of Life Questionnaire [18]. Detailed time-use data were collected using methods based on the World Bank's Living Standards Measurement Study [15].<br><br>
Training and Fieldwork
Interviewers were trained for 1 wk, including 2 d of pilot testing. Attempts were made to minimise measurement bias by emphasising the need for consistency in data collection among cases and controls. The questionnaires were translated into the local languages (three in Kenya, three in the Philippines, and one in Bangladesh) and back-translated by independent translators (one for each language) who were also asked to comment on appropriateness of language used for the target population. A review was held to discuss differences in translation and modify accordingly. The questionnaire was piloted in each setting and small modifications to wording of some items were made, where appropriate, to ensure local understanding. Teams were accompanied by a field supervisor at least 1 d per wk to ensure that high quality was maintained and interviews were observed randomly throughout the study.<br><br>Statistical Analysis
Microsoft Access was used for data entry, and all data were double entered and validated. Analyses were undertaken in SAS version 8.2.
The mean and range of each expenditure item was calculated to assess whether answers were plausible, and to identify and exclude gross outliers (none identified). Rental equivalents were imputed based on household characteristics and non-rent expenditure for households where these estimates were missing or unreasonably low (< $1 per mo) (four in Kenya, three in Bangladesh, 18 in the Philippines). Total monthly household consumption was divided by the number of household members to calculate per capita household expenditure. Per capita household expenditure was divided into quartiles, separately for each country, based on the distribution of the data for the case and control <span class="yellow">participants</span> combined. Households with incomplete expenditure data were excluded from analyses (five cases and four controls in Kenya; one case and one control in Bangladesh).
A relative index of household assets was derived using principal components analysis (PCA) to determine weights for a list of assets and wealth indicators [19]. Variables entered into the PCA included building materials of the house, ownership of ten household assets, animal ownership, and education of the head of the household. The derived index was divided into quartiles from poorest (lowest socioeconomic status [SES] index) to least poor (highest SES index). PCA analyses were undertaken separately for each country. The means of the poverty variables were first compared for cases recruited through the two different methods, and then from cases and controls using t-tests for continuous variables (e.g., PCE and assets). For categorical variables (e.g., household rank) we used the Mann-Whitney test and presented medians and interquartile ranges. PCE was highly skewed and therefore was log transformed for the t-tests. The two-way correlations were calculated between PCE, assets, and household rank, in turn.
Logistic regression analyses were undertaken separately for each country, assessing the association between case/control status and sociodemographic and poverty variables. Conditional logistic regression was not undertaken, since the matching was incomplete, so all analyses were adjusted for the matching variables (age, sex, and rural/urban location). Likelihood ratio tests were undertaken to assess the significance of adding covariates with more than two levels (e.g., age groups, self-rated health groups) to the model. Tests for trend were undertaken across quartiles of the poverty variables and assessed using the p-value for trend. Analyses were also conducted adjusting for the logistic regression analyses for poverty by social support indicators (marital status and household size) and self-rated health, since these variables may confound the association between cataract visual impairment and poverty. Analyses from the Philippines were also adjusted for study site, since data were obtained from two settings (Negros and Antique). An attempt was made to disentangle the relationship between poverty and cataract by stratifying the analyses by age, sex, and level of visual impairment among the cases.<br><br>Ethical Approval
Informed signed or thumb-printed consent was obtained from all cases and controls. In Kenya and Bangladesh all cases were offered free cataract surgery at the local hospital, with free transport. In the Philippines, <span class="yellow">patients</span> were referred for surgery, which was subsidised for <span class="yellow">patients</span> who could not afford the fee. Ethical approval for this study was obtained from the ethics committees of the London School of Hygiene & Tropical Medicine, the Kenya Medical Research Institute, the Bangladesh Medical Research Council, and the University of St. La Salle, Bacolod, Philippines. This study complied with the guidelines of the Declaration of Helsinki.<br><br>
Results
Sociodemographic Characteristics of Cases and Controls
Case and control <span class="yellow">participants</span> were matched reasonably closely by sex and location. However, within the age category ≥ 70 y, cases tended to be older than the controls, so that cases were over-represented in the oldest age groups (75–79 and ≥ 80 y) compared to controls (Table 1). Cases were less likely to be married than controls, in Kenya (OR 0.6, 95% CI 0.3–1.1), Bangladesh (0.6, 0.4–1.0), and the Philippines (0.7, 0.4–1.0), although this only reached statistical significance in Bangladesh (p = 0.03). There was a strong protective effect of literacy and education on cataract in Bangladesh and Kenya that was not evident in the Philippines. Cases were substantially less likely to have a job other than working in the field compared to controls in all three countries. Cases reported significantly poorer self-rated health than controls—this pattern was particularly evident in the Philippines (OR for lowest versus highest quartile of self-rated health = 5.7, 95% CI 3.0–10.7) but also apparent in Kenya (2.6, 1.1–6.2) and Bangladesh (3.3, 2.1–5.3).<br><br>Summary Wealth Measures
All three settings were poor. The mean PCE was less than US$1 per <span class="blue">person</span> per day in all three settings: US$26.4 (standard deviation [SD] = US$34.9) in Kenya, US$21.7 (US$48.0) in Bangladesh and US$26.1 (US$23.5) in the Philippines. The biggest expense was food in all three settings, making up 55% of PCE in Kenya, 47% in Bangladesh, and 64% in the Philippines, followed by household expenses including rent (21% in Kenya, 28% Bangladesh, and 22% Philippines) (Figure 1). The majority of food consumption was from direct purchase (70% in Kenya, 75% in Bangladesh, and 77% in the Philippines) or home-grown production (24% in Kenya, 22% in Bangladesh, and 17% in the Philippines), and little was from gifts or payments.
An asset score was created through PCA in the three settings. The first principal component explained 22% of the variability in asset variables in Kenya, 25% in Bangladesh, and 24% in the Philippines. Self-perceived wealth of the household clustered around the average with a large proportion of households in Kenya (48%), Bangladesh (43%), and the Philippines (64%); households stating that they were ranked between 4 and 6, on a scale from 1 to 10, in terms of wealth in their community. The three measures of poverty were highly correlated, each showing significant correlation (p < 0.001) with the other measure.<br><br>Economic and Household Characteristics of Cases and Controls
There were no significant differences in PCE, assets, or household rank between cases recruited through the population-based survey and those recruited through case detection, with the exception that the case-detection cases had lower household rank in Kenya (mean = 3.7 versus 3.1, p = 0.02). Consequently, cases recruited through the two methods were combined in the subsequent analyses.
Cases were poorer than controls, in all three settings according to all three poverty measurements (Table 2). The mean PCE was 20%–28% lower for members of households with a case than for control households, and this difference was highly significant in Bangladesh and the Philippines; for Kenya it was lower but did not reach significance (p = 0.07). The PCA score for assets was significantly lower among cases than controls in Kenya and Bangladesh, and it was lower in the Philippines although it did not reach significance (p = 0.06). Self-perceived wealth was significantly lower for households with a case compared to control households in Kenya (3.4 versus 4.5) and Bangladesh (3.9 versus 4.6), though not in the Philippines (4.1 versus 4.3).
There was no difference in the size of the households of cases and controls in any of the three settings. The ratio of dependents (i.e., household member aged <15 or ≥ 50 y) to independents (i.e., household member aged 15–50 y) was similar between cases and controls in Bangladesh (1.4 versus 1.4), but the dependency ratio was higher for controls than cases in Kenya (2.1 versus 1.6) and the Philippines (1.7 versus 1.3), due to the smaller number of <span class="yellow">people</span> of working age.<br><br>Patterns of Expenditure in Cases and Controls
Figure 1 shows the total PCE and the allocation of expenditure within quartiles of PCE for cases and controls. Monthly PCE was similar for cases and controls within each of the quartiles of expenditure. There was a gradual increase in PCE between the first three quartiles, and then a rapid increase between the third and the richest quartile. Within the first three quartiles of PCE the majority of expenditure was on food. Substantial expenditure on non-food items was observed only in the highest quartile of expenditure, where about half of expenditure was on non-food items. Similar patterns of PCE were observed for cases and controls in Kenya, Bangladesh, and the Philippines within each quartile of expenditure. These results demonstrate that cataract visual impairment was related to reduced PCE, but not allocation of expenditure.<br><br>Multivariate Analyses of Poverty and Cataract Visual Impairment
Multivariate analyses showed that case <span class="yellow">participants</span> were consistently poorer than controls in Kenya, Bangladesh, and the Philippines, using three different measures of poverty (Table 3). Cases were more likely than controls to be in the lowest quartile of PCE rather than the highest quartile in Kenya (OR 2.3, 95% CI 0.9–5.5), Bangladesh (1.9, 1.1–3.2) and the Philippines (3.1, 1.7–5.7). In all three settings these associations showed significant dose–response as assessed by the p-value for trend across the quartiles, with decreasing PCE related to case status and these relationships persisted after adjustment for self-rated health and social support indicators. A similar pattern was observed for the relationship between case–control status and asset ownership. Cases were significantly more likely to be in the lowest quartile of asset ownership rather than the highest quartile compared to controls in Kenya (3.7, 1.4–9.6), Bangladesh (2.6, 1.5–4.4), and the Philippines (2.1, 1.1–3.8). Cases were also significantly more likely to be in the lowest quartile of household rank rather than the highest, compared to controls in Kenya (3.5, 1.5–8.0), Bangladesh (2.7, 1.6–4.7) and the Philippines (2.3, 1.1–4.8). The associations with assets and household rank also showed a significant dose–response relationship, and the associations were largely unchanged after adjustment for self-rated health and social support indicators. In Kenya and Bangladesh the relationship between PCE and case status was somewhat weaker than for the other measures of poverty, while the reverse was true in the Philippines.
Stratifying the association between PCE and cataract visual impairment by level of visual impairment showed an inconsistent pattern (Table 4). In Kenya, the association with low PCE was somewhat stronger comparing cataract blind cases to controls (OR 3.1, 95% CI 0.9–10.8) than comparing moderate visually impaired cases to controls (1.8, 0.6–5.4), while this pattern was reversed in Bangladesh (blind cases versus controls: 1.8, 1.0–3.4; moderately visually impaired cases versus controls: 3.1, 1.3–7.2). In the Philippines the association with low PCE was strongest comparing severely visually impaired cases to controls (5.9, 2.0–17.6). The association between cataract visual impairment and PCE was stronger among <span class="yellow">men</span> than <span class="yellow">women</span> in Bangladesh and the Philippines, while the reverse was true in Kenya (Table 5). In Kenya and the Philippines the strongest association between cataract and PCE was among <span class="yellow">people</span> aged 70–79 y, while in Bangladesh the strongest effect was in <span class="yellow">people</span> aged over 80 y. Stratifying the association between assets and household rank with cataract by level of visual impairment, sex, or age broadly repeated these findings, and generally supported the lack of consistent pattern (unpublished data).<br><br>
Discussion
This large, multicentre population-based case–control study provides evidence that <span class="yellow">people</span> with visual impairment from cataract are poorer than control <span class="yellow">participants</span> with normal vision matched for age and sex. This pattern was evident whether poverty was measured in terms of PCE, assets, or self-rated wealth. Marital status seemed to be protective for cataract visual impairment, possibly indicating the role of social support in health-seeking behaviour. Reduced self-rated health was also strongly related to cataract visual impairment. This demonstrates the impact of poor vision on overall assessments of health and supports our previous finding of a relationship between cataract and quality of life [17].
Adjustment for marital status and self-rated health did not entirely explain the association between poverty and cataract visual impairment, suggesting that it operated through other pathways. Visual impairment could cause poverty through reduced employment opportunities. We might therefore expect to see a stronger relationship between cataract and poverty among the blind case <span class="yellow">participants</span> who may have fewer employment opportunities than among those less impaired (i.e., moderate visual impairment). Poverty may also cause visual impairment through restricted access to cataract surgery. In this case we would expect to see a stronger relationship between poverty and less severely affected cases (i.e., moderate visual impairment), as poor families may allocate money for surgery on members who are blind from cataract, so that poverty mainly restricts access to surgery among <span class="yellow">people</span> who are moderately visually impaired. The relationships that we observed between level of visual impairment and cataract were inconsistent across the three settings. Perhaps this shows that both pathways were operating or that the dynamics of the relationship between poverty and blindness vary in different settings. Levels of literacy and education were lower among cases than controls. These long-term indicators of disadvantage are unlikely to have changed after the onset of cataract. This observation provides some evidence that poverty preceded blindness in our study <span class="yellow">participants</span>.
It is frequently asserted that blindness is both a cause and consequence of poverty, but there are few empirical data to support this claim. Globally, the prevalence of blindness is five-fold higher in poor than rich countries [2], and data from Pakistan and India suggest that within countries the poor are more likely to be blind [3, 4]. Some blinding conditions are a direct consequence of poverty, notably trachoma, which thrives in poor areas lacking water and sanitation [20]. Other blinding diseases clearly contribute to poverty, such as onchocerciasis, which results in the abandonment of the fertile areas near to the rivers where the disease vector thrives [9]. A larger literature shows that poor <span class="yellow">people</span> are more likely to be ill or disabled than their richer compatriots, ranging from general disability in India, Bulgaria, and Ghana [21]; common mental disorders in Brazil, Chile, India, and Zimbabwe [22]; deafness in Brazil [23]; and tuberculosis in China [24]. There are also some exceptions such as a case-control study in Rwanda which failed to show an association between PCE and musculoskeletal impairment, perhaps because the population was almost universally poor [25].
Poverty may increase the incidence of disease, particularly preventable diseases such as tuberculosis. Poverty may also restrict access to appropriate health care and so prolong the duration of disease. A study in rural Tanzania showed that care-seeking behaviour for childhood illness is worse among poorer families than among the relatively rich families [26]. Another Tanzanian study found that <span class="yellow">people</span> with higher levels of asset ownership were more likely to obtain antimalarials even though they were less likely to be parasitaemic [27]. With respect to cataract, there is little evidence that prevention is possible, and so the main pathway from poverty to blindness is likely to be through reduced access to cataract surgical services. High health care costs may also exacerbate poverty. A study in rural China showed that ill health increases medical expenditure significantly, which detracts from expenditure on food, education, investment in farming, and participation in social activities [28]. Inability to afford cataract surgery is cited as the major barrier to the uptake of surgery in the surveys conducted in Kenya, the Philippines, and Bangladesh [6–8]. This indicates that the cost of surgery is perceived as substantial by many households, notwithstanding the problems of assessing the complex issue of barriers in the absence of in-depth qualitative interviews. Consequently, there are lower rates of cataract surgery among the poor [3].
Poverty may also limit the employment opportunities of the <span class="blue">person</span> with disability or their household members. This pattern has been demonstrated for <span class="yellow">people</span> with <span class="yellow">HIV</span> in South Africa [29], tuberculosis in China [24], or disability in Sri Lanka [22]. An impact of blindness on reduced employment or income has been observed in Guinea [9] and India [4]. A belief that blindness reduces the employment opportunities of household members is widespread, but so far there is limited supportive evidence. There is a further complication to investigations of the relationship between cataract and poverty, as the individuals with cataract are likely to be elderly and facing multiple disabilities. Our study took account of the potential impact of multiple disabilities, as we adjusted for self-rated health, which is closely related to overall health, and this adjustment had no overall impact on our results [30].
Study Strengths
This was a large population-based case–control study, conducted in three countries, allowing international comparisons. This was the first study, to our knowledge, to relate PCE to visual impairment. We also measured assets, which reflects long-term access to resources, and self-rated wealth. We used expenditure as a proxy for income, which has aided both academic and nonacademic investigations. As one example, the notorious Chicago gangster Al Capone managed to escape prosecution for smuggling, gambling, bootlegging, and murder for years, but was eventually convicted of tax evasion, because the jury was convinced that his exorbitant expenses on clothes, furnishing, foods, and gifts were inconsistent with his claim that he had no income. Expenditure often provides a better measure of poverty than income for a number of reasons. Income may be variable by season, whereas households attempt to smooth expenditure over the year. <span class="yellow">People</span> are more comfortable sharing information about expenditure than income, and it may be a more meaningful measure than income in an agrarian society as it reflects what the household is able to command based on its current income, borrowing ability, or household savings [31]. PCE also has advantages over assets, as it may be more responsive to change, which will be important for the follow-up analyses of the study <span class="yellow">participants</span> after they have undergone cataract surgery.<br><br>Study Limitations
There are a number of limitations relating to the measurement of poverty in this study. Our analyses focus on monetary indicators of poverty, while we acknowledge that health, education, and housing are also important. We concede that it is difficult to measure expenditure accurately [32,33], but this also true for the measurement of diet and other variables, which is standard practise in many epidemiological studies. Furthermore, a large number of items were included in our measure of expenditure so that the measure was comprehensive [33]. Expenditure data were not validated through diaries or other means, although assets and self-rated wealth correlated highly with PCE. Other recent estimates of expenditure are not available from surveys conducted in these countries to allow comparison. The per capita estimates of monthly gross national income from the World Development Indicators database show somewhat higher estimates in Kenya (US$48) and Bangladesh (US$40) than our PCE derived estimates, and far higher estimates for the Philippines (US$108). This discrepancy may be reasonable, as the World Development Indicators reflect national averages, while we sampled the households with elderly <span class="yellow">people</span> in poor regions of the country, many of whom were visually impaired from cataract. PCE was calculated simply by dividing the total household expenditure by the number of household members, without inclusion of economies of scale or equivalence scales. There is no widely accepted alternative to the simple equal-sharing convention, and the majority of expenditure was on food which does not allow for economies of scale. Furthermore, there were slightly fewer <span class="yellow">people</span> of working age in the control households in Kenya and the Philippines, so adjustment for equivalence scores would be unlikely to explain the higher poverty among cases. The case and control households were of similar sizes in the three settings, so economies of scales are unlikely to have explained the differences.
There were a number of limitations relating to study design. Unfortunately, we did not record the exact numbers of cases and controls who refused to participate or were unable to communicate (believed to be fewer than five in each country), so the response rate is unknown, but was believed to be high. A variety of methods were used for case recruitment, as we were not able to obtain enough cases through the survey alone. However, cases recruited through the population-based survey and through case detection had similar poverty characteristics.<br><br>Conclusions
Our data show that <span class="yellow">people</span> with visual impairment due to cataract were poorer than controls in three low income countries, Bangladesh, Kenya, and the Philippines. The Millennium Development Goals are committed to the eradication of extreme poverty and provision of health care to poor <span class="yellow">people</span>. This study confirms an association between poverty and blindness and highlights the need for increased provision of cataract surgery to poor <span class="yellow">people</span>, particularly since cataract surgery is a highly cost-effective intervention in these settings [34].<br><br><br><br><h3>pmcA2636785</h3>Identification of recruitment and retention strategies for rehabilitation professionals in Ontario, Canada: results from expert panels
Abstract
Background
Demand for rehabilitation services is expected to increase due to factors such as an aging population, workforce pressures, rise in chronic and complex multi-system disorders, advances in technology, and changes in interprofessional health service delivery models. However, health <span class="yellow">human</span> resource (HHR) strategies for Canadian rehabilitation professionals are lagging behind other professional groups such as physicians and nurses. The objectives of this study were: 1) to identify recruitment and retention strategies of rehabilitation professionals including occupational therapists, physical therapists and speech language pathologists from the literature; and 2) to investigate both the importance and feasibility of the identified strategies using expert panels amongst HHR and education experts.<br><br>Methods
A review of the literature was conducted to identify recruitment and retention strategies for rehabilitation professionals. Two expert panels, one on Recruitment and Retention and the other on Education were convened to determine the importance and feasibility of the identified strategies. A modified-delphi process was used to gain consensus and to rate the identified strategies along these two dimensions.<br><br>Results
A total of 34 strategies were identified by the Recruitment and Retention and Education expert panels as being important and feasible for the development of a HHR plan for recruitment and retention of rehabilitation professionals. Seven were categorized under the Quality of Worklife and Work Environment theme, another seven in Financial Incentives and Marketing, two in Workload and Skill Mix, thirteen in Professional Development and five in Education and Training.<br><br>Conclusion
Based on the results from the expert panels, the three major areas of focus for HHR planning in the rehabilitation sector should include strategies addressing Quality of Worklife and Work Environment, Financial Incentives and Marketing and Professional Development.<br><br><br><br>Background
Demand for rehabilitation services is expected to increase within the next decade primarily due to factors such as an aging population, workforce pressures, rise in chronic and complex multi-system disorders, advances in technology, and changes in health service delivery models [1-4]. In Canada, rehabilitation personnel constitute the third largest health professional group after nurses and physicians. Despite the size of this workforce, studies have consistently reported ongoing shortages of physiotherapists (PTs), occupational therapists (OTs) and speech-language pathologists (SLPs) across all jurisdictions [5-7]. Similarly, recruitment and retention of rehabilitation professionals has been considered a challenge internationally, nationally and provincially. At the international level, the literature reports recruitment and retention difficulties of rehabilitation therapists in countries such as Australia, New Zealand, United Kingdom and the United States [8-13]. Provinces across Canada face similar issues; with Ontario projected to face the most difficulty due to its population growth rate [14].
Based on the Canadian Institute for Health Information's Health Personnel Trends in Canada from 1993 to 2002 report, numerous factors have been suggested to influence demand for physiotherapy and occupational therapy services. Factors that may influence increase demand for physiotherapy include: shift in health service delivery models from hospital to community care; earlier <span class="yellow">patient</span> discharge; increased expectations from aging Canadians concerning more active lifestyles; growing private practice sector and continued shortages for PTs in both private and public sectors in rural, remote and urban settings across Canada [2]. In 1993, an Ontario study stated that in order to meet demands of changing health care policy, medical technology and demographic changes in the population, the PT profession required an annual growth rate of 4.4% until the year 2000 [5]. However, the national health personnel databases revealed that the actual average annual growth rate of active PTs in Canada from 1995 to 2004 was only 2.5%, approximately half of the projected requirement suggested to meet demand [15].
Similarly, in Ontario in the early 1990s an increase in demand for OTs was projected because of the reported shortage in OTs and high attrition rate [16]. The shortage of OTs was explained by another Ontario study to be the result of the changing philosophies of care and management for the disabled, and a clearer understanding of the role of OT in the physical and mental well-being of the disabled [17]. In terms of actual shortages, some authors have reported ongoing vacancies and recruitment difficulties for OTs [11,18] while others have reported an increase in demand for both PTs [19] and OTs [20].
Speech language pathology is facing similar service demands. A report released in March 2003 by the College of Audiologists and Speech-Language Pathologists of Ontario (CASLPO) concluded that based on prevalence rates for Ontario residents with speech, language and related disorders, the demand for service would increase by 13% while the number of SLPs would decrease by 4% resulting in an overall reduction in service of 15% [21]. The American Speech-Language-Hearing Association (ASHA) has been tracking SLP vacancies. In their 2005 ASHA Speech-Language Pathology Health Care survey, 48% of respondents indicated that they had funded unfilled positions for SLPS in their agency [22]. The same survey also reported that 65% of respondents in home care indicated that job openings were more numerous than job seekers in their geographic area.
While labour market demand and supply are influential factors on recruitment and retention decisions, the development of strategies requires an understanding of conceptual frameworks or theories to categorise and explain how other underlying factors impact health worker's mobility. For example, Lehmann et al.'s model described that health worker's decisions to accept and stay in remote areas in the public sector depends on two interrelated aspects: the impact of the different environments (i.e. individual, local, work, national and international) and the location of decision-makers (i.e. local government, Ministry of Health, HR directorate, public service and other ministries)[23]. Behavioural and social science theories, such as those explained by Tett and Meyer, found that job satisfaction and organizational commitment each contribute independently to the prediction of the intention to resign (turnover), however job satisfaction was a stronger predictor than organizational commitment[24]. Based on this notion, considerable research has been devoted to identifying factors that affect job satisfaction among rehabilitation professionals. While there is no single, agreed upon model of job satisfaction, a variety of theoretical models have been studied to explain concepts and relationships associated with overall job satisfaction. The two most commonly used theories of job satisfaction for rehabilitation professionals are the Herzberg's Motivation-Hygiene Theory[25] and Mottaz's concepts of work values and work rewards [26].
A number of rehabilitation studies have used the Herzberg's Motivation-Hygiene Theory, also known as the two-factor theory of motivation to explain associations between motivation, job satisfaction and retention factors among OTs, PTs and SLPs [27-31]. Frederick Herzberg et al. explained that there were two independent incidents occurring at <span class="yellow">peoples</span>' jobs: one that made them feel good or satisfied, and another that made them feel bad or dissatisfied at work [25]. Intrinsic factors that motivate <span class="yellow">people</span> such as achievement, recognition, work itself, responsibility, advancement and personal growth were called the "motivators" which lead to feelings of satisfaction. Extrinsic factors such as work conditions, company policies, supervision, interpersonal work relations, salary and job security, known as "hygiene" factors, were claimed to prevent dissatisfaction. "Motivators" directly affect a <span class="blue">person</span>'s motivational drive to do a good job, therefore they are believed to be more important than hygiene factors.
Mottaz on the other hand, accounted for individual differences in job satisfaction among workers and based his study on two dimensions: "work rewards" and "work values"[26]. "Work rewards" are perceived characteristics of the job and have three conceptual clusters which include task, social and organizational rewards [26]. Mottaz describes "task rewards" (intrinsic) as having five independent characteristics including: skill variety, task identity, task significance, autonomy and feedback. Examples include interesting and challenging work, self-direction and responsibility, creativity, opportunities to use one's skills and feedback. In the same study, Mottaz stated that "social rewards" (extrinsic) are derived from the interpersonal relationships established with others at work. Having supportive colleagues and supervisors is an example of this dimension. Lastly, "organizational rewards" (extrinsic) are tangible rewards that are provided by the employer/organization to facilitate performance. Such factors include working conditions, pay and fringe benefits, career advancement and security. The second dimension of job satisfaction is based on "work values", which is the importance that individuals place on their work rewards [26]. For example, some rehabilitation therapists may value extrinsic rewards such as pay and benefits as more important than intrinsic factors like clinical autonomy and challenging work. Although the Herzberg and Mottaz conceptual frameworks are organized differently, their job satisfaction variables are very similar (i.e. work conditions, pay, interpersonal relationships, etc.) and they both classify these factors as having intrinsic or extrinsic elements.
Despite the growing body of literature on recruitment and retention factors in various industries, there is a minimal amount of research studying these factors specifically among rehabilitation professionals. One published study however, did look at extrinsic and intrinsic job satisfaction factors on recruitment and retention of rehabilitation professionals (OTs, PTs and SLPs)[32]. Results from this study showed that intrinsic factors such as professional growth and having a work environment in line with personal values are more significant in predicting career satisfaction than extrinsic factors such as pay and continuing education. These same intrinsic factors are also significant in predicting retention in rehabilitation professionals. Another study looking at recruitment and retention of allied health professionals in the rural areas in New South Wales identified that the main reasons why <span class="yellow">people</span> liked working in rural areas were because of the attractive environment and helpful team members[33]. However 82% of employees reported that having their partner move away was the number one reason for leaving a rural job. A similar study was conducted among OTs and PTs in Northwestern Ontario[34]. Findings from this study indicated that factors contributing to initial decision on location of practice include availability of leisure/recreation activities, proximity of family origin and influences of spouse/partners. Study results also showed that the main reasons therapists left their job were to be closer to their family, lack of job opportunity and spousal influence.
Solely understanding factors that influence recruitment and retention decisions is not sufficient in the development of a HHR plan for rehabilitation professionals. In order for the plan to be effective and sustainable in addressing these factors, the most important and feasible workforce strategies needs to be identified.
There have been a number of reports on health <span class="yellow">human</span> resources (HHR) planning, recruitment and retention strategies for physicians [35,36] and nurses [37], however information regarding rehabilitation professionals is lacking. Canadian reports indicate that the main reason for significant gaps in this field is the absence of current and reliable data available on supply, demand and labour force participation trends for rehabilitation therapists [38-40]. There is some research that has investigated theoretical models of job satisfaction on recruitment and retention [28,32]; however few studies have looked at how these models have been implemented. Other studies have examined the relationship of gender, workplace setting (i.e. hospital, ambulatory, rehabilitation, acute and long-term care) and geographical location (i.e. rural or urban) on job satisfaction and retention among rehabilitation professionals [41-43]. Furthermore, no empirical studies have examined conceptual frameworks for organizing recruitment and retention strategies for rehabilitation therapists. To address this gap, this research identified recruitment and retention strategies from the literature for rehabilitation professionals and determined their importance and feasibility using expert panels.<br><br>Methods
Phase 1: Literature Review
Identification of recruitment and retention strategies
A review of the literature was conducted to identify recruitment and retention strategies for rehabilitation therapists. In this study, rehabilitation professionals were defined as physical therapists (PTs), occupational therapists (OTs) and speech-language pathologists (SLPs). Both published and non-empirical literature was accessed in this review. Keywords used to search for relevant published studies in the Consolidated International Nursing and Allied Health Sciences Library (CINAHL) (1982 to 2005) and Medline (1996 to 2005) included: "health <span class="yellow">human</span> resources or health manpower", "rehabilitation or rehabilitation professionals or vocational", "allied health professionals or personnel", "recruitment strategies", "retention strategies", "physical therapist or physiotherapist", "occupational therapy or occupational therapist", "speech-language pathologist or speech-language pathology". Non-empirical literature searches were made on international and national on-line catalogues and publications from health organizations, professional associations, and hospital and home care organizations. International reports were limited to developed countries since the purpose of this study was to identify strategies appropriate to the Ontario setting.<br><br>Organization and consolidation of strategies
There was a paucity of peer-reviewed studies obtained exploring rehabilitation HHR strategies, therefore the majority of strategies were selected from grey literature reports from international, national and provincial health organizations. From the literature review, 107 potential strategies were identified according to their relevance to HHR issues for rehabilitation in Ontario. These strategies were then categorized into two broad groups: A) Recruitment and Retention (n = 73), and B) Education (n = 34). The majority of strategies were not specific to rehabilitation professionals and they were reviewed by a group of three individuals collectively (rehabilitation researcher, manager, and clinician) for duplication, clarity, action focused properties and appropriateness to the Canadian or Ontario setting. When necessary, a small number of strategies were re-worded to be relevant to a rehabilitation context. This analysis resulted in the selection of 40 Recruitment and Retention and 24 Education strategies. Only 14 recruitment and retention and six education strategies were obtained from peer-reviewed articles. Since the majority of strategies were identified from the grey literature, it was not surprising that there was no apriori peer-reviewed conceptual framework that reflected the breadth of the strategies obtained from the literature review. As a result, the themes used by the Health and Community Services <span class="yellow">Human</span> Resources Sector Study in Newfoundland and Labrador [44] formed the basis for the organizational framework for this study since they aligned with the identified strategies. Each group was further categorized into the five themes (three for Recruitment and Retention and two for Education). The three Recruitment and Retention strategy themes were: (1) Quality of Worklife and Work Environment [n = 19]; (2) Workload and Skill Mix [n = 6]; and (3) Financial Incentives and Marketing [n = 15]. The two Education strategy themes were: (1) Education and Training [n = 11] and (2) Professional Development (n = 13).<br><br>
Phase 2: Expert Panel
<span class="yellow">Participant</span> Selection
Once this study was approved by the Research Ethics Board at the University of Toronto, key informants who participated in a previous study regarding rehabilitation supply and demand at the University of Toronto [21] were asked to nominate potential <span class="yellow">participants</span> for the panels. The selection criteria considered were acknowledged leadership in the panel member's specialty, expertise in recruitment and retention or education and training of rehabilitation professionals. Absence of conflicts of interest, geographic diversity, and diversity of practice setting were also considered. After purposefully selecting the initial list of candidates from among the nominations, each nominee was contacted to establish their interest and availability. Those who expressed an interest in participating were asked to send their curriculum vitae to help the research team evaluate their contributions to their field of expertise. Once candidate panelists were selected, each received a letter explaining the expert panel process and consent form. Two separate panels were constructed: one for Recruitment and Retention (n = 8) and the other for Education (n = 9) (Table 1). The size of the panel was large enough to permit diversity of representation while still being small enough to allow all <span class="yellow">participants</span> to be involved in the group discussion [45].<br><br>Expert Panel Process: Round 1 Survey
A modified-delphi technique was then used for the expert panel process, [46,47] based on the RAND/UCLA appropriateness method [45]. In round 1, members of the Recruitment and Retention panel were sent an electronic survey containing the 40 strategies identified from the literature review and the Education panelists were also sent an electronic survey with 24 strategies. For Round 1, each panel was asked to rate the strategies using a nine-point Likert-type rating scale that ranged from "none" (1) to "maximum" (9), on two key dimensions: Feasibility and Importance. Feasibility was defined as the practicality and cost implications of the strategy and was rated from the respondents' perspective. Importance was defined as how valuable, appropriate and useful the strategy could be for rehabilitation HHR planning in Ontario. At the end of the survey, panelists were given the opportunity to suggest additional strategies that they felt were appropriate to consider. Once completed, panelists were asked to return the survey to the study office by email or fax prior to the expert panel meeting in Round 2. Data from each questionnaire were entered into a spreadsheet and tabulated. Descriptive statistics were calculated for each strategy using frequency distributions and proportional percentages of respondents. Importance and feasibility rankings were based on the percentage of expert panelists' low, medium and high ratings.<br><br>Expert Panel Process Round 2: Expert Panel one-day meeting
After the independent completion of the survey, each panel was convened separately for a one-day meeting for final discussions, debates and consensus voting to decide on strategies [48]. A strategy that had been scored 7, 8 or 9 for both feasibility and importance by two-thirds of the panel was considered a high rating. Strategies that had a combination of medium and high scores between 4 and 9 in either of the two dimensions were considered medium rated strategies, while low rated strategies had scores between 1 and 3 for both dimensions.
On the day of the meeting, the panelists were given a copy of the aggregated survey results indicating the ratings of all of the strategies. High and low rated strategies were not discussed as there was already consensus, whereas all medium rated strategies were subject to discussion. Using a nominal group process [47], each strategy was discussed in turn, and panelists were given an opportunity to raise any issues or concerns regarding the clarity and wording of each strategy. Each of the strategies discussed were then individually rated a second time by each panelist in an attempt to reach further consensus.<br><br><br><br>Results
Selection of strategies for Round 1: Modified Delphi process
Following Round 1 rating of the 40 identified strategies, the Recruitment and Retention panel reached consensus on 12 strategies. However, 14 had a combination of high/medium importance and feasibility ratings and 14 had medium ratings on both dimensions, therefore it required further discussion. An additional strategy regarding family relocation programs was added by this panel.
The Education Panel ranked 16 of 24 strategies with high importance and feasibility after Round 1. Since there were only eight strategies with medium ratings, this expert panel decided to review all the strategies at the face-to-face meeting to discuss the rationale that would explain why some of the highly rated strategies were not already implemented and to come to a consensus on the other eight medium rated strategies. They also added an additional strategy for career paths.<br><br>Selection of strategies for Round 2: Face-to-face meeting
A total of 34 strategies were identified by both the Recruitment and Retention and Education expert panels as being important and feasible for the development of a HHR plan for recruitment and retention of rehabilitation professionals. Under the Recruitment and Retention theme, seven were categorized as Quality of Worklife and Work Environment; two were Workload and Skill Mix, and another seven were Financial Incentives and Marketing. As for the Education panel, five were categorized as Education and Training strategies while the other thirteen were related to Professional Development.
As indicated in Table 2, at the end of the second round of voting, the Recruitment and Retention panel had a total of 16 highly important and feasible strategies, 8 high/medium importance and feasibility, 8 medium and 9 low ratings for both dimensions. The Education panel on the other hand had a total of 18 high, 1 high/medium, 3 medium and 3 low rating strategies.<br><br>Recruitment and Retention Strategy Rankings
Table 3 provides a detailed description and ranking of each of the recruitment and retention strategies that were rated highly important and feasible. The importance and feasibility rankings were based on the largest proportion of panel members rating a strategy a 7, 8 or 9. The overall combined ranking was based on the average of the proportion of these two dimensions. Among these selected strategies, the majority were classified under Quality of Worklife and Work Environment (44%) and Financial Incentives and Marketing (44%), followed by Workload and Skill Mix (12%). It should be noted that some strategies had equal rankings; therefore the total number of rankings did not equal the total number of strategies.
Recruitment and retention strategies that had a combination of high and medium ratings in either of the two dimensions included: sense of empowerment in promoting healthy work environments; team-building exercises; developing participatory decision-making systems; improving rural working conditions; recognizing work-life balance; creating an environment where staff are valued; optimizing scope of practice and work-management autonomy. Strategies that had medium importance and feasibility ratings included: resolving concerns about liability and accountability in collaborative practice; recruiting international trained therapists; opportunity to work in different settings; interprofessional payment schemes; family leave; staff recognition and creating a position for a provincial health professional recruiter. Low importance and feasibility strategies included: word of mouth references; bursaries and retention bonuses; exchange employment opportunities; health promotion; retention workshop; 80–20 staffing model (80% clinical and 20% learning new skills or training others); using recruitment agencies and providing recruitment bonuses (Table 4).<br><br>Education Strategy Rankings
Education strategies that were rated highly important and feasible are described in Table 5. The majority of strategies in this group tend to be in the area of Professional Development (72%), more so than Education and Training (28%).
The medium rated education strategies included: expand interprofessional education; provide incentives for students interested in rural practice; summer mentorship programs for high school students; and aboriginal student support program. The strategies that were considered neither feasible nor important included: using return of service contracts after professional development; create a tiered pathway approach through modular education and laddered credentialing and in accreditation standards allow greater use of rural practice sites (Table 6).
Since the purpose of the panel was to identify recruitment and retention and education strategies that could inform the development of a HHR plan for rehabilitation professionals, there was also discussion about contextual factors that would influence a plan. Panelists commented that key factors to consider prior to implementation of these strategies should include workplace setting, geographical location (i.e. urban and rural) and gender issues.<br><br>
Discussion
The purpose of this study was to identify recruitment and retention strategies to inform the development of HHR planning for rehabilitation professionals in Ontario. This study highlights that Quality of Worklife and Work Environment, Financial Incentives and Marketing and Professional Development are the three major areas of focus when developing a competitive HR plan in the rehabilitation sector.
Quality of Worklife and Work Environment
Quality of Worklife and Work Environment strategies ranked among the top category for recruitment and retention of rehabilitation therapists. This has also been found among nurses [44] where it was reported that addressing such factors can affect the overall success of the program [49]. Specifically, our findings showed that the top ranked strategy for both importance and feasibility was improving and maintaining the safety of rehabilitation professionals in the workplace. Specific strategies that could reduce aggression, abuse and violence in the workplace include: zero tolerance policies, access to employee support programs and providing assistance to rehabilitation professionals who work alone (i.e. home care and rural and remote areas). Since there is less control over the environment in the home care setting, safety may become a greater concern in one practice setting over another. This might suggest that because there is less control in environments such as home care, remote areas, and psychiatric settings, maintaining safety will be more difficult and that solutions will need to be tailored to these settings in order to ensure retention of providers. Although no studies have looked at implementing personal safety strategies for home care therapists, written policies and procedures for home care nurses during inclement weather and for dealing with abusive or dangerous <span class="yellow">patients</span>, families and neighbourhoods have been reported [50].
In addition to the above, ensuring open and timely communication between employer and worker was also ranked highly among the recruitment and retention strategies. Examples of strategies include: open door policies, employee advisory committees and regular staff meetings and evaluations. Although these strategies were reported to be used among organizations providing services to <span class="yellow">persons</span> with developmental disabilities in Alberta, there was no description of the organizations, sample size or methodology [51]. Similar findings were found in a qualitative study among 16 nurses working from diverse practice settings (acute, long-term care, rehabilitation and community; from both urban and rural areas) in a health region in western Canada. From the semi-structured interviews, study <span class="yellow">participants</span> expressed a desire for improved consultation and communication with nurses regarding changes to the health care system [52].<br><br>Financial Incentives and Marketing
Another area that was ranked highly was marketing strategies to increase high school student and public awareness of rehabilitation careers. These specific strategies were also recommended by the Ontario Hospital Association (OHA) in order to establish a competitive position for Ontario hospitals in respect of recruitment and retention of health care professionals [53]. Similar strategies have been developed by the American Physical Therapy Association (APTA) in response to the declining number of students applying to Physical Therapy Education Programs [54]. To address this trend, APTA developed a campaign to promote Physical Therapy as the profession of choice to high school and college students across the United States. The potential components of their plan included: developing a "Recruiting Kit" for educators, students and various APTA members to be used in the high school and college settings to introduce Physical Therapy as a career; establishing public relations initiatives that demonstrate the role of Physical Therapy in the public arena targeting minority groups that are underrepresented in the profession; and creating alliances with professional associations of high school guidance counsellors and educators. Based on our finding, the APTA model may have applicability in Ontario.<br><br>Workload and Skill Mix
Of the six Workload and Skill Mix strategies only two were highly rated: implementing a caseload management database and using support personnel. Caseload management has been identified in the literature as an issue affecting all three rehabilitation professions. For example, in physiotherapy, Christie's study [55] found that caseload expectations tended to be significantly higher than the reality and that caseload varies across different programs. Similarly, the Canadian Association of Speech-Language Pathologists and Audiologists (CASPLA) survey indicated that factors affecting the workload of SLPs include delivery models, client disorder, severity and work setting [56]. A literature review and environmental scan undertaken by the Canadian Association of Occupational Therapists (CAOT) proposed that guiding principles for caseload management should include: evidence-based occupational therapy, cost-effectiveness, accountability, professional leadership and expert judgment, comprehensiveness and flexibility [57]. Therefore, upon implementation of a caseload management database for rehabilitation, key factors to consider include workplace setting and client service delivery models.
The other highly rated Workload and Skill Mix strategy was the use of support personnel (i.e. physiotherapy assistants or exercise therapists) to increase efficiency of utilization of scarcer and higher order rehabilitation competencies. Considerations for implementing this strategy include addressing key issues such supply, standards of education, standards of practice and accreditation. These are highlighted in an article by Salvatori [58] who reported that the actual number of OT personnel delivering OT services in Canada remains unknown and that there are no national standards of education nor accreditation process for OT assistants. CAOT believes that in order to utilize support personnel appropriately, studies on <span class="yellow">human</span> resource needs for occupational therapy and support personnel are first needed with input from OTs, stakeholders, funders, decision makers and health policy planners [59]. Since there is a lack of competency profiles related to the role, responsibilities, and supervision of assistants, particularly with regards to delivering services in unsupervised community-based settings, the type of workplace setting where this strategy may be implemented should be considered [58].<br><br>Education and Training
Given that 60% of highly rated Education and Training strategies targeted rural and remote practices underscores the importance of specific strategies for rural and remote areas in the development of a HHR plan. The need to build on existing mechanisms to expand the availability of rural and remote clinical placements by providing financial and accommodation support was ranked among the top two most important and feasible education strategies for rehabilitation professionals. Not only has this strategy been used as a recruitment tool for rehabilitation students, it has also been reported by Solomon et al. [34] to be effective in retaining OTs and PTs in underserviced Northwestern Ontario communities. Respondents from Solomon et al.'s study reported that the top three benefits of supervising students were that it stimulates thinking, it provides opportunity to contribute to the profession and that it provides access to current information. The reported disadvantages however was that it was time-consuming and students contributed stress to the working environment. Similarly, a two-part study found substantial gaps between financial incentives students deem important in the creation of an appealing clinical placement opportunity and the actual provisions offered to them by Southeastern Ontario communities [60,61]. Although OT and PT students reported that they were more willing to complete a clinical placement in an underserviced community if provided travel stipends, rent-free housing and interprofessional education opportunities, the majority of these incentives were only available to medical students. In addition to training students for rural and remote practice, a longitudinal study reported that perceived opportunity for career development was the most significant factor related to job turnover and regional attrition among physiotherapists working in Northern Ontario [5]. Therefore developing workforce strategies for rehabilitation therapists working in these areas should be among one of the priority areas in HHR planning.<br><br>Professional Development
Our findings indicate that the theme with the largest number of strategies that were considered important and feasible to implement as part of HHR planning was professional development. Many were specific to rural and remote areas. Although the importance of continuous professional development (CPD) in recruitment and retention is well recognized, a Canadian study reported several barriers to its implementation [62]. In the case of OTs employed in public settings in Nova Scotia, Townsend et al. (2006) found that the most powerful deterrent for CPD was the lack of support from workplace policies. Based on their study results, the use of CPD as a recruitment and retention strategy was highly influenced by gender issues, work-life balance, career advancement, working conditions, geographical location, professional versus employer responsibility, and employee benefits. Although occupational therapy is a female-dominated profession, workplace policies did not address issues of gender. For example, therapists in this study indicated that CPD competes with family commitments, therefore these activities are "done largely during personal time, mainly at their own cost, and on top of childcare, eldercare, homemaking and other family responsibilities" [62]. In addition, heavy workloads, lack of salary and career incentives, and lack of policy and funding support are all barriers to CPD. These issues become more pronounced in rural and remote settings because smaller communities often only have one therapist; hence the systemic pressure of workload demands makes it difficult for the therapist to leave <span class="yellow">patient</span> care. OTs from this study also questioned who was responsible for CPD. Some felt that it was the professional's responsibility while others felt that it was the responsibility of the employer to provide CPD opportunities. The primary limitation employers faced was the lack of financial resources, however giving employees time off without pay was an alternative strategy utilized instead of funding professional development activities. Although there are professional and provincial variations in funding for CPD across Canada, these results are informative in that it highlights the need for employers to consider how workplace policies can affect recruitment and retention strategies.
Limitations of this study should be noted. First, the majority of the strategies were obtained from the grey literature that is not subject to the same scrutiny as the peer-reviewed literature. Second, almost none of the strategies were specifically developed for rehabilitation professionals and in many cases had to be re-worded to fit the rehabilitation context. There is a lack of research on rehabilitation clinicians' perspectives on recruitment and retention strategies; therefore future research should focus on investigating this area. Third, during the face-to-face meeting, bias could have resulted from panelists whose opinion may have influenced others significantly, especially if members came from similar workplace settings. The facilitator of the expert panels however, followed a strict process for managing the discussion and ensured that all panelists were given the opportunity to express their opinions.
Finally, although some strategies such as competitive wage packages, training/growth opportunities and professional development are viewed as both a recruitment and retention incentive, other strategies do not overlap and are appropriate for only one of the two tasks. For example, increasing public awareness of rehabilitation careers, providing rural and remote orientation packages and family relocation programs are only appropriate for attracting a worker while ensuring open and timely communication may be seen as a strategy only for retention. Future research should therefore consider studying recruitment and retention strategies separately so that a distinction between the two can be made.<br><br>
Conclusion
This study identified 34 strategies that should be considered as important and feasible for implementation as part of HHR planning for rehabilitation professionals. Although the highest ranked strategies focused on areas of Quality of Worklife and Work Environment, Financial Incentives and Marketing and Professional Development, key factors that need to be considered in the context of implementation include: workplace setting, geographical location and gender issues. While this is the first study to our knowledge that provides a comprehensive list of recruitment and retention strategies relevant to rehabilitation professionals, more information is needed for the development of a HHR plan. Information on trends in labour force participation as well as knowledge regarding the use and effectiveness of recruitment and retention strategies for rehabilitation professionals is needed. More importantly, the success of implementing and sustaining such strategies requires future research to validate these strategies from the perspective of rehabilitation clinicians and <span class="yellow">human</span> resource decisions makers (i.e. local government, stakeholders, etc.) so that specific barriers and challenges can be identified.<br><br>Competing interests
The authors declare that they have no competing interests.<br><br>Authors' contributions
DT participated in the design of the study, conducted the literature review, analyzed and interpreted the results and drafted the manuscript.
LMH, AD, DB and KB were involved in providing feedback and editing the content of the manuscript.
MDL recommended <span class="yellow">participants</span> for the expert panel and was involved in providing feedback and editing the content of the manuscript.
SJ participated in the design of the study, recommended <span class="yellow">participants</span> for the expert panel, organized and consolidated strategies, interpreted the data and edited the content of the manuscript.<br><br>Pre-publication history
The pre-publication history for this paper can be accessed here:<br><br><br><br><h3>pmcA1562423</h3>Alexithymia and anxiety in female chronic pain <span class="yellow">patients</span>
Abstract
Objectives
Alexithymia is highly prevalent among chronic pain <span class="yellow">patients</span>. Pain is a remarkable cause for high levels of chronic anxiety. The purpose of this study was to investigate the prevalence of alexithymia and to determine anxiety levels among DSM-IV somatoform pain disorder (chronic pain) female <span class="yellow">patients</span> and to examine the relationship between alexithymia and the self-reporting of pain.<br><br>Methods
Thirty adult females (mean age: 34,63 ± 10,62 years), who applied to the outpatient psychiatry clinic at a public hospital with the diagnosis of chronic pain disorder (DSM-IV), were included in the study. Thirty seven healthy females (mean age: 34,46 ± 7,43 years), who matched for sociodemographic features with the <span class="yellow">patient</span> group, consisted the control group. A sociodemographic data form, 26-item Toronto Alexithymia Scale (TAS-26), Spielberger Trait Anxiety Inventory (STAI) were administered to each subject and information was obtained on several aspects of the <span class="yellow">patients</span>' pain, including intensity (measured by VAS), and duration.<br><br>Results
Chronic pain <span class="yellow">patients</span> were found significantly more alexithymic than controls. There was a positive correlation between TAS-26 scores and the duration of pain. The alexithymic and nonalexithymic group did not differ in their perception of pain. Neither positive correlation nor significant difference was found between alexithymia and trait anxiety in pain <span class="yellow">patients</span>.<br><br>Discussion
Alexithymia may be important in addressing the diversity of subjective factors involved in pain. The conceptualization of alexithymia as a personality trait as well as a secondary state reaction is underlined by our data.<br><br><br><br>Background
The original definition of alexithymia is the inability to identify and use verbal language to describe feelings [1,2]. Alexithymia has been associated with a variety of psychiatric disorders as well as physical illness [3-10]. As a measure, Toronto Alexithymia Scale was significantly correlated with the measures of the tendency to experience and report physical signs and symptoms [11].
Several studies have found a high prevalence of alexithymia in pain <span class="yellow">patients</span>. Chronic pain <span class="yellow">patients</span> frequently exhibit many of the core features of alexithymia, such as problems in identifying and describing subjective feelings, impoverished imaginative abilities, and excessive preoccupation with physical symptoms and external events. Although several studies have found a high prevalence of alexithymia in pain <span class="yellow">patients</span>, the way alexithymia may possibly influence pain experience is still unclear [12,13].
DSM-IV-TR defines pain disorder as the presence of pain that is "the predominant focus of clinical attention" [14]. In chronic pain disorder, <span class="yellow">patients</span> complain of chronic pain, for which no physical etiology could be found or the underlying disorder is insufficient in explaining the symptoms. The pain causes clinically significant distress or impairment in social, occupational, or other important areas of functioning. Psychological factors are judged to have an important role in the onset, severity, exacerbation, or maintenance of the pain [15].
The alexithymic <span class="blue">person</span>'s difficulty in identifying and describing feelings may increase symptom reporting by several mechanisms. Consequently, due to the difficulty to experience and express emotions, alexithymia has been linked with somatosensory amplification, which is the tendency to focus on benign somatic sensations. Alexithymic subjects are considered to focus on somatic manifestations of emotional arousal, resulting in misinterpretation of somatic sensations as signs of physical illness [12,13,16]. Accordingly, previous studies have found evidence of an association between alexithymia and the development of functional somatic symptoms, as seen in <span class="yellow">patients</span> with somatoform disorders. On the other hand, alexithymia may also occur as a secondary state reaction in response to severe and chronic medical illness [17-21].
Based on previous findings, these factors are worth receiving more attention in terms of clinical research. The purpose of the present study was to investigate the prevalence of alexithymia among DSM-IV somatoform pain disorder (chronic pain) female <span class="yellow">patients</span> and to examine the relationship between alexithymia and the self-reporting of pain in this group of <span class="yellow">patients</span>. Besides, the study searched for the anxiety levels of chronic pain <span class="yellow">patients</span> with or without alexithymia.<br><br>Materials and methods
Sample
The sample consisted of 30 females who applied to the outpatient psychiatry clinic at a public hospital and who met DSM-IV diagnostic criteria for chronic pain disorder. <span class="yellow">Patients</span> with concomitant psychiatric disorders, such as major depression, anxiety disorders and somatoform disorders other than pain disorder were excluded.
<span class="yellow">Patients</span> either directly applied to the psychiatry clinic themselves or were referred for psychiatric assessment from another outpatient clinic, mainly physical medicine and rehabilitation. After complete description of the study, written informed consent was obtained from each subject.
The control group was 37 healthy females, who matched for age, and education with the subjects. All subjects participated voluntarily in the study and gave consent after the procedure had been fully explained to them.
The mean age of the <span class="yellow">patients</span> and the healthy controls was 34,63 ± 10,62 (range: 16–62) and 34,46 ± 7,43 (range: 22–57) years and the educational level was 6,13 ± 3,03 (range: 5–11) and 6,59 ± 2,9 (range: 5–14) years, respectively. There were no significant differences between the two groups with respect to age (t = 0,79, df = 65, P > 0,05), educational level (t = 1,02, df = 65, P > 0,05), and marital status (x2 = 0,51, df = 1, P > 0,05).<br><br>Measures
A detailed sociodemographic data form was used for all subjects. All <span class="yellow">participants</span> were applied Structured Clinical Interview for DSM-IV (SCID-I) [22], Turkish version [23]. Regarding the pain assessment, information was first obtained on several aspects of the <span class="yellow">patients</span>' pain, such as intensity, and duration. Pain intensity was measured by Visual Analogue Scale (VAS), using a horizontal 10-cm line with the statement 'no pain at all' at the extreme left-hand end and 'the worst possible pain' or 'unbearable' at the right-hand extreme. VAS is scored by measuring the distance from the end of the scale indicating absence of pain (or no distress or no pain relief) to the place marked by the <span class="yellow">patient</span> [24].
The psychometric scales used in the study were the 26-item Toronto Alexithymia Scale (TAS-26] and the Trait Anxiety Inventory (STAI), which were both validated in Turkish population studies [25-28]. TAS is a psychometrically well validated and reliable instrument in the assessment of alexithymia. TAS has been validated in Turkish studies as a true or false scale. Twenty-six items are scored either as 1 or 0 and the higher scores indicate higher degrees of alexithymia. TAS has an interval consistency of 0.65 [Kuder-Richardson) and test-retest reliability is r = 0.71, p < 0.01 in Turkish reliability and validity study. The sample was divided into nonalexithymic and alexityhmic groups, with the recommended cut-off score of 11 [27]. Spielberger Trait Anxiety Inventory (STAI) is one of the two sections of the Spielberger Anxiety Inventory (the other, measuring state anxiety). 'Trait anxiety' has been defined as anxiety proneness, that is, the tendency to respond to situations perceived as threatening with elevations in the intensity of state anxiety [26].<br><br>Statistical analysis
In order to determine the relative importance of a number of factors in pain disorders, we used both correlation analyses. The alexithymic and nonalexithymic groups were compared using the independent sample t-tests on scores of psychological tests. The statistical procedure, which was carried out by a SPSS package program for Windows using Chi-square, Fisher's exact test, two tailed t test and Pearson correlation coefficients, was also used to determine group differences (alexithymics versus nonalexithymics) in sociodemographic variables and various aspects of pain.<br><br>
Results
In the chronic pain group, 56.7% of <span class="yellow">patients</span> (n = 17) had a score greater than 11 on the TAS-26, and were considered alexithymic. The mean TAS-26 score of the alexithymic group (n = 17) was 17.88 ± 3.43 and the nonalexithymic group (n = 13) was 8.39 ± 2.02. Age (t = 1,38, df = 28, p > 0,18), education (t = -0,21, df = 28, p > 0,16) and marital status (x2 = 0,27, df = 1, p > 0,87) were not associated with alexithymia (Table 1).
In the control group, 24,3% of <span class="yellow">patients</span> (n = 9) were alexithymic according to TAS-26. The mean TAS-26 score of the alexithymic group (n = 9) was 13,82 ± 1,93 and the nonalexithymic group (n = 28) was 10,33 ± 0,86. Alexithymia was not associated with age (t = -1,08, df = 35, p > 0,29), educational level (t = 1,1, df = 35, p > 0,28), or marital status (x2 = 0,74, df = 1, p > 0,79) or anxiety levels in the control subjects (Table 1).
The duration and severity of pain, TAS-26 scores, and STAI scores of the female pain <span class="yellow">patients</span> are shown in Table 2. Comparison of the alexithymics with nonalexithymics on either the severity of pain or pain duration showed no statistical significance (t = 0,64, df = 28, p > 0,52, t = 2,05, df = 28, p > 0,05, respectively).
TAS-26 score and duration of pain were found positively correlated (r = 0,50, n = 30, p > 0,005). STAI (trait) scores of the alexithymics in the pain group did not significantly differ from the nonlalexithymics (t = 0,06, df = 28, p > 0,95) and besides, TAS-26 and STAI scores were not correlated (r = 0,06, p > 0,72).
In summary, there are three points to be emphasized. First, chronic pain <span class="yellow">patients</span> were found significantly more alexithymic than controls (56,7% to 24,3%). Second, a positive correlation was observed between TAS-26 scores and duration of pain. Third, neither positive correlation nor significant difference was found between alexithymia and trait anxiety in pain <span class="yellow">patients</span>.<br><br>Discussion
The results of the present study suggest that <span class="yellow">patients</span> with chronic pain disorder are more alexithymic than individuals with no pain. This finding is consistent with results obtained with earlier measures of alexithymia [11-13]. Although they may share common clinical features, alexithymia and somatoform pain are independent constructs. Alexithymia may be a consequence to the effects of severe physical symptoms, such as a reduced quality of life and limitations in daily activities. Besides, alexithymia may be conceptualized as a personality trait as well as a secondary state reaction [2,3,15-17]. In this study, the question investigated was whether alexithymia has any correlation with the duration or severity of the pain itself.
There were no significant differences between alexithymic and nonalexitymic <span class="yellow">patients</span> on self reports of current pain severity. This is in accordance with Cox's study [1994] in which it was further pointed out that alexithymic <span class="yellow">patients</span> were found to use significantly more verbal descriptors of pain compared to nonalexithymic <span class="yellow">patients</span> [13]. In our study, pain intensity was only evaluated by using VAS. One problem in trying to measure the intensity of pain is the lack of an objective way. Pain is a subjective experience and each <span class="yellow">patient</span> may communicate in a different way, verbally or nonverbally [29]. <span class="yellow">Patients</span> in this sample were sufferers of chronic pain, who had already chosen an approved way of expressing their distress. Since this is true regardless of alexithymia, alexithymic groups and nonalexithymic groups in this sample showed no difference on pain severity.
The positive correlation between alexithymia and the duration of pain in this sample supports the assumption of a two-way hypothesis. It is often assumed that pain can be caused by alexithymic personality traits and also that severe and chronic pain may cause emotional change. One of the limitations of this study is that because of the cross-sectional design, we are unable to draw conclusions about the direction of causality between alexithymia and pain. The duration of the <span class="yellow">patients</span>' pain could approximately be determined, yet the preexisting level of alexithymia was not known. In the usual absence of internal stimuli, alexithymic <span class="blue">person</span> may be expected to maintain an external focus of attention, such as pain. Symptom chronicity may force the alexithymic <span class="blue">person</span> to attent to and amplify this somatic sensation.
Difficulties in the ability to identify and differentiate emotions and somatic experiences are core features of the alexithymic construct. Therefore, alexithymic <span class="yellow">patients</span> might be expected to differ from nonalexithymic ones in their anxiety levels. Yet, in our pain group alexithymic <span class="yellow">patients</span> showed no significant difference from the nonalexithymics on trait anxiety. Besides, alexithymia and anxiety were not correlated at all. The reasons may be lying in the specific characteristics of this <span class="yellow">patient</span> group itself.
The study included <span class="yellow">patients</span> suffering from chronic symptoms; with an average of 7,44 ± 6,82 years of pain in the alexithymic and 3,31 ± 2,79 years in the nonalexithymic groups. Persistency of any physical symptom may bring along alexithymia as a coping strategy. In their paper, Crook and Tunks (1988) examined the types of coping strategies used by persistent pain sufferers and addressed to the importance to alter their attitudes and behavior that tend toward catastrophizing, avoidance and withdrawal, rather than simply concentrate on trying to teach them techniques for 'coping with stress' to help persistent pain sufferers [30]. Sufferers of chronic symptoms in this sample were members of a subgroup who have been seeking medical care for a long time and besides given the chance of being referred to a psychiatrist. Therefore, alexithymic or not, their anxiety might have induced unique coping strategies and illness behavior.
Alexithymia may be important in addressing the diversity of subjective factors involved in pain [31]. It is not known whether it should be addressed in the treatment of pain <span class="yellow">patients</span>, but a high level of alexithymia may effect the nature of assessment. In summary, the conceptualization of alexithymia as a personality trait as well as a secondary state reaction is underlined by our data. However, regarding the cross-sectional design of this study, only limited conclusions can be drawn about the nature of the causal relationship between alexithymia and chronic pain. Therefore, future longitudinal studies assessing the cause of alexithymic characteristics are required to fully elucidate the concepts of primary and secondary alexithymia.<br><br>
<h3>pmcA2556924</h3>Are there sensitive subgroups for the effects of airborne particles?
Abstract
Recent studies have shown that particulate air pollution is a risk factor for hospitalization for heart and lung disease; however, little is known about what subpopulations are most sensitive to this pollutant. We analyzed Medicare hospital admissions for heart disease, chronic obstructive pulmonary disorders (COPD) and pneumonia in Chicago, Cook County, Illinois, between 1985 and 1994. We examined whether previous admissions or secondary diagnoses for selected conditions predisposed <span class="yellow">persons</span> to having a greater risk from air pollution. We also considered effect modification by age, sex, and race. We found that the air-pollution-associated increase in hospital admissions for cardiovascular diseases was almost doubled in subjects with concurrent respiratory infections. The risk was also increased by a previous admission for conduction disorders. For COPD and pneumonia admissions, diagnosis of conduction disorders or dysrhythmias increased the risk of particulate matter < 10 microm in aerodynamic diameter (PM(10))-associated admissions. <span class="yellow">Persons</span> with asthma had twice the risk of a PM(10)-associated pneumonia admission and <span class="yellow">persons</span> with heart failure had twice the risk of PM(10)-induced COPD admissions. The PM(10) effect did not vary by sex, age, and race. These results suggest that <span class="yellow">patients</span> with acute respiratory infections or defects in the electrical control of the heart are a risk group for particulate matter effects.
Articles <br><br> Are There Sensitive Subgroups for the Effects of Airborne Particles? Antonella Zanobetti,1 Joel Schwartz,1,2 and Diane Gold1,2 1Environmental <br><br> Epidemiology Program, Department of Environmental Health, Harvard School of Public Health, Boston, Massachusetts, USA; 2Channing Laboratory, Department of Medicine, Harvard Medical School and Brigham and <span class="yellow">Women</span>'s Hospital, Boston, Massachusetts, USA <br><br> Recent studies have shown that particulate air pollution is a risk factor for hospitalization for heart and lung disease; however, little is known about what subpopulations are most sensitive to this pollutant. We analyzed Medicare hospital admissions for heart disease, chronic obstructive pulmonary disorders (COPD) and pneumonia in Chicago, Cook County, Illinois, between 1985 and 1994. We examined whether previous admissions or secondary diagnoses for selected conditions predisposed <span class="yellow">persons</span> to having a greater risk from air pollution. We also considered effect modification by age, sex, and race. We found that the air-pollution-associated increase in hospital admissions for cardiovascular diseases was almost doubled in subjects with concurrent respiratory infections. The risk was also increased by a previous admission for conduction disorders. For COPD and pneumonia admissions, diagnosis of conduction disorders or dysrhythmias increased the risk of particulate matter < 10 �m in aerodynamic diameter (PM10)-associated admissions. <span class="yellow">Persons</span> with asthma had twice the risk of a PM10-associated pneumonia admission and <span class="yellow">persons</span> with heart failure had twice the risk of PM10-induced COPD admissions. The PM10 effect did not vary by sex, age, and race. These results suggest that <span class="yellow">patients</span> with acute respiratory infections or defects in the electrical control of the heart are a risk group for particulate matter effects. Key words: effect modification, hospital admissions, particulate air pollution. Environ Health Perspect 108:841�845 (2000). [Online 28 July 2000] http://ehpnet1.niehs.nih.gov/docs/2000/108p841-845zanobetti/abstract.html <br><br> Particulate air pollution has been associated with increases in daily deaths and hospital admissions in studies all over the world (1�15). These associations are now well documented but little is known, as yet, of the characteristics of <span class="yellow">persons</span> that put them at increased risk of adverse events related to particulate air pollution. This has been identified as a key data gap (16). Schwartz and Dockery (17) reported that <span class="yellow">persons</span> older than 65 years of age had a somewhat increased risk of death, and this has been confirmed in other studies (18). A more detailed examination of particulate matter-related risk by deciles of age (19) showed the risk beginning to increase at approximately 40 years of age and reaching its maximum for those 75 years of age and older. In addition to age, several studies suggest that <span class="yellow">persons</span> with respiratory illness are at increased risk for cardiovascular effects associated with air pollution. An examination of death certificates on high- and low-air pollution days reported a substantial difference in the proportion of deaths from cardiovascular causes that had respiratory disease as a contributing cause of death (19). A recent follow-up study of a cohort of <span class="yellow">persons</span> with chronic obstructive pulmonary disease (COPD) in Barcelona, Spain, found an association between particulate air pollution and all-cause mortality in the cohort (20). The magnitude of the risk per microgram per cubic meter of exposure was substantially greater than that for the general population. Environmental Health Perspectives <br><br> Controlled exposure of animals with chronic bronchitis and control animals to concentrated air particles also demonstrated a potentiating effect of chronic lung disease in the response to airborne particles (21). This has led to the hypothesis that the cardiovascular effects of air pollution are predominantly in <span class="yellow">persons</span> with chronic lung disease. There has been even less done to examine potential modifiers of the effects of airborne particles on hospital admissions. The existing literature on comorbidity shows that comorbidity per se seems to increase the risk of adverse outcomes (22�30). Little is known about the role of these comorbidities as effect modifiers for the effects of air pollution. This study uses data from the Medicare system to examine potential short-term and long-term medical conditions that may increase a <span class="blue">person</span>'s risk of hospital admissions associated with particulate air pollution. In addition, we examine potential effect modification by age, race, and sex. <br><br> Materials and Methods Health data. The Health Care Financing Administration (Baltimore, MD) maintains records of every hospital admission for Medicare <span class="yellow">participants</span> in the United States. <span class="yellow">Persons</span> in this database have a unique identifier. Using this identifier, we traced every hospital admission for heart and lung disease for each <span class="blue">person</span> in Cook County, Illinois, between 1985 and 1994. We chose Cook County because it is the most populous <br><br> county in the United States with daily monitoring for particulate matter with aerodynamic diameter < 10 �m (PM10). The data were then analyzed to look at effect modification by concurrent and preexisting conditions as well as by age, race, and sex. To establish a baseline risk, we computed daily counts of hospital admissions for cardiovascular disease (CVD) [International Classification of Disease, 9th edition, World Health Organization, Geneva (ICD-9) code 390�429], pneumonia (ICD-9 code 480�487), and COPD (ICD-9 code 490�496, excluding 493). The association between these daily counts and PM10 was examined for the years 1988�1994, when daily PM10 monitoring data were available in Chicago. Once our baseline risks were established, we examined three classes of potential effect modifiers. First, we looked at whether previous admissions for selected conditions predisposed <span class="yellow">persons</span> to having a greater risk from air pollution. For each of the three admission categories (CVD, pneumonia, and COPD), we considered 10 causes (defined by a previous admission) as effect modifiers: COPD (ICD-9 code 490�496 except 493), asthma (ICD-9 code 493), acute bronchitis (ICD-9 code 466), acute respiratory illness (ICD-9 code 460�466), pneumonia (ICD-9 code 480�487), CVD (ICD-9 code 390�429), myocardial infarction (ICD-9 code 410), congestive heart failure (ICD-9 code 428), conduction disorders (ICD-9 code 426), and dysrhythmias (ICD9 code 427). To test the hypothesis that <span class="yellow">persons</span> with these conditions had higher risks of subsequent PM10-related admissions, we computed separate daily counts of admissions for our three target causes, stratified by whether or not the <span class="blue">person</span> admitted had been previously admitted for the hypothesized predisposing condition. Separate analyses were then performed within each strata to see if the effects of PM10 differed by strata. Address correspondence to A. Zanobetti, Department of Environmental Health, Environmental Epidemiology Program, Harvard School of Public Health, 665 Huntington Avenue, Boston, MA 02115 USA. Telephone: (617) 4324642. Fax: (617) 277-2382. E-mail: azanob@ sparc6a.harvard.edu Supported by NIEHS grant ES07937. Received 18 January 2000; accepted 18 April 2000. <br><br> � VOLUME 108 | NUMBER 9 | September 2000 <br><br> 841 <br><br> Articles <br><br> � <br><br> Zanobetti et al. <br><br> The second set of potential predisposing conditions included secondary diagnoses associated with the index admission. These could represent the presence of a chronic condition (e.g., COPD) that has not resulted in a previous hospital admission. They could also represent acute conditions that may have increased the subjects' sensitivity to air pollution. For example, if respiratory infections modified the effect of particulate matter on the cardiovascular health of <span class="yellow">persons</span> with underlying heart disease, then the risk of a hospital admission for heart disease might be different in <span class="yellow">persons</span> with infections. If this were true, then the risk ratio of a 10-�g/m3 increase of PM10 on cardiovascular admissions of <span class="yellow">persons</span> with a concurrent respiratory infection would be different from the ratio in <span class="yellow">persons</span> without respiratory infection. To test these hypotheses, we computed separate daily counts of admissions for events with and without the concurrent conditions hypothesized to increase sensitivity to air pollution. These were taken as the same 10 conditions in the first analysis with certain exclusions for pairing that would be illogical. That is, the concurrent diagnosis of a specific cardiac condition was not treated as an effect modifier for admissions for any cardiovascular condition. Likewise, pneumonia and COPD were not possible concurrent conditions for each other. The third set of predisposing conditions considered was being older than 75 years of age, nonwhite, and female. These were examined for all three outcomes. We obtained weather data for O'Hare Airport from the EarthInfo CD-ROM (EarthInfo CD NCDC Surface Airways, EarthInfo Inc., Boulder, CO), and we obtained air pollution data from the U.S. Environmental Protection Agency Aerometric Information Retrieval System network (31). <br><br> running-line smoother, loess (35), was chosen to estimate the smooth function. To control for weather variables and day of the week, we chose the smoothing parameter that minimized the Akaike's information criterion (36). To model seasonality we chose the smoothing parameter that minimized the sum of the autocorrelation of the residuals while removing seasonal patterns. Two autoregressive terms (37) were added in the model to eliminate the remaining serial correlation from the residuals. We used the mean of PM10 on the day of the admission and the day before the admission as our exposure variable. This gives results that are similar to those obtained fitting a full distributed lag model (38). PM10 was treated linearly. Our baseline models used the daily counts of CVD, pneumonia, and COPD admissions as outcomes. We then subdivided those counts by the presence or absence of the potential effect modifier and reestimated our regressions on those subgroups. We considered effect modification to be indicated when the estimates of PM10 in the group with the condition was outside of the 95% confidence interval (CI) of the effect estimate in <span class="yellow">persons</span> without the condition. <br><br> Results Table 1 shows the mean daily admissions for COPD, cardiovascular, and pneumonia both overall and in the presence of the potential effect modifiers. For some effect modifiers such as conduction disorders or myocardial infarctions, the counts in conjunction with our respiratory outcomes are <br><br> low, which limits power. In general, the numbers are lower for examining effect modification by previous admissions than for effect modification by concurrent diagnosis. This is as expected because many clinically relevant comorbidities may never have resulted in a hospital admission. Table 2 shows the 25th, 50th, and 75th percentile values for the environmental variables. The mean value for PM10 is 33 �g/m3. The daily values for PM10 were computed as the average of 10 monitors, two of which measured PM10 almost every day and the others less frequently (38). Table 3 shows the mean daily counts of CVD, COPD, and pneumonia by sex, age groups, and race. The distribution by sex is almost even, although the counts of admissions for males are generally lower (approximately 10%) than for females, particularly for cardiovascular diseases. The counts of CVD, COPD, and pneumonia admissions were similar for <span class="yellow">people</span> 65�75 or 75 years of age and older. Tables 4�6 show the results for the effect PM10 overall and stratifying by concurrent diagnosis and previous admissions. These are expressed as the percentage increase for 10 �g/m3 PM10. Table 4 shows the results for CVD. A 10-�g/m3 increase in PM10 was associated with a 1.31% (5% CI, 0.97%; 95% CI, 1.66%) increase in hospital admissions for heart disease in all elderly <span class="yellow">persons</span>. A concurrent (not previous) diagnosis of COPD modified the risk of PM10-associated admissions for heart disease. However, significant associations were still seen between PM10 <br><br> Table 1. Mean daily counts of admissions, Chicago 1986�1994, for COPD, CVD, and pneumonia overall and by concurrent diagnosis and by previous admissions. By concurrent diagnosis COPD CVD Pneumonia Overall Respiratory disease Acute bronchitis Acute respiratory infections Pneumonia Asthma COPD Cardiovascular disease CVD Conduction disorders Cardiac dysrhythmias Congestive heart failure Myocardial infarction NA, not applicable. <br><br> By previous admissions COPD CVD Pneumonia 7.8 0.8 0.9 1.6 0.9 2.7 2.1 0.0 0.4 0.9 0.3 102.1 1.6 1.8 7.3 1.5 2.0 54.7 1.0 9.9 24.2 11.4 26.5 0.9 1.0 6.4 0.7 1.4 7.2 0.2 1.5 3.1 1.0 <br><br> Methods We analyzed the data with a generalized additive robust Poisson regression model (32). This approach has become the norm in such studies (14,33,34). In the generalized additive model the outcome is assumed to depend on a sum of nonparametric smooth functions for each variable that models the potential nonlinear dependence of daily admission on weather and season. The model is of the form: log[E(Yt)] = 0+ S1 (X1 )+... + Sp (Xp) where E(Yt) is the expected value of the daily count of admissions Yt and Si are the smooth functions of the covariates Xi. We examined temperature, previous day's temperature, relative humidity, barometric pressure, and day of week covariates. The locally weighted <br><br> 7.8 0.1 0.3 0.4 0.1 NA 4.7 0.2 1.4 1.8 0.1 <br><br> 102.1 0.9 1.3 4.0 1.8 13.4 NA NA NA NA NA <br><br> 26.5 0.3 0.3 NA 0.9 6.9 14.7 0.6 4.6 7.3 0.4 <br><br> Table 2. 25th, 50th, and 75th percentile values for the environmental variables in Chicago, 1988�1994. Temperature (�F) 35 51 67 Relative humidity 62 70 79 Barometric pressure 29.2 29.3 29.4 PM10 (�g/m3) 23 33 46 <br><br> Table 3. Mean daily counts of admissions by sex, race, and age groups, Chicago, 1986�1994. Group Overall Female Nonwhite Age > 75 years COPD 7.8 4.2 1.6 3.7 CVD 102.1 59.4 21.0 55.1 Pneumonia 26.5 14.7 5.2 17.4 <br><br> 842 <br><br> VOLUME <br><br> 108 | NUMBER 9 | September 2000 � Environmental Health Perspectives <br><br> Articles <br><br> � <br><br> Effects of particles on sensitive subgroups <br><br> and heart disease admissions in <span class="yellow">persons</span> without COPD listed as either a comorbidity or a cause of previous admission (Table 4). A significant association was also seen in <span class="yellow">persons</span> without any respiratory disease as a concurrent diagnosis, although the risk is much lower than in <span class="yellow">persons</span> with respiratory disease. However, the risk associated with PM10 was roughly doubled in subjects with concurrent respiratory infections and the risk estimates in those subjects were outside the 95% CI of the risk in <span class="yellow">patients</span> without concurrent respiratory infections. A previous admission for conduction disorders (e.g., heart block) increased the risk of a PM10-related subsequent admission for any heart condition, and a weaker indication of effect modification was seen for <span class="yellow">persons</span> with previous admission for dysrhythmias. In contrast heart failure and previous myocardial infarctions were highly insignificant as effect modifiers. Table 5 shows the results for COPD. Overall, there is a 1.89% (95% CI, 0.8�3.0) increase in COPD admissions for a 10�g/m3 increase in PM10. The results of the stratified analysis suggest that preexisting heart disease modifies Table 4. Percentage increase in hospital admissions for CVD in all <span class="yellow">persons</span> and by concurrent diagnosis and previous admissions. PM10 2.5% CI 97.5% CI All <span class="yellow">persons</span> 1.31 By concurrent diagnosis Respiratory disease All respiratory disease With 1.65 Without 0.98 Acute bronchitis With 2.50 Without 1.07 Acute respiratory infections With 2.71 Without 1.06 Pneumonia With 1.95 Without 1.03 COPD With 1.59 Without 1.08 By previous admissions Respiratory disease All respiratory disease With 1.18 Without 1.08 COPD With 1.48 Without 1.09 Asthma With 1.71 Without 1.08 Cardiovascular disease Conduction disorders With 2.89 Without 1.07 Cardiac dyshrethmias With 1.61 Without 1.04 0.97 1.66 <br><br> the risk of COPD admissions on high particle days. Previous admissions for any cardiovascular disease increased the risk of a PM10associated COPD admission approximately 2.5-fold. A previous heart failure admission caused an even more striking increase in the PM10 effect. Previous admissions for dysrhythmias and conduction defects were rare (Table 1) with no power to examine effect modifications. Listings as concurrent diagnoses were more common and here they joined heart failure in increasing the risk of PM 10 -associated COPD admissions. For COPD there was also some indication that concurrent pneumonia or an acute respiratory infection admission in the last year increased risk. The low numbers made these estimates less precise, however. The percentage increase in pneumonia admission (Table 6) for 10 �g/m3 PM10 is higher than for COPD or CVD with an increase of 2.34% (95% CI, 1.66�3.0). As with COPD, <span class="yellow">persons</span> with heart disease appeared at higher risk of pneumonia hospital admissions associated with particulate air pollution. Here diagnoses suggestive of impaired autonomic control of the heart, such as conduction disorders or dysrhythmias, were associated with increased risk for PM 10 effects on pneumonia admissions. Unlike COPD, no difference was seen for congestive heart failure. <span class="yellow">Persons</span> with asthma Table 5. Percentage increase in hospital admissions for COPD in all <span class="yellow">persons</span> and by concurrent diagnosis and previous admissions. PM10 2.5% CI 97.5% CI All <span class="yellow">persons</span> 1.89 By concurrent diagnosis Respiratory disease Pneumonia With 4.00 Without 1.51 Cardiovascular disease Conduction disorders With 2.34 Without 1.60 Cardiac dysrhythmias With 3.09 Without 1.43 Congestive heart failure With 2.90 Without 1.39 By previous admissions Respiratory disease Acute respiratory infections With 3.20 Without 1.70 Cardiovascular disease CVD With 2.90 Without 1.18 Congestive heart failure With 4.37 Without 1.14 Within 1 year 6.04 0.80 2.99 <br><br> had twice the risk of a PM10-induced pneumonia admission as <span class="yellow">persons</span> without asthma. Table 7 shows the results by sex, age, and race. None of the effect size estimates for any of the stratification variables were outside of the 95% CI for the opposite strata. There was a tendency for the effect of PM10 on CVD admissions to be higher for females, whereas the effect on pneumonia admissions was higher for males. In general, we found somewhat larger effects on whites compared to nonwhites, and for <span class="yellow">persons</span> older than 75 years of age compared to younger <span class="yellow">persons</span>. <br><br> Discussion In this analysis we examined whether the effect of PM10 on the risk of hospital admission for heart and lung disease was different depending on the presence of comorbidities. We found that PM10 was associated with hospital admissions for all three causes (CVD, COPD, and pneumonia) and we found not a general increase in PM10 related risk with comorbidities, but a specific pattern that is suggestive of potential mechanisms and consistent with other recent epidemiologic and toxicologic findings. One major finding of this study is that preexisting cardiovascular disease, particularly impaired autonomic control (conduction defects and dysrhythmias) and heart failure, substantially increased the risk of respiratory admissions associated with airborne particles. In fact, recent <span class="yellow">human</span> studies have shown that exposure to particulate air pollution is a risk factor for reduced heart rate variability (39�41). Reduced heart rate variability is an adverse response and a risk factor for arrhythmia. A new study of defibrillator discharges in <span class="yellow">patients</span> with implanted cardioverter defibrillators found that discharges were associated with air pollution (42). Exposure to combustion Table 6. Percentage increase in hospital admissions for pneumonia in all <span class="yellow">persons</span> and by concurrent diagnosis and previous admissions. PM10 All <span class="yellow">persons</span> By concurrent diagnosis Respiratory disease Asthma With Without Cardiovascular disease Conduction disorders With Without Cardiac dysrhythmias With Without By previous admissions Cardiovascular disease Cardiac dysrhythmias With Without 2.34 2.5% CI 97.5% CI 1.66 3.02 <br><br> 1.10 0.64 �0.47 0.76 0.18 0.76 0.55 0.72 0.85 0.75 <br><br> 2.20 1.33 5.55 1.37 5.30 1.37 3.36 1.35 2.34 1.41 <br><br> �0.45 0.47 �4.42 0.58 0.64 0.33 0.77 0.24 <br><br> 8.65 2.57 9.59 2.64 5.60 2.55 5.08 2.55 <br><br> 0.45 0.76 �0.40 0.78 �0.43 0.77 0.22 0.76 0.75 0.72 <br><br> 1.91 1.41 3.40 1.40 3.89 1.39 5.63 1.38 2.48 1.36 <br><br> 4.18 2.07 7.92 1.99 � � <br><br> 1.01 1.46 4.28 1.37 � � <br><br> 7.46 2.69 11.69 2.61 � � <br><br> �1.38 0.66 0.99 �0.01 1.43 0.05 2.10 <br><br> 8.01 2.76 4.85 2.39 7.40 2.24 10.14 <br><br> 3.47 2.08 <br><br> 1.21 1.45 <br><br> 5.79 2.71 <br><br> Increases are for a 10-�g/m3 increase in PM10. <br><br> Increases are for a 10-�g/m3 increase in PM10. <br><br> Increases are for a 10-�g/m3 increase in PM10. <br><br> Environmental Health Perspectives <br><br> � VOLUME 108 | NUMBER 9 | September 2000 <br><br> 843 <br><br> Articles <br><br> � <br><br> Zanobetti et al. <br><br> Table 7. Effect modification by sex, race, and age groups for 10 �g/m3 PM10. % All <span class="yellow">persons</span> Male Female White Non-white Age > 75 Age  75 1.89 1.34 2.19 1.65 1.07 2.20 1.33 COPD (95% CI) (0.80, 2.99) (�0.14, 2.84) (0.81, 3.59) (0.51, 2.81) (�1.11, 3.3) (0.72, 3.69) (0.03, 2.65) % 1.31 1.07 1.21 1.20 0.70 1.28 0.93 CVD (95% CI) (0.97, 1.66) (0.62, 1.51) (0.83, 1.6) (0.86, 1.55) (0.1, 1.3) (0.88, 1.69) (0.51, 1.35) % 2.34 2.65 1.91 2.45 1.91 2.12 2.52 Pneumonia (95% CI) (1.66, 3.02) (1.81, 3.5) (1.11, 2.72) (1.77, 3.14) (0.69, 3.14) (1.38, 2.86) (1.57, 3.48) <br><br> Figures shown are the percentage increase in admissions (95% CI). <br><br> particles has also been associated with arrhythmia in an animal model (43) and changes in ST segments have been noted as well (44). This is the first study to suggest <span class="yellow">persons</span> with defects in the electrical control of the heart are also at higher risk of respiratory illness after exposure to airborne particles. These data also suggest that <span class="yellow">persons</span> admitted to hospitals for pneumonia during an air pollution episode may be at high risk for clinically significant conduction disorders during that hospital admission. <span class="yellow">Patients</span> with congestive heart failure were at greater risk of hospital admissions for COPD in association with airborne particles. Heart failure and COPD is not an uncommon combination. The finding that these <span class="yellow">patients</span> are at higher risk for admissions associated with particulate air pollution is new but is also consistent with several other recent reports. The spontaneous hypertensive <span class="yellow">rat</span> develops a model of heart failure, and recent studies have reported greater sensitivity to particulate air pollution in these <span class="yellow">rats</span>. These include both electrocardiogram abnormalities (44) and pulmonary toxicity (45,46). Similarly, in an epidemiologic study, Hoek et al. (47), found a higher relative risk of death with an increase in PM10 for congestive heart failure deaths than other deaths. The potential role of COPD in those heart failure deaths was not examined. Another consistent pattern in our data is of acute respiratory infections increasing susceptibility to airborne particles. Acute bronchitis, or more generally acute upper respiratory illnesses, as well as pneumonia, increased susceptibility to particle-associated admissions for CVD and COPD. The notion that air pollution exacerbates acute respiratory infections is well supported by studies which report associations between airborne particles and hospital admissions for respiratory infections (48,49). Zelikoff et al. (50) exposed <span class="yellow">rats</span> infected with streptococcus to concentrated air particles and reported a significant increase in bacterial burdens and in the extent of pneumonia compared to animals exposed to filtrated air. This suggests an impaired immune response. Similarly, exposure to combustion <br><br> particles enhances influenza infections in <span class="yellow">mice</span> (51). An impaired defense to respiratory infection is a major reason that <span class="yellow">persons</span> with COPD require hospital admission. If airborne particles result in further impairment the effect modification we observe makes good sense. The effect modification for heart disease admissions is more relevant. This modification is consistent with the earlier report of Schwartz (19), who found greater reports of respiratory complications on death certificates with an underlying cause of heart disease if the death occurred on a day with high levels of airborne particles. Although airborne particle exposure has been associated with increased exacerbation of asthma (2,12,48,52�59), this paper is the first to suggest that asthmatics are more susceptible to PM10-induced pneumonia exacerbation or to cardiovascular effects. The effects on pneumonia admissions are plausible, given the impaired ability to fight off infections in asthmatics with mucus plugs and the evidence the airborne particles impair the lungs' ability to fight off bacterial and viral infections, as noted earlier. The increased cardiovascular sensitivity, albeit weaker, is interesting. If airborne particles affect the cardiovascular system via the role of the lung in autonomic control, it is possible that asthmatics would be more sensitive to those effects. Animal models of asthma showed that combustion particles enhance the asthmatic response to aeroallergen challenges (59). This suggests an enhancement of pulmonary response in asthmatics. On the other hand, the diagnosis of asthma is problematic in the elderly, and crossover with COPD is possible. The possibility that this explains our results is reduced by our failure to find previous hospital admission for COPD was an effect modifier for the effect of particles on cardiovascular admissions. We must acknowledge several potential limitations of this study. First, we considered only previous admissions that occurred within Cook County. Hence <span class="yellow">persons</span> with previous admissions elsewhere would be misclassified to our reference group. The effect of this would be to reduce the difference in PM 10 effect between the two groups. VOLUME <br><br> Nevertheless, we identified some interesting interactions. We cannot exclude the possibility that there are areas we missed for this reason. We also examined interactions in a log relative risk model, which is inherently multiplicative. Although we believe this is justified because doubling the population exposed would be expected to double the pollution associated admissions, it results in a more conservative definition of interaction than would an additive risk model. Finally, our exposure is clearly measured with error. Most of this error is Berkson error (60) and hence will introduce no bias, and Zeger et al. (60) showed that the remaining error would have to have pathologic correlations with other variables to result in an upward bias. Another important result from this study, of course, is an estimate of the magnitude of the effect of airborne particles on public health. The PM10 concentrations in Chicago during this period were associated with approximately 1,600 additional admissions per year for heart disease, 740 additional admissions per year for pneumonia, and 170 additional admissions per year for COPD. These are not trivial increases in serious morbidity. The results of our study should be replicated in additional cities, although they do begin to fill in some missing information about the effects of airborne particles on health. More generally airborne particles have been associated with a broad range of systemic changes including heart rate variability (39�41), increased peripheral neutrophils (61�63), increased plasma viscosity (64), an increase in blood pressure (65), and the outcomes mentioned previously. The role of these systemic changes as potential sources of the specific effect modifications we have seen should be an area of fruitful research in the future. REFERENCES AND NOTES 1. Katsouyanni K, Touloumi G, Spix C, Schwartz J, Balducci F, Medina S, Rossi G, Wojtyniak D, Sunyer J, Bacharova L, et al. Short term effects of ambient sulphur dioxide and particulate matter on mortality in 12 European cities: results from time series data from the APHEA project. Br Med J 314:1658�1663 (1997). Pope CA, Dockery DW, Schwartz J. Review of epidemiologic evidence of health effects of particulate air pollution. Inhal Toxicol 7:1�18 (1995). Schwartz J. Air pollution and daily mortality: a review and meta analysis. Environ Res 64:36�52 (1994). Dominici F, Samet J, Zeger SL. Combining evidence on air pollution and daily mortality from the largest 20 US cities: a hierarchical modeling strategy. R Stat Soc Ser A, in press. Burnett RT, Dales RE, Raizenne ME, Krewski D, Summers PW, Roberts GR, Raad-Young M, Dann T, Brooke T. Effects of low ambient levels of ozone and sulfates on the frequency of respiratory admissions to Ontario hospitals. Environ Res 65:172�194 (1994). Anderson HR, Spix C, Medina S, Schouten JP, Castellsague J, Rossi G, Zmirou D, Touloumi G, Wojtyniak B, Ponka A, et al. Air pollution and daily admissions for <br><br> 2. <br><br> 3. 4. <br><br> 5. <br><br> 6. <br><br> 844 <br><br> 108 | NUMBER 9 | September 2000 � Environmental Health Perspectives <br><br> Articles <br><br> � <br><br> Effects of particles on sensitive subgroups <br><br> 7. <br><br> 8. 9. <br><br> 10. <br><br> 11. <br><br> 12. <br><br> 13. <br><br> 14. <br><br> 15. <br><br> 16. <br><br> 17. <br><br> 18. <br><br> 19. 20. <br><br> 21. <br><br> 22. <br><br> 23. <br><br> 24. <br><br> 25. <br><br> 26. <br><br> 27. <br><br> 28. <br><br> 29. <br><br> 30. <br><br> chronic obstructive pulmonary disease in 6 European cities: results from the APHEA project. Eur Respir J 10:1064�1071 (1997). Schwartz J. Short term fluctuations in air pollution and hospital admissions of the elderly for respiratory disease. Thorax 50:531�538 (1995). Schwartz J. Air pollution and hospital admissions for heart disease in eight U.S. counties. Epidemiology 10:17�22 (1999). Schwartz J. Air pollution and hospital admissions for the elderly in Minneapolis. Arch Environ Health 49:366�374 (1994). Schwartz J. Air pollution and hospital admissions for the elderly in Birmingham, Alabama. Am J Epidemiol 139:589�598 (1994). Schwartz J. Air pollution and hospital admissions for the elderly in Detroit, MI. Am J Respir Crit Care Med 150:648�655 (1994). Pope CA III. Respiratory disease associated with community air pollution and a steel mill, Utah valley. Am J Public Health 79:623�628 (1989). Saldiva PH, Pope CA, Schwartz J, Dockery DW, Lichtenfels AJ, Salge JM, Barone I, Bohm GM. Air pollution and mortality in elderly <span class="yellow">people</span>: a time series study in Sao Paulo, Brazil. Arch Environ Health 50:159�163 (1995). Schwartz, J. Air pollution and hospital admissions for cardiovascular disease in Tucson. Epidemiology 8:371�177 (1997). Delfino RJ, Murphy Moulton AM, Becklake MR. Emergency room visits for respiratory illnesses among the elderly in Montreal: association with low level ozone exposure. Environ Res 76:67�77 (1998). National Research Council. Research Priorities for Airborne Particulate Matter. Washington, DC:National Academy Press, 1998. Schwartz J, Dockery DW. Increased mortality in Philadelphia associated with daily air pollution concentrations. Am Rev Respir Dis 145:600�604 (1992). Samet JM, Zeger SL, Berhane K. The association of mortality and particulate air pollution. In: Particulate Air Pollution and Daily Mortality. The Phase I Report of the Particle Epidemiology Evaluation Project. Boston, MA:Health Effects Institute, 1995. Schwartz J. What are <span class="yellow">people</span> dying of on high air pollution days? Environ Res 64:26�35 (1994). Sunyer J, Schwartz J, Tobias A, MacFarlane D, Garcia J, Anto JM. <span class="yellow">Patients</span> with chronic obstructive pulmonary disease are a susceptible population of dying due to urban particles. Am J Epidemiol 151(1):50�56 (2000). Godleski JJ, Sioutas C, Katler M, Koutrakis P. Death from inhalation of concentrated air particles in animal models of pulmonary disease. Am J Respir Crit Care Med 153:A15 (1996). Matsui K, Goldman L. Comorbidity as a correlate of length of stay for hospitalized <span class="yellow">patients</span> with acute chest pain. J Gen Intern Med 11:262�268 (1996). Charlson M, Szatrowshi TP, Peterson J, Gold J. Validation of a combined comorbidity index. J Clin Epidemiol 47:1245�1251 (1994). Monane M, Kanter DS, Glynn RJ, Avorn J. Variability in length of hospitalization for stroke. The role of managed care in an elderly population. Arch Neurol 53:848 (1996). Hallstrom AP, Cobb LA, Yu BH. Influence of comorbidity on the outcome of <span class="yellow">patients</span> treated for out-of-hospital ventricular fibrillation. Circulation 93:2019�2022 (1996). Malenka DJ, Mclerran D, Roos N, Fisher ES, Wennberg JE. Using administrative data to describe case-mix: a comparison with the medical record. J Clin Epidemiol 47:1027�1032 (1994). Romano PS, Roos LL, Jollis JG. Adapting a clinical comorbidity index for use with ICD-9-CM administrative data: differing perspectives. J Clin Epidemiol 46:1075�1079 (1993). Deyo RA, Cherkin DC, Ciol MA. Adapting a clinical comorbidity index for use with ICD-9CM administrative databases. J Clin Epidemiol 45:613�619 (1992). Charlson ME, Pompei P, Ales KL, MacKenzie CR. A new method of classifying prognostic comorbidity in longitudinal studies: development and validation. J Chronic Dis 40:373�383 (1987). Librero J, Peir� S, Ordi�ana R. Chronic comorbidity and outcomes of hospital care: length of stay, mortality, and readmission at 30 and 365 days. J Clin Epidemiol 52:171�179 (1999). <br><br> 31. Nehls GJ, Akland GG. Procedures for handling aerometric data. J Air Pollut Control Assoc 23:180�184 (1973). 32. Hastie T, Tibshirani R. Generalized Additive Models. London:Chapman and Hall, 1990. 33. Schwartz J. Generalized additive models in epidemiology. In: International Biometric Society, Invited Papers. 17th International Biometric Conference, 8�12 August 1994, Hamilton, Ontario, Canada. Washington, DC:International Biometric Society, 1994;55�80. 34. Rossi G, Vigotti MA, Zanobetti A, Repetto F, Giannelle V, Schwartz J. Air pollution and cause specific mortality in Milan, Italy, 1980�1989. Arch Environ Health 54:158�164 (1999). 35. Cleveland WS, Devlin SJ. Robust locally-weighted regression and smoothing scatterplots. J Am Stat Assoc 74:829�836 (1988). 36. Akaike H. Information theory and an extension of the maximum likelihood principal. In: 2nd International Symposium on Information Theory (Petrov BN, Csaki F, eds). Budapest:Akademiai Kaiado, 1973;267�281. 37. Brumback BA, Ryan LM, Schwartz J, Neas LM, Stark PC, Burge HA. Transitional regression models with application to environmental time series. J Acoust Soc Am 95(449):16�28 (2000). 38. Schwartz J. The distributed lag between air pollution and daily deaths. Epidemiology 11:320�326 (2000). 39. Pope CA III, Verrier RL, Lovett EG, Larson AC, Raizenne ME, Kanner RE, Schwartz J, Villegas GM, Dockery DW. Heart rate variability associated with particulate air pollution. Am Heart J 138:890�899 (1999). 40. Gold DR, Litonjua A, Schwartz J, Lovett E, Larson A, Nearing B, Allen G, Verrier M, Cherry R, Verrier R. Ambient pollution and heart rate variability. Circulation 101(11):1267�1273 (2000). 41. Liao D, Creason J, Shy C, Williams R, Watts R, Zweidinger R. Daily variation of particulate air pollution and poor cardiac autonomic control in the elderly. Environ Health Perspect 107:521�525 (1999). 42. Peters A, Liu E, Verrier RL, Schwartz J, Gold DR, Mittelman M, Baliff J, Allen G, Monahan K, Dockery DW. Air pollution and incidences of cardiac arrhythmia. Epidemiology 11(1):11�17 (2000). 43. Godleski JJ, Verrier RL, Koutrakis P, Catalano P. Mechanisms of Morbidity and Mortality from Exposure to Ambient Air Particles. Health Effects Institute Research Report 91. Cambridge, MA:Health Effects Institute, 2000. 44. Watkinson WP, Campen MJ, Kodavanti UP, Ledbetter AD, Costa DL. Effects of inhaled residual oil <span class="yellow">fly</span> ash particles on electrocardiographic and thermoregulatory parameters in normal and compromised <span class="yellow">rats</span> [Abstract]. Am J Respir Crit Care Med 157:A150 (1998). 45. Watkinson WP, Campen MJ, Costa DL. Cardiac arrhythmia induction after exposure to residual oil <span class="yellow">fly</span> ash particles in a <span class="yellow">rodent</span> model of pulmonary hypertension. Toxicol Sci 41:209�216 (1998). 46. Kodavanti UP, Jackson MC, Richards J, Ledbetter A, Costa DL. Differential pulmonary responses to inhaled emission particulate matter (PM) in systemically hypertensive vs. normotensive <span class="yellow">rats</span> [Abstract]. Am J Respir Crit Care Med 157:A260 (1998). 47. Hoek G, Brunekreef B, van Wijnen JH. Cardiovascular mortality response to air pollution is strongest for heart failure and thrombotic causes of death [Abstract]. Epidemiology 10:S177 (1999). 48. Bates DV, Szito R. Hospital admissions and air pollutants in southern Ontario: the acid summer haze effect. Environ Res 43:317�331 (1987). 49. Pope CA III. Respiratory disease associated with community air pollution and a steel mill, Utah valley. Am J Public Health 79:623�628 (1989). 50. Zelikoff JT, Nadziejko C, Fang T, Gordon C, Premdass C, Cohen MD. Short term, low-dose inhalation of ambient particulate matter exacerbates ongoing pneumococcal infections in Streptococcus Pneumoniae-infected rates. In: Proceedings of the Third Colloquium on Particulate Air Pollution and <span class="yellow">Human</span> Health (Phalen RF, Bell YM, eds). Irvine, CA:Air Pollution Health Effects Laboratory, University of California, 1999;8-94�8-101. 51. Clarke RW, Hemenway DR, Frank R, Kleeberger SR, Longphre MV, Jakab GJ. Particle associated sulfate exposure enhances <span class="yellow">murine</span> influenza mortality [Abstract]. Am J Respir Crit Care Med 155:A245 (1997). <br><br> 52. Pope CA, Dockery DW, Spengler JD, Raizenne ME. Respiratory health and PM10 pollution: a daily time series analysis. Am Rev Respir Dis 144:668�674 (1991). 53. Schwartz J, Koenig J, Slater D, Larson T. Particulate air pollution and hospital emergency visits for asthma in Seattle. Am Rev Respir Dis 147:826�831 (1993). 54. Thurston GD, Ito K, Lippman M, Hayes CG, Bates DV. Respiratory hospital admissions and summertime haze air pollution in Toronto, Ontario: consideration of the role of acid aerosols. Environ Res 65:271�290 (1994). 55. Norris G, YoungPong SN, Koenig JQ, Larson TV, Sheppard L, Stout JW. An association between fine particles and asthma emergency department visits for <span class="yellow">children</span> in Seattle. Environ Health Perspect 107:489�493 (1999). 56. Hamada K, Goldsmith CW, Kobzik L. Air pollutant aerosols allow airway sensitization to allergen in juvenile <span class="yellow">mice</span>. Am J Resp Crit Care Med A28 (1999). 57. Lambert AL, Selgrade M, Dong W, Winsett D, Gilmour M. Enhanced allergic sensitization by residual oil <span class="yellow">fly</span> ash particles is mediated by soluble metal constituents [Abstract]. Am J Respir Crit Care Med 159:A26 (1999). 58. Dailey LA, Madden MC, Devlin RB. Do airway epithelial cells from normal and asthmatic donors respond differently to an in vitro challenge with a particulate pollutant? [Abstract]. Am J Respir Crit Care Med 157:A598 (1998). 59. Gilmour MI, Winsett D, Selgrade MJ, Costa DL. Residual oil <span class="yellow">fly</span> ash exposure enhances allergic sensitization to house dust mite in <span class="yellow">rats</span> and augments immune-mediated inflammation [Abstract]. Am J Respir Crit Care Med 155:A244 (1997). 60. Zeger SL, Thomas D, Dominici F, Samet JM, Schwartz JM, Dockery D, Cohen A. Exposure measurement error in time�series studies of air pollution: concepts and consequences. Environ Health Perspect 108:419�426 (2000). 61. Salvi S, Blomberg A, Rudell B, Kelly F, Sandstrom T, Holgate ST, Frew A. Acute inflammatory responses in the airways and peripheral blood after short-term exposure to diesel exhaust in healthy <span class="yellow">human</span> volunteers. Am J Respir Crit Care Med 159:702�709 (1999). 62. Tan WC, van Eeden S, Qiu DW, Liam BL, Dyachokova Y, Hogg JL. Particulate air pollution, bone marrow stimulation and the pathogenesis of excess cardiovascular and pulmonary deaths. Am J Respir Crit Care Med 155:1441�1447 (1997). 63. Gordon T, Nadziejko C, Schlesinger R, Chen LC. Pulmonary and cardiovascular effects of acute exposure to concentrated ambient particulate matter in <span class="yellow">rats</span>. Toxicol Lett 96�97:285�288 (1998). 64. Peters A, Doering A, Wichmann HE, Koenig W. Increased plasma viscosity during an air pollution episode: a link to mortality? Lancet 349(9065):1582�1587 (1997). 65. Peters A, Stieberv J, Doering A, Wichmann HE. Is systolic blood pressure associated with air pollution? [Abstract]. Epidemiology 10(4):S177 (1999). <br><br> Environmental Health Perspectives <br><br> � VOLUME 108 | NUMBER 9 | September 2000 <br><br> 845 <br><br>  <h3>pmcA2636797</h3>Efficacy of intra-articular hyaluronan (Synvisc®) for the treatment of osteoarthritis affecting the first metatarsophalangeal joint of the foot (hallux limitus): study protocol for a randomised placebo controlled trial
Abstract
Background
Osteoarthritis of the first metatarsophalangeal joint (MPJ) of the foot, termed hallux limitus, is common and painful. Numerous non-surgical interventions have been proposed for this disorder, however there is limited evidence for their efficacy. Intra-articular injections of hyaluronan have shown beneficial effects in case-series and clinical trials for the treatment of osteoarthritis of the first metatarsophalangeal joint. However, no study has evaluated the efficacy of this form of treatment using a randomised placebo controlled trial. This article describes the design of a randomised placebo controlled trial to evaluate the efficacy of intra-articular hyaluronan (Synvisc®) to reduce pain and improve function in <span class="yellow">people</span> with hallux limitus.<br><br>Methods
One hundred and fifty community-dwelling <span class="yellow">men</span> and <span class="yellow">women</span> aged 18 years and over with hallux limitus (who satisfy inclusion and exclusion criteria) will be recruited.
<span class="yellow">Participants</span> will be randomised, using a computer-generated random number sequence, to receive a single intra-articular injection of up to 1 ml hyaluronan (Synvisc®) or sterile saline (placebo) into the first MPJ. The injections will be performed by an interventional radiologist using fluoroscopy to ensure accurate deposition of the hyaluronan in the joint. <span class="yellow">Participants</span> will be given the option of a second and final intra-articular injection (of Synvisc® or sterile saline according to the treatment group they are in) either 1 or 3 months post-treatment if there is no improvement in pain and the <span class="yellow">participant</span> has not experienced severe adverse effects after the first injection. The primary outcome measures will be the pain and function subscales of the Foot Health Status Questionnaire. The secondary outcome measures will be pain at the first MPJ (during walking and at rest), stiffness at the first MPJ, passive non-weightbearing dorsiflexion of the first MPJ, plantar flexion strength of the toe-flexors of the hallux, global satisfaction with the treatment, health-related quality of life (assessed using the Short-Form-36 version two questionnaire), magnitude of symptom change, use of pain-relieving medication and changes in dynamic plantar pressure distribution (maximum force and peak pressure) during walking. Data will be collected at baseline, then 1, 3 and 6 months post-treatment. Data will be analysed using the intention to treat principle.<br><br>Discussion
This study is the first randomised placebo controlled trial to evaluate the efficacy of intra-articular hyaluronan (Synvisc®) for the treatment of osteoarthritis of the first MPJ (hallux limitus). The study has been pragmatically designed to ensure that the study findings can be implemented into clinical practice if this form of treatment is found to be an effective treatment strategy.<br><br>Trial registration
Australian New Zealand Clinical Trials Registry: ACTRN12607000654459<br><br><br><br>Background
Osteoarthritis (OA) is a degenerative joint disease that commonly presents within the first metatarsophalangeal joint (MPJ) of the foot. The terms hallux limitus and hallux rigidus have frequently been used interchangeably to describe differing severities of pain and limitation of motion associated with OA at the first MPJ [1]. Hallux limitus is a progressive osteoarthritic condition of the first MPJ that may advance to an end-stage presentation of hallux rigidus where the joint fuses and there is a complete restriction of motion [1]. First MPJ OA is the second most common disorder affecting the foot after hallux valgus [2]. The prevalence of the condition increases with age, and it has been reported that radiographic changes in the first MPJ affect are evident in approximately 46% of <span class="yellow">women</span> and 32% of <span class="yellow">men</span> at 60 years of age [3]. Osteoarthritis at the first MPJ is characterised by the symptoms of pain and stiffness at the joint [1]. Secondary painful symptoms relate to compensations during gait that may occur due to the reduced motion of the first MPJ [1]. The presence of pain associated with first MPJ OA impacts on normal walking and quality of life [4].
Treatment of hallux limitus involves conservative measures (such as physical therapy, foot orthoses, footwear modification, joint manipulation and injection with corticosteroid) [5], or surgical intervention (either joint-salvage or joint-destructive procedures) [6]. Pharmacological treatment is also often undertaken as an adjunct for pain relief in the management of hallux limitus [6]. However, although non-steroidal anti-inflammatory drugs (NSAIDs) and cyclooxygenase-2 inhibitors have been found to be effective in the management of various forms of OA, gastrointestinal complications remain a concern [7]. In light of these limitations with existing treatments, an alternative treatment termed 'viscosupplementation' – the intra-articular injection of hyaluronan into arthritic joints with the aim of restoring the viscoelasticity of the synovial fluid [8] – has been proposed and has attracted considerable attention in the medical literature as a treatment for OA [9]. In particular, both the American College of Rheumatology (ACR) and European League Against Rheumatism (EULAR) recommend hyaluronan in the management of OA of the knee [10,11]. Although the results of systematic reviews investigating the effectiveness of this type of treatment for knee OA are controversial, the most recent update of the Cochrane systematic review evaluating viscosupplementation for the treatment of knee OA concluded that viscosupplementation was both safe and effective for the treatment of OA and was superior or equivalent to any form of systemic intervention or intra-articular corticosteroids [9,12].
Despite there being a large number of studies investigating the effectiveness of hyaluronan for knee OA, few studies have investigated the effects of this form of treatment for OA at the first MPJ [13]. In a case-series retrospective study, 14 <span class="yellow">patients</span> with radiographically confirmed OA at the first MPJ that received up to 3 intra-articular injections of 1 ml hyaluronan (Ostenil® Mini) (sodium hyaluronate) reported a statistically significant reduction in pain (reported using a visual analogue scale) after 6 months [14]. The treatment was well tolerated, with 3/14 (21%) <span class="yellow">participants</span> reporting mild adverse reactions at the injection site. In another study, Pons et al[13] compared a single intra-articular injection of 1 ml Ostenil® Mini (sodium hyaluronate) with 1 ml Trigon depot® (triamcinolone acetonide, a corticosteroid) for the treatment of painful, grade 1 hallux limitus (Karasick and Wapner [15] scale) in 37 <span class="yellow">participants</span> (40 feet) [13]. Both treatment groups showed statistically significant reductions in pain at rest or on palpation for up to 12 weeks post-injection. However, hyaluronan treatment resulted in a statistically significant greater reduction in pain during walking and greater improvement in the American Orthopaedic Foot and Ankle Society (AOFAS) hallux MPJ score compared to treatment with triamcinolone acetonide. The treatment with hyaluronan was well tolerated, with 2/20 (10%) <span class="yellow">participants</span> reporting mild adverse reactions at the injection site.
Although both of these studies suggest that intra-articular hyaluronan is safe and effective for the treatment of hallux limitus, neither used a placebo control group [13,14]. This limitation is significant as a placebo effect can account for 79% of the efficacy of intra-articular hyaluronan treatment [16]. Further, both studies are limited in that neither of the studies used blinding of both the <span class="yellow">participants</span> and assessors in their protocols. It is therefore possible that the positive effects of hyaluronan may have been overestimated. Accordingly, the aims of this project are to conduct a double blind randomised controlled trial to determine the effectiveness of intra-articular hyaluronan (Synvisc®) on (i) foot pain and function; (ii) the range of motion of the first MPJ; (iii) the strength of the plantarflexor muscles of the first MPJ; (iv) the health related quality of life; and (v) the use of pain-relieving medications in <span class="yellow">people</span> with hallux limitus. The study protocol is presented in this paper, consistent with the recommendations of Editorial Board of BioMed Central [17].<br><br>Methods
Design
This study is a parallel group, <span class="yellow">participant</span> and assessor blinded, randomised controlled trial with a 6 month follow-up (Figure 1). It has been developed using the principles described by Osteoarthritis Research Society International (OARSI) Clinical Trials Task Force guidelines [18]. <span class="yellow">Participants</span> will be randomised to receive a single intra-articular injection of up to 1 ml hyaluronan (Synvisc®) or sterile saline (placebo) into the first MPJ. Allocation to either the Synvisc® or placebo groups will be achieved using a computer-generated random number sequence. The allocation sequence will be generated and held by an external <span class="blue">person</span> not directly involved in the trial. Concealment of the allocation sequence will be ensured as each <span class="yellow">participant</span>'s allocation will be contained in a sealed opaque envelope. Envelopes will be made opaque by using a sheet of aluminium foil inside the envelope. In addition, a system using carbon paper will be employed so the details (name and date of recruitment) are transferred from the outside of the envelope to the paper inside the envelope containing the allocation prior to opening the seal. Assessors and <span class="yellow">participants</span> will be blinded to group allocation. <span class="yellow">Participants</span> will be given the option of a second and final intra-articular injection (of Synvisc® or sterile saline according to the treatment group they are in) on days 30 or 90 if there is no improvement in pain and the <span class="yellow">participant</span> has not experienced severe adverse effects after the first injection).<br><br><span class="yellow">Participants</span>
The <span class="yellow">Human</span> Studies Ethics Committee at La Trobe University (Human Ethics Committee Application No. 07-45) and the Radiation Advisory Committee of the Victorian Department of <span class="yellow">Human</span> Services have given approval for the study. Written informed consent will be obtained from all <span class="yellow">participants</span> prior to their participation. <span class="yellow">People</span> with hallux limitus will be recruited from a number of sources:
(i) advertisements in relevant Melbourne (Australia) newspapers;
(ii) mail-out advertisements to health-care practitioners in Melbourne;
(iii) advertisements using relevant internet web-sites (including );
(iv) posters displayed in local retirement villages, community centres and universities located in Melbourne.
Respondents will initially be screened by telephone interview to ensure they are suitable for the study. Suitable individuals will then be invited to participate in the study and attend an initial assessment.
To be included in the study, <span class="yellow">participants</span> must meet the following inclusion criteria:
(i) be aged at least 18 years;
(ii) report having symptoms of pain, during walking or rest, in the first MPJ for at least 3 months;
(iii) report having pain rated at least 20 mm on a 100 mm visual analogue pain scale (VAPS);
(iv) have pain upon palpation of the dorsal aspect of the first MPJ;
(v) radiographic evidence of OA (score 1 or 2 for either osteophytes or joint space narrowing using a previously published radiographic classification) [19] at the first MPJ.
(vi) able to walk household distances (>50 meters) without the aid of a walker, crutches or cane;
(vii) be willing to attend the La Trobe University Medical Centre (Melbourne, Australia) for treatment with either Synvisc® or placebo (single intra-articular injection) and attend the Health Sciences Clinic at La Trobe University (Melbourne, Australia) for the initial assessment and the outcome measurements (at baseline and 1, 3 and 6 months post-treatment);
(viii) not receive other intra-articular injections into the first MPJ during the course of the study, apart from those dictated by the study;
(ix) be willing to discontinue taking all pain-relieving medications (analgesics and non-steroidal anti-inflammatory medications (NSAIDs), except paracetamol up to 4 g/day, taken by mouth or applied topically):
- for at least 14 days prior to the baseline assessment;
- during the study period (6 months after the final treatment with Synvisc®).
<span class="yellow">Participants</span> who do take paracetamol need to discontinue its use at least 24 hours prior to the baseline assessment and follow-up assessments at 1, 3 and 6 months after the treatment;
(x) be willing to not receive any physical therapy on the involved MPJ or trial of shoe modifications or foot orthoses during the study period.
Exclusion criteria for <span class="yellow">participants</span> in this study will be:
(i) Severe radiographic evidence of OA (score 3 for either osteophytes or joint space narrowing) at the first MPJ using a previously published radiographic classification [19];
(ii) previous surgery on the first MPJ;
(iii) intra-articular steroid, or any other intra-articular injection at the first MPJ in the previous 6 months;
(iv) treatment with systemic steroid (excluding inhalation or topical steroids), immunosuppressives or anticoagulants (except for acetylsalicylic acid at dosages of up to 325 mg/day);
(v) presence of joint infection(s) of the foot;
(vi) significant deformity of the first MPJ including hallux abducto valgus (grade of 3 or 4 scored using the Manchester Scale [20];
(vii) presence of peripheral vascular disease. Peripheral vascular disease will be considered to be present if any of the following are present [21];
▪ past history of, vascular surgery, Raynaud's phenomenon, vasculitis associated with connective tissue diseases, Buerger's disease, arterial emboli, deep vein thrombosis or lower limb ulcers;
▪ history of intermittent claudication or rest pain;
▪ presence of atrophy, ulcers or significant oedema;
▪ inability to palpate at least one pedal pulse;
▪ Ankle Brachial Pressure Index <0.9;
(viii) presence of one or more conditions that can confound pain and functional assessments of the first MPJ, such as metatarsalgia, plantar fasciitis, pre-dislocation syndrome, sprains of the foot, Achilles tendinopathy, degenerative joint disease of the foot (other than the first MPJ) or painful corns and callus;
(ix) planning to undergo any surgical procedure or receive any injections, apart from those dictated by the study, at the involved first MPJ during the study period;
(x) presence of systemic inflammatory condition or infection, such as inflammatory arthritis, diagnosed with rheumatoid arthritis, ankylosing spondylitis, psoriatic arthritis, reactive arthritis, septic arthritis, acute pseudogout, or any other connective tissue disease;
(xi) evidence of gout or other musculoskeletal disease other than OA within the feet. Gout will be screened for using clinical history and physical assessment (painful joint, abrupt onset, swelling), radiographic assessment (asymmetrical joint swelling, subcortical cysts without erosion and tophi) as well as serum uric acid levels (hyperuricaemia = serum uric acid > mean + 2 SD from normal population) [22];
(xii) active skin disease or infection in the area of the injection site;
(xiii) any medical condition that, in the opinion of the investigators, makes the <span class="yellow">participant</span> unsuitable for inclusion (e.g., severe progressive chronic disease, malignancy, bleeding disorder, clinically important pain in a part of the musculoskeletal system other than the first MPJ, or fibromyalgia);
(xiv) pregnant or lactating <span class="yellow">women</span>, or <span class="yellow">women</span> who are of <span class="yellow">child</span> bearing age or have not undergone menopause (Synvisc® has not been tested in pregnant <span class="yellow">women</span> or <span class="yellow">women</span> who are nursing);
(xv) cognitive impairment (defined as a score of < 7 on the Short Portable Mental Status Questionnaire) [23];
(xvi) known hypersensitivity (allergy) to hyaluronan preparations, or to avian proteins, feathers or egg products;
(xvii) involvement in any clinical research study in the previous 3 months that could be considered to affect the results of this study.<br><br>Intra-articular injections for the treatment groups
<span class="yellow">Participants</span> will be randomised to receive a single intra-articular injection of up to 1 ml of hyaluronan (Synvisc®; Genzyme Biosurgery, Genzyme Corporation, NJ, USA) or sterile saline (placebo) into the first MPJ. Each 2 ml ampoule of Synvisc® contains 16 mg of hylan G-F 20 (cross-linked hylan polymers; hylan A and B), 17 mg sodium chloride, 0.32 mg disodium hydrogen phosphate, 0.08 mg sodium dihydrogen phosphate monohydrate. The hyaluronan is extracted from <span class="yellow">chicken</span> combs and the purified material has an average molecular weight of 6,000 kDa.
The injections will be performed by the same experienced interventional radiologist (AEZ) using fluoroscopic imaging to ensure accurate deposition of the hyaluronan within the joint. As the Synvisc® is provided in ampoules that are labelled with the product name, it will not be possible to blind the injector, however this <span class="blue">person</span> is not involved in generation of the allocation order, recruitment, assessment or data analysis. The intra-articular injection will be performed using a 21 gauge (0.80 × 19 mm) Surflo® (Terumo® Corp., Tokyo, Japan) winged infusion set under aseptic procedures. Either a dorso-lateral or dorso-medial approach for injection will be used at the discretion of the injector (depending on which approach provides minimum interference from the osteophytes at the first MPJ joint margins). No anaesthetic will be used. If the <span class="yellow">participant</span> has bilateral painful first MPJs, only one side (the most painful side) will be treated and used for data collection. The injector will record the volume of the agent that is injected.
<span class="yellow">Participants</span> will be given the option of a second and final intra-articular injection (of Synvisc® or sterile saline according to the treatment group they are in) on days 30 or 90 if there is no improvement in pain (assessed using the VAPS for pain during walking or at rest) and the <span class="yellow">participant</span> has not experienced severe adverse effects after the first injection).<br><br>Assessments
Initial assessments
An initial assessment will be performed to determine the eligibility of <span class="yellow">participants</span> for this study. Demographic data will be collected including the age, gender, height and weight of <span class="yellow">participants</span>. Data will also be obtained concerning the presentation of symptoms (foot affected, duration of symptoms). If the <span class="yellow">participant</span> has bilateral painful first MPJs, the most painful side will be used for data collection and subsequent treatment. To establish eligibility for the study, <span class="yellow">participants</span> will undergo a clinical assessment, have one set of dorso-plantar and lateral weight-bearing x-rays taken of their feet to grade the severity of first MPJ OA as well as undergo a blood test to assess serum uric acid levels (to exclude gout).
Weightbearing dorso-plantar and lateral radiographic views will be obtained from both feet with the <span class="yellow">participant</span> standing in a relaxed bipedal stance position. All x-rays will be taken by the same medical imaging department using a Shimadzu UD150LRII 50 kw/30 kHz Generator and 0.6/1.2 P18DE-80S high speed x-ray tube from a ceiling suspended tube mount. AGFA MD40 CR digital phosphor plates in a 24 cm × 30 cm cassette will be used. For dorso-plantar projections, the x-ray tube will be angled 15° cephalad and centered at the base of the third metatarsal. For lateral projections, the tube will be angled 90° and centered at the base of the third metatarsal. The film focus distance will be set at 100 cm [19].<br><br>Baseline assessments and outcome measures
<span class="yellow">Participants</span> who are eligible for the study will be invited to attend a baseline assessment. During the baseline assessment, <span class="yellow">participants</span> will undergo primary and secondary outcome measurements prior to receiving their injection. The outcome measurements have been developed in accordance of the recommendations of the OARSI Clinical Trials Task Force guidelines [18].<br><br>Primary outcome measures
Outcome measurements (primary and secondary) will occur at four time-points at baseline, 1, 3 and 6 months post-treatment (after the intra-articular injection of Synvisc® or placebo). The assessor performing the measurements will be blinded as to which treatment group <span class="yellow">participants</span> have been allocated to. <span class="yellow">Participants</span> who receive a second treatment at day 30 or 90 will be followed for a further 30 days or 90 days respectively and undergo outcome measurements at 7 or 9 months respectively.
The primary outcome measures will be the Pain and Function subscales of the Foot Health Status Questionnaire (FHSQ) [24]. The FHSQ includes 13 questions that assess four domains of foot health, Foot pain, Foot function, Footwear and General foot health. The FHSQ has been subjected to an extensive validation (content, criterion and construct validity) process. It has a high test-retest reliability (intraclass correlation coefficients ranging from 0.74 to 0.92) and a high degree of internal consistency (Cronbach's α ranging from 0.85 to 0.88) [24]. Rigorous reviews have rated it as one of the highest quality foot health status measures currently available [25-27].<br><br>Secondary outcome measures
The secondary outcome measures will be:
(i) Severity of pain
Severity of pain at the first MPJ during walking, and during rest, over the past week will be assessed using a 100 mm visual analogue pain scale. The left side of the scale (0 mm) will be labelled "no pain" and the right side of the scale (100 mm) will be labelled "worst pain possible" for each question [25,28].<br><br>(ii) Severity and duration of stiffness at the first metatarsophalangeal joint
The severity of stiffness at the first MPJ during walking over the past week will be assessed using a 100 mm visual analogue scale. The left side of the scale (0 mm) will be labelled "not stiff at all" and the right side of the scale (100 mm) will be labelled "most stiff possible". The average duration of stiffness at the first MPJ over the past week will be assessed using a four category scale response. The responses are: "none", "1–15 minutes", "16–30 minutes" and "greater than 30 minutes" [29].<br><br>(iii) Passive, non-weightbearing dorsiflexion range of motion of the first metatarsophalangeal joint
First MPJ dorsiflexion range of motion will be measured using a goniometer as the maximum angle at which the hallux cannot be passively moved into further extension in a non-weightbearing position (Figure 2) [30]. The test will be performed two times and the average will be used for analysis. This measurement technique shows high intra-reliability (ICC = 0.95, standard error of mean = 1.3°) [30].<br><br>(iv) Plantar flexion strength of the toe-flexors of the hallux
Plantar flexion strength of the toe-flexors of the hallux will be measured using the Mat Scan® plantar pressure measurement device [31]. <span class="yellow">Participants</span> will be seated with the hip, knee, and ankle at 90 degrees and their foot placed over the Mat Scan® plantar pressure measurement device (Tekscan, Boston, MA, USA) (Figure 3a). This system consists of a 5-mm thick floor mat (432 × 368 mm) incorporating 2288 resistive sensors (1.4 sensors/cm2) sampling at a rate of 40 Hz. The mat will be calibrated for each <span class="yellow">participant</span> using his or her own bodyweight before each testing session. <span class="yellow">Participants</span> will be instructed to use their toe-flexor muscles to maximally push their hallux down on the MatScan® device and forces under the hallux will be recorded (Figure 3b). The test will be performed three times for the hallux and the maximal force will be used for analysis. The test-retest reliability of this measurement technique has previously been shown to be high, with intraclass correlation coefficients (ICCs) = 0.88 (95% CI 0.81 – 0.93) [31].<br><br>(vi) Plantar pressure measurement
Plantar pressures will be recorded during level barefoot walking using the MatScan® system (Tekscan®, Boston, MA, USA). The two-step gait initiation protocol will be used to obtain foot pressure data, as it requires fewer trials than the mid-gait protocol and has similar re-test reliability [32]. Three trials will be recorded, which has been found to be sufficient to ensure adequate reliability of pressure data [32,33]. Following data collection, the Research Foot® software (version 5.24) will be used to construct individual "masks" to determine maximum force (kg) and peak pressure (kg/cm2) under seven regions of the foot: hallux, lesser toes, 1st MPJ, 2nd MPJ, 3rd to 5th MPJs, midfoot and heel (Figure 4a). For each region, the median of the three trials will be used for analysis. Typical plantar pressure recordings from a <span class="yellow">participant</span> are shown in Figure 4b.<br><br>(vi) Global satisfaction with the treatment
Global satisfaction with the treatment will be assessed using a 5-point Likert scale, as well as a dichotomous (yes/no) scale. The five point-Likert scale will ask "How satisfied are you with the treatment you received for your big-toe joint pain?", and will have the following five responses: "Dissatisfied", "Only moderately satisfied", "Fairly satisfied", "Clearly satisfied" and "Very satisfied". The dichotomous scale of satisfaction will be answered as "Yes"' or "No" in response to the question: "Would you recommend the treatment that you received to someone else with big-toe joint pain".<br><br>(vii) Health related quality of life
The Short-Form-36 (version two) (SF-36) questionnaire will be used to assess health related quality of life. The SF-36 is a 36 question survey that measures eight health concepts most affected by disease and treatment. The eight health concepts can then be used to form two summary measures: Physical health and Mental health. The Short Form-36 (SF-36) has been extensively validated and is one of the most widely used instruments to measure health status. The SF-36 shows content, concurrent, criterion, construct, and predictive evidence of validity. The reliability of the eight concepts and two summary measures has been assessed using both internal consistency and test-retest methods. Reliability statistics have exceeded 0.80 [34-37].<br><br>(viii) Self-reported magnitude of symptom change
Self-reported magnitude of symptom change will be measured using a 15-point Likert scale. The scale will ask <span class="yellow">participants</span> "how much have your symptoms in your big-toe joint have changed from the beginning of the study to now?". The fifteen responses will range from "A very great deal better" to "A very great deal worse".<br><br>(ix) Use of rescue medications to relieve pain at the first metatarsophalangeal joint
The number of <span class="yellow">participants</span> who consumed rescue medication (e.g., paracetamol) and mean consumption of rescue medication to relieve pain at the first MPJ (mean grams of paracetamol/<span class="yellow">participant</span>/month] will be assessed using a medications diary that <span class="yellow">participants</span> will self-complete [38,39]. The diary will be returned to the assessor at monthly intervals for analysis.<br><br>(x) Frequency and severity of adverse events as safety variables
The frequency (number of <span class="yellow">participants</span> affected and number of cases) and types of adverse events (including adverse drug reactions) in each treatment group during the trial will be recorded using a questionnaire that <span class="yellow">participants</span> will complete during the follow-up appointments at 1, 3 and 6 months post-treatment [40]. To classify the 'type' of adverse event, a blinded assessor will classify the adverse event as being serious or non-serious [40]. Any serious adverse events, defined as adverse events leading to serious disability, hospital admission, or prolongation of hospitalisation, life-threatening events; or death) will be further classified using the International Classification of Diseases (ICD) codes [41]. Non-serious adverse events will include both local (pain, effusion and heat, with each classified as mild, moderate, severe) and systemic adverse events. An open-response type format will also be available for <span class="yellow">participant</span> responses.<br><br><br><br>Sample size
The sample size for the study has been pre-specified using an a priori power analysis using the primary outcome measure of the pain domain of the FHSQ [42]. One hundred and forty two <span class="yellow">participants</span> (i.e. 71 per group) will provide power of 90% to detect a minimally important difference in the pain domain of the FHSQ (i.e. 14 points on the FHSQ questionnaire) with the significance level set at p < 0.05. A difference of 14 points was determined to be a clinically significant difference worth detecting [43] and a standard deviation of 25 was derived from a previous report [44]. This calculation included a 5% drop-out rate [13]. However, we will aim to recruit 150 <span class="yellow">participants</span> (~75 <span class="yellow">participants</span> per intervention group). Further, we have conservatively ignored the extra precision provided by covariate analysis when estimating the sample size.<br><br>Statistical analysis
Statistical analysis will be undertaken using SPSS version 14.0 (SPSS Corp, Chicago, Ill, USA) and STATA 8 (Stata Corp, College Station, Tex., USA) statistical software. All analyses will be conducted on an intention-to-treat principle using all randomised <span class="yellow">participants</span> [45-47]. Missing data will be replaced with the last score carried forward [48]. Standard tests for normal distribution will be used and transformation carried out if required.
Demographic characteristics (gender, age, weight, height, body mass index) will be determined for the baseline visit for each treatment group. Summary statistics will be calculated for duration of symptoms, side affected (left, right, bilateral), grade of OA at the first MPJ [19] as well as all primary and secondary outcome measurements for each treatment group.
Analyses will be conducted on 1, 3 and 6 month outcome measures. The continuously-scored outcome measures at 1, 3 and 6 months will be compared using analysis of covariance with baseline scores and intervention group entered as independent variables [49,50]. The exception to this will be the plantar pressure measurements which will be analysed at baseline, 1, 3 and 6 months using two-way repeated measures analysis of variance statistics. Post-hoc comparisons will be performed using Bonferroni-adjusted t-tests. Nominal and ordinal scaled data will be compared at 1, 3 and 6 months using Mann-Whitney U-tests and chi-square analyses (or Fisher's exact test where appropriate) respectively. Effect sizes will be determined using Cohen's d (continuous scaled data) or odds ratios (nominal scaled data and ordinal scaled data) as appropriate.
The outcome measurements obtained at 7 or 9 months for <span class="yellow">participants</span> that receive a second and final intra-articular injection (of Synvisc® or sterile saline according to the treatment group they are in) on days 30 or 90 respectively, will also be analysed as described above. These analyses will be classified as secondary outcomes.<br><br>
Discussion
This study is a randomised placebo controlled trial designed to investigate the efficacy of intra-articular hyaluronan (Synvisc®) to reduce pain and improve function in <span class="yellow">people</span> with OA of the first MPJ (hallux limitus). Two studies have previously investigated the efficacy of intra-articular hyaluronan for the treatment of first MPJ OA [13,14]. However, neither of these studies used a placebo control group. To our knowledge, this is the first randomised controlled trial using intra-articular hyaluronan for OA of the first MPJ.
The use of a placebo control group is essential for studies evaluating the effects of intra-articular therapies as there is likely to be a large placebo response related to the injection procedure and this may inflate the results in uncontrolled evaluations [51]. Indeed, a recent meta-analysis of hyaluronan for knee OA concluded that a placebo effect accounted for 79% of the efficacy of intra-articular hyaluronan [16].
The study protocol and outcome measures have been developed in accordance of the recommendations of the OARSI Clinical Trials Task Force guidelines [18]. The outcome measures are pain and function subscales of the FHSQ, pain and stiffness at the first MPJ, range of motion (dorsiflexion) of the first MPJ, plantar flexion strength of muscles of the first MPJ, generic health related quality of life (SF-36), <span class="yellow">patient</span> satisfaction with treatment, consumption of rescue medication as well as frequency and nature of adverse effects. These outcomes will be measured at baseline then at 1, 3 and 6 months after treatment. Previous research suggests that the effects of intra-articular hyaluronan persist for up to 12 months following treatment [9,38]. Thus, the use of follow-up assessments at 6 month post-treatment will allow us to determine if the effects, if any, of intra-articular hyaluronan persist in the longer term.
<span class="yellow">Participants</span> will be given the option of a second and final intra-articular injection (of Synvisc® or sterile saline according to the treatment group they are in) on days 30 or 90 if there is no improvement in their symptoms. Although this has the potential to complicate the interpretation of the results of the study, this protocol was included as it is likely to be more reflective of clinical practice [14], and this is in keeping with the pragmatic nature of this trial.
In summary, this project is the first randomised controlled trial to be conducted to evaluate the efficacy of intra-articular hyaluronan for reducing pain and improving function in <span class="yellow">people</span> with hallux limitus. The study protocol, including interventions, have been pragmatically designed to ensure that the study findings are generaliseable to clinical practice. Recruitment for the study will commence in June 2008, and we expect final results to be available in mid-2010.<br><br>Competing interests
HBM and KBL are Editor-in-Chief and Deputy Editor-in-Chief, respectively, of Journal of Foot and Ankle Research. It is journal policy that editors are removed from the peer review and editorial decision making processes for papers they have co-authored.<br><br>Authors' contributions
SEM, HBM, KBL and CJH conceived the idea and obtained funding for the study. SEM, HBM, KBL, AEZ and JDL designed the trial protocol. SEM, HBM, KBL and GVZ drafted the manuscript. All authors have read and approved the final manuscript.<br><br>
<h3>pmcA328326</h3>Enzymatic multiplex DNA sequencing.
Abstract
The problem of reading DNA sequence films has been reformulated using an easily implemented, multiplex version of enzymatic DNA sequencing. By utilizing a uniquely tagged primer for each base-specific sequencing reaction, the four reactions can be pooled and electrophoresed in a single lane. This approach has been previously proposed for use with fluorescently labelled probes (1), and is analogous to the principle used in four-dye fluorescence sequencing except that the signals are resolved following electrophoresis (2). After transfer to a nylon membrane, images are obtained separately for each of the four reactions by hybridization using oligonucleotide probes. The images can then be superimposed to reconstitute a complete sequence pattern. In this way the correction of gel distortion effects and accurate band registration are considerably simplified, as each of the four base-specific ladders require very similar corrections. The methods therefore provide the basis for a second generation of more accurate and reliable film reading programs, as well as being useful for conventional multiplex sequencing. Unlike the original multiplex protocol (3), the approach described is suitable for small projects, as multiple cloning vectors are not used. Although more than one vector can be utilized, only a library of fragments cloned into any single phage, phagemid or plasmid vector is actually required, together with a set of tagged oligonucleotide primers.Images<br><br><br><br><br><br>
 Nucleic Acids Research, Vol. 19, No. 12 3301 <br><br> Enzymatic multiplex DNA sequencing <br><br> Mark Chee <br><br> Medical Research Council Laboratory of Molecular Biology, Hills Road, Cambridge CB2 20H, UK <br><br> Received March 15, 1991; Revised and Accepted May 2, 1991 <br><br> ABSTRACT <br><br> The problem of reading DNA sequence films has been reformulated using an easily implemented, multiplex version of enzymatic DNA sequencing. By utilizing a uniquely tagged primer for each base-specific sequencing reaction, the four reactions can be pooled and electrophoresed in a single lane. This approach has been previously proposed for use with fluorescently labelled probes (1), and is analogous to the principle used in four-dye fluorescence sequencing except that the signals are resolved following electrophoresis (2). After transfer to a nylon membrane, images are obtained separately for each of the four reactions by hybridization using oligonucleotide probes. The images can then be superimposed to reconstitute a complete sequence pattern. In this way the correction of gel distortion effects and accurate band registration are considerably simplified, as each of the four basespecific ladders require very similar corrections. The methods therefore provide the basis for a second generation of more accurate and reliable film reading programs, as well as being useful for conventional multiplex sequencing. Unlike the original multiplex protocol (3), the approach described is suitable for small projects, as multiple cloning vectors are not used. Although more than one vector can be utilized, only a library of fragments cloned into any single phage. phagemid or plasmid vector is actually required, together with a set of tagged oligonucleotide primers. <br><br> INTRODUCTION <br><br> The community of biologists is undertaking the sequencing of representative genomes of various free-living organisms, ranging in size from Mycoplasma (800kb) to mammals (3 Gb) (4). However, the largest contiguous DNA sequences which have been determined so far are the genomes of several dsDNA eukaryotic viruses (5, 6, 7, 8, 9) and plant chloroplasts (10, 11, 12). The largest of these is the 229kb genome of <span class="yellow">human cytomegalovirus</span> (8). The difficulty in sequencing millions of base pairs of DNA is that several steps in the methods are relatively labour intensive, although the sequencing reactions themselves are rapid and easily performed. Two limiting steps in conventional procedures are the size fractionation of sequencing reaction products by gel electrophoresis and the subsequent reading of sequence ladders. The former problem can be overcome by multiplexing, which theoretically allows an enormous amount of <br><br> data to be obtained from a single gel by processing clones as mixtures rather than individually (3). Each sequence in the mixture is labelled by a unique short oligonucleotide 'tag' sequence. This allows the mixture to be resolved following electrophoresis: the superimposed sequence ladders are blotted from the gel to a nylon membrane, and detected one at a time by hybridization using tag-specific oligonucleotide probes. In practice, at least 50 sets of sequences can be obtained from a single gel (3). <br><br> Unfortunately, a bottleneck in the multiplex procedure is the reading of sequence films. In previous large-scale sequencing projects this task has been performed with the aid of a sonic digitizer (13, 14). Although film reading programs have been under development for some time (15), and some programs are commercially available, their error rates are presently more variable and unpredictable than that of a skilled <span class="red">person</span> and the accurate interpretation of film-imaged sequence ladders by computer programs is difficult to achieve in routine practice. Programs specifically designed to read multiplex films have an advantage. This is because a sequence image can be used as an 'internal standard' to help interpret other images derived from the same membrane (3). However, the original implementation of the multiplex strategy used chemical sequencing (16), which yields a more complex sequence ladder than the enzymatic dideoxynucleotide chain-termination method (17). Most successful large scale sequencing projects have used the chaintermination method and <span class="yellow">bacteriophage M13</span> vectors, which allows the routine production of clean and easily interpretable sequences (18). It was therefore decided to adapt the original multiplex protocol for use with enzymatic sequencing, using tagged primers. <br><br> MATERIALS AND METHODS <br><br> Eight oligonucleotide sequencing primers were synthesized, each 37 nucleotides in length. The 3' end of each primer consists of the 17 nucleotide M13 universal priming sequence [GTAAAACGACGGCCAGT3']. The 5' ends of the primers bear different 20mer tag sequences (Figure 1). In four of the primers, UEO1C, UPOIC, UE02C and UP02C, these tags are complementary to the EO1, PO1, E02 and P02 probe sequences respectively (copied from the original 'plex' vectors (3)). A second set of four primers, UJOL14C, UJOL15C, UJOL16C and UJOL17C, have the following tag sequences: 5' CAAGTTTGAAGGTACTCATT, TATCAATTAAATTGTllTGAC, GTGTTGCTACCCAAGAAGCA, and TGTCACTAGAGCTGTCACTT, respectively. The <br><br> ?=) 1991 Oxford University Press <br><br> 3302 Nucleic Acids Research, Vol. 19, No. 12 <br><br> oligonucleotides were gel-purified (19) and used to sequence ssDNA templates prepared by phenol extraction (20) or SDS denaturation (21). Conventional sequencing reactions were performed as previously described (20). <br><br> For hybridization experiments, radioactively labelled nucleotides were omitted from the sequencing reactions. Instead, the 21d of each nucleotide mix added to the reaction mixture consisted of the following: 'A' mix: 6.25MtM dATP, 62.5lM ddATP; 'C' mix: 6.25MM dCTP, 40MtM ddCTP; 'G' mix: 6.25MtM dGTP, 80MtM ddGTP; 'T' mix: 6.25MM dTTP, 250yM ddTTP; as well as 125MM of each of the three other dNTPs in each mix. Apart from the use of these modified mixes, no changes were made to the conventional sequencing procedure (20). <br><br> Sequencing reactions were pooled and ethanol precipitated as appropriate. Precipitation in microtitre trays was carried out as follows: a mixture of 3.2M1 3M NaAc pH 5.0 and 112Mi1 EtOH was dispensed to individual wells of a microtitre plate (Falcon 3911 or Corning 25855) using an 8-channel pipettor. Each set of four reactions was added to the EtOH/NaAc mixture, and the tray sealed using a Falcon 3073 plate sealer. The samples were mixed by inversion and stored at -20?C for 30 minutes. The DNA was collected by a 20 minute centrifugation at 4 000 rpm in an IEC Centra 3C centrifuge. The sealer was removed, and the plate inverted to discard the supernatant. After blotting the tray on tissue paper, 200MI of 95 % EtOH was added to each well. The plate was covered with a plastic lid and recentrifuged for 2 minutes. The EtOH was discarded and the plate inverted for several minutes on tissue paper, then left for 20 minutes to air dry. Precipitated samples were resuspended in 6M1 deionized water by vortexing on an SMI multi-tube vortexer for 1 minute. Samples were denatured and electrophoresed on 6 % polyacrylamide buffer gradient gels as previously described (20). <br><br> Following electrophoresis, the gel was transferred to a dry piece of Whatman 3MM blotting paper, and placed on a second sheet of blotting paper supported on a glass plate and saturated in 4 x SSC (SSC: 150mM NaCl, l5mM trisodium citrate). This sheet was wicked in a tray containing 1 litre of 4 x SSC. The DNA was transferred to a nylon membrane (Amersham Hybond N) by capillary blotting overnight (22). DNA was fixed to the membranes by U.V. crosslinking (23). <br><br> Plex oligonucleotide probes were a kind gift of Dr.George Church. Probes were tailed at their 3' ends using [a-32p] dCTP as previously described (3). For the preparation of digoxigenin (DIG) labelled probes, identical tailing reactions were carried out substituting  I0pmols of DIG-II dUTP (Boehringer Mannheim) for [a-32P] dCTP. Membranes were prehybridized for at least 10 minutes in 4 x SSC, 5 x Denhardts' (0.1 % (w/v) each of BSA (heated at 80?C for 30 minutes to inactivate any alkaline phosphatase activity), Ficoll (Pharmacia) and polyvinylpyrrolidone), 0.5% (w/v) SDS, 5mM NaHPO4 (23). Hybridization was carried out in 25-50M1 of prehybridization buffer per cm2 of membrane. The probe concentration was approximately lnM. After lh at 42?C, unbound probe was removed by five 1 minute washes at room temperature in 1 x SSC, 0.5% SDS (200MI/cm2 membrane). Radioactive blots were covered in Saran wrap and exposed to film immediately. Detection of DIG labelled probes used an anti-DIG antibodyalkaline phosphatase conjugate (Boehringer Mannheim) according to the manufacturer's instructions, except that all volumes were reduced by 70% and the conjugate was used at a 1:10 000 dilution. Blots were developed in 25M1 of 100mM Tris.Cl pH9.5, <br><br> mantane4-methoxy4(3 "-phosphoryloxy)phenyl-1 ,2-dioxetane); Tropix)/cm2 for 30 minutes at 37?C, prior to exposure to film. Probes and dioxetane were stripped from the membranes by two 10 minute washes at 700C with 0.2% SDS, 2mM EDTA (200,ul/cm2 membrane). <br><br> The hybridization and washing procedures were carried out in plastic bags. However, washing steps have also been performed with gentle agitation in a perspex tub (43 x 27 x 15cm) mounted on a reciprocal shaker, with equivalent results. In the latter case a minimum wash volume of 500mls was used. The use of a tub is more convenient for batch processing and should be straightforward to automate. <br><br> RESULTS <br><br> Autoradiograms revealed no difference in sequence quality when tagged primers were used instead of the 17mer universal primer in conventional [a-35S] dATP labelled sequencing reactions and in multiplex hybridization experiments using [a-32P] dCTP-tailed probes (results not shown). Experiments were then conducted to determine the feasibility of pooling the four base reactions for each clone and fractionating them in a single lane to obtain a superimposed but interpretable set of sequence ladders. The question addressed was whether or not difficulties in band registration might arise as a result of mobility differences between the different primer sequences and/or distortion of the membrane between probings. It is relevant that an automated film reader employing an internal standard requires that the nylon membrane does not undergo significant distortions between probings (George Church, personal communication). Clones were sequenced using the four tagged primers UEOlC, UPOIC, UE02C, and UP02C, one for each base reaction (Figure 1). The A, C, G and T reactions for each clone were pooled, and processed as described above. A complete set of sequence autoradiograms was obtained from four consecutive rounds of probing with [a-32P] dCTP-labelled oligonucleotides. Alignment of the films showed that sequence-specific mobility effects and distortion of the membrane between probings were sufficiently minor to allow accurate registration of the bands, and hence accurate reading of the sequence. At least 200 nucleotides of sequence could be read accurately from a single clone by simply tracing the four sets of bands using different colours, overlaying the tracings, and reading the bands sequentially. In order to assess the practicality of reading the sequences by machine, the images were scanned to provide optical density profiles (Figure 2). These profiles were overlaid, and were found to be sufficiently in register to allow accurate interpretation of the sequence for at least 300 nucleotides. This was essentially the limit of resolution of the gel for accurate manual reading. <br><br> In order to ensure that the relatively minor mobility differences observed between the four primers were not coincidental to the oligonucleotides used, a second set of four tagged M13 universal primers was synthesised, this time incorporating 20mer sequences derived from the genome of <span class="yellow">murine</span> herpesvirus-68 (UJOL14C, 15C, 16C, 17C). Sequencing reactions were performed using [cx-35S] dATP to label the DNA directly. Various templates were sequenced, and in all cases correctly ordered sequence ladders were obtained following conventional electrophoresis in which the four reactions were run side-by-side (results not shown). <br><br> Initial hybridization experiments were conducted using [f -32p] <br><br> dCTP tailed oligonucleotide probes. However, the use of <br><br> lOOmM NaCl, 5OmM MgC12, 0.15mM AMPPD ([3-(2'-ada<br><br> B <br><br> C <br><br> 'Ordinary'                       Plex'      4-CJ3              4-rn     + <br><br> Primeir                        Primer <br><br> "All      "C"       "G"   "   T" <br><br> 'Plex'                       'Ordinary'                                        Pool and <br><br> Vector                          Vector                                          fractionate <br><br> Resolve by sequential <br><br> hybridizations <br><br> Sequencing reactions <br><br> SequencingreactIo product <br><br> Sequencing reaction product <br><br> -           n;   <br><br> =      = <br><br> -   =   <br><br> -   n:  = <br><br> Figure 1. Approaches to enzymatic multiplex DNA sequencing. a) A set of sequence-tagged vectors can be used. The tag site is shown in red, and the insert to be sequenced in blue. However, the original plex vectors (3) are plasmids, and therefore amenable only to dsDNA sequencing. Sets of <span class="yellow">bacteriophage M13</span> vectors have been constructed bearing either one (32) or two [Chee, unpublished] of the plex tag sites flanking the polylinker, which can be used for this approach. b) The strategy used in this paper. In this case the tag site is carried on the primer. c) If tagged primers are used, there is no practical impediment to performing each base reaction using a different primer, as depicted. The reactions can then be pooled in any combination desired. The configuration shown, in which the four reactions are electrophoresed in a single lane, is designed to facilitate accurate band registration and reading by an automatic film reader. In order to read the sequence manually, base reactions would be run side-by-side. The logistics of processing the reactions are essentially the same with either configuration; the same number of probings are required. <br><br> Figure 2. Four overlaid one-dimensional optical density profiles for a single clone shown in two overlapping sections. The optical density profiles are unprocessed, except for a simple transform to correct for the relative displacement (translation and rotation) of the four images from which they are extracted. The profiles read 5' to 3' from right to left. Nucleotides positions 66 to 214 from the start of the universal priming site are shown. The sequence is that of Bluescribe M13+ (template DNA obtained by rescue with M13K07 helper phage (30)), and was determined using the primers UEOIC, UPOIC, UE02C, and UP02C for the T, C, G and A <br><br> specific reactions respectively. Detection was by autoradiography following hybridization with [a- 32p] dCTP tailed plex probes. <br><br> A <br><br> Nucleic Acids Research, Vol. 19, No. 12 3303 <br><br> I <br><br> 3304 Nucleic Acids Research, Vol. 19, No. 12 <br><br> a) <br><br> 175-... <br><br> -w<br><br> .m; <br><br> b) <br><br> 182<br><br> a :...... <br><br> F.VW <br><br> an <br><br> - w <br><br> -1 <br><br> S              -  K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~i <br><br> 'F C C; A                                I1 'CG A <br><br> Figure 3. Four separate base-specific reactions imaged from a single lane using chemiluminescent detection. The clones sequenced are: a) Bluescribe M13 + (obtained by rescue with M13K07 helper phage (30)) and b) an M13 recombinant clone prepared in a microtitre tray (21) (a kind gift of Victoria Smith). Nucleotide positions shown on the figure are numbered from the start of the universal priming site. The clones were sequenced using UEOlC, UPOIC, UE02C, and UP02C for the T, C, G and A specific reactions respectively. The blot was probed with corresponding DIG-11-dUTP labelled oligonucleotides. <br><br> radioactivity on the scale envisioned for a large sequencing project is undesirable for reasons of safety. The relatively long exposure times required (6 to 24 hours) and the short half lives of the probes might also be inconvenient. It has been shown that a biotin/streptavidin/alkaline phosphatase based detection system used in conjunction with a chemiluminescent dioxetane substrate overcomes these disadvantages (24, 25, 26). We utilized a different bridging system with similar results. Digoxigenin (DIG) labelled oligonucleotide probes were detected using anti-DIG antibody-alkaline phosphatase conjugates and a chemiluminescent dioxetane substrate. Exposure times of 10 to 15 minutes were typically required, following a one hour preincubation period (Figure 3). In our hands the DIG bridging system was similar in sensitivity to the streptavidin based system (24), and the practical lower limit of template ssDNA required in order to obtain an easily interpretable sequencing ladder was estimated to be in the range of 20 to 50fmols per reaction. However, the sensitivity of detection was limited only by enzymaticallytriggered background luminescence, and not by the level of signal obtained. The nonradioactive methods described have been used successfully in an 8-plex system. <br><br> DISCUSSION <br><br> Although the original multiplex protocol was based on a set of tagged vectors (3), tagged primers have also been used or proposed for various forms of multiplex DNA sequencing (George Church, personal communication; 2, 27). For example, a proposal was recently put forward for multiplex sequencing using sequence-labelled primers and fluorophor-labelled probes <br><br> (1), similar in principle to the methods used here. However, we use tagged primers and the superposition of the four sequencing reactions to address the problem of reading DNA sequence films; a part of this solution is to utilize M13 dideoxynucleotide sequencing, thereby improving the quality of the data to be analyzed. In addition, the proposal for fluorophor-labelled probes does not take into consideration any of the practical sequencing problems addressed here, and, in the version described, remains a promising but unproven scheme for large scale DNA sequencing. <br><br> There are several advantages to tagging primers instead of vectors. Firstly, there is no need to prepare multiple libraries of clones in special vectors. This means that workers can use vector/host combinations that yield good results in their hands, and an increased depth of multiplexing can easily be accomodated by synthesizing more primers. This should make multiplexing more accessible to workers undertaking smaller projects. A theoretical disadvantage of tagged primers is that the procedure can only be multiplexed following primer annealing (1), or following the sequencing reactions (this paper; in practice, pooling immediately after the annealing step might lead to increased backgrounds if one or more primers were present in excess over their template DNAs). This is a relatively late stage. In the original procedure (3), clones were pooled prior to amplification by growth, an early step. However, we do not believe the sacrifice to be of practical importance when using phage vectors. In our experience, recombinant M13 phage have variable growth rates and the effects of competition are likely to severely limit the number of clones that can usefully be pooled for growth. In contrast, by growing clones individually, the depth of multiplexing is only really limited by probe sensitivity. We have not investigated the factors influencing variability in phage growth rates. <br><br> It is worth noting that reliable protocols have been developed for growing large numbers of individual M13 clones and preparing high quality ssDNA templates in microtitre trays (28, 21). It is relatively simple to prepare manually two microtitre trays of ssDNA templates (192 clones) in a day. Sufficient clones can be prepared in a week to sequence a 20kb fragment to a redundancy of 10 (Victoria Smith, personal communication). In this laboratory, ssDNA is now prepared with the aid of a commercially available robotic workstation (21). As sequencing reactions are also carried out in microtitre trays, manually or robotically (20, 29), the entire M13-based dideoxynucleotide sequencing procedure is amenable to automation (29). For these reasons we see little practical advantage in pooling clones early. Finally, by not pooling clones early, the ability to easily retrieve individual clones is retained, which may facilitate directed sequencing later in a project should this become necessary. <br><br> Multiplex DNA sequencing is currently limited by the lack of a robust computer program which can correct for the large variety of gel and sequencing artefacts that are normally encountered. The foundation of a film reading program is the ability to bring into register precisely vertical arrays of base-specific bands. This requires the ability to track lanes, correct for distortions, and order bands based on their relative spacing. A method of sequencing which has successfully overcome the problem of sequence reading uses real-time detection of fluorescently labelled DNA samples migrating through the gel (2). This system also utilizes the principle of running the four base reactions down the same lane (2). However, bands are detected at a fixed location <br><br> in space, and their detection is separated in time. Hence the <br><br> Nucleic Acids Research, Vol. 19, No. 12 3305 <br><br> problem of gel distortion is essentially avoided, although corrections for the different mobilities of the four dyes must be carried out. In contrast, we utilize the advantages of single lane electrophoresis to address the problem of superimposing four relatively large and complex two-dimensional images. Furthermore, by using sequence-tagged oligonucleotides which are detected by hybridization, a much greater depth of multiplexing can realistically be achieved than by real-time detection. <br><br> The use of two-dimensional colour traces to depict the processed output of a film reader is consistent with the method of displaying fluorescence traces, and should facilitate the checking and editing of sequence databases in which both kinds of data have been entered. The sequence compilation programs used in this laboratory, which are already capable of handling large shotgun databases (8, 31), have recently undergone extensive improvements (Rodger Staden, personal communication). There is now an interactive database editor which allows the graphical display of fluorescence traces, and it is envisaged that this feature could be extended to allow the handling of data from a film reader when a suitable machine is developed. <br><br> ACKNOWLEDGEMENTS <br><br> I am particularly grateful to George Church for thought-provoking discussions and gifts of vectors and oligonucleotide probes and to John Sulston for advice. I also thank Victoria Smith for the gift of DNA samples, Bart Barrell for long-term support, Tom O'Keefe of Milligen/Biosearch for lessons in multiplexing and Amersham International for the optical density overlays shown in Figure 2. M.C. is supported by a fellowship from Applied Biosystems. <br><br> 12. Hiratsuka, J., Shimada, H., Whittier, R., Ishibashi, T., Sakamoto, M., Mori, <br><br> M., Kondo, C., Honju, Y., Sun, C. -R, Meng, B. -Y, Li, Y. -Q, Kanno, A., Nisizawa, Y., Hirai, A., Shinozaki, K. and Sugiura, M. (1989) Molecular and General Genetics, 217, 185-194. <br><br> 13. Komaromy, M. and Govan, H. (1984) Nucleic Acids Research, 12, 675-678. 14. Staden, R. (1984) Nucleic Acids Research, 12, 499-503. <br><br> 15. Elder, J. K., Green, D. K. and Southern, E. M. (1986) Nucleic Acids <br><br> Research, 14, 417-424. <br><br> 16. Maxam, A. M. and Gilbert, W. (1977) Proceedings of the National Academy <br><br> of Sciences, U.S.A., 74, 560-564. <br><br> 17. Sanger, F., Nicklen, S. and Coulson, A. R. (1977) Proceedings of the National <br><br> Academy of Sciences, U.S.A., 74, 5463-5467. <br><br> 18. Sanger, F., Coulson, A. R., Barrell, B. G., Smith, A. J. H. and Roe, B. <br><br> A. (1980) Journal of Molecular Biology, 143, 161-178. 19. Applied Biosystems User Bulletin (1987) 13, 11-16. <br><br> 20. Bankier, A. T., Weston, K. M. and Barrell, B. G. (1987) Methods in <br><br> Enzymology, 155, 51-93. <br><br> 21. Smith, V., Brown, C. M., Bankier, A. T. and Barrell, B. G. (1990) DNA <br><br> Sequence, 1, 73-78. <br><br> 22. Southern, E. M. (1975) Journal of Molecular Biology, 98, 503-517. <br><br> 23. Church, G. M. and Gilbert, W. (1984) Proceedings of the National Academy <br><br> of Sciences, U.S.A., 81, 1991-1995. <br><br> 24. Beck, S., O'Keefe, T., Coull, J. M. and Koster, H. (1989) Nucleic Acids <br><br> Research, 17, 5115-5123. <br><br> 25. Tizard, R., Cate, R. L., Ramachandran, K. L., Wysk, M., Voyta, J. C., <br><br> Murphy, 0. J. and Bronstein, I. (1990) Proceedings of the National Academy of Sciences, U.S.A., 87, 4514-4518. <br><br> 26. Beck, S. and Koster, H. (1990) Analytical Chemistry, 62, 2558-2570. <br><br> 27. Jacobson, K. B., Arlinghaus, H. F., Schmitt, H. W., Sachleben, R. A., <br><br> Brown, G. M., Thonnard, N., Sloop, F. V., Foote, R. S., Larimer, F. W., Woychik, R. P., England, M. W., Burchett, K. L. and Jacobson, D. A. (1991) Genomics, 9, 51-59. <br><br> 28. Eperon, I. C. (1986) Analytical Biochemistry, 56, 406-412. <br><br> 29. Bankier, A. T. and Barrell, B. G. (1989) In Howe, C. J. and Ward, E. <br><br> S. (ed), Nucleic acids sequencing: a practical approach. IRL Press, Oxford, Vol. 1, pp. 37-78. <br><br> 30. Vieira, J. and Messing, J. (1987) Methods in Enzymology, 153, 3-11. 31. Davison, A. DNA Sequence, in press. <br><br> 32. Heller, C., Radley, E., Khurshid, F. A. and Beck, S. Gene, in press. <br><br> REFERENCES <br><br> 1. Yang, M. M. and Youvan, D. C. (1989) Biotechnology, 7, 576-580. <br><br> 2. Smith, L. M., Sanders, J. Z., Kaiser, R. J., Hughes, P., Dodd, C., Connell, <br><br> C. R., Heiner, C., Kent, S. B. H. and Hood, L. E. (1986) Nature, 321, 674-679. <br><br> 3. Church, G. M. and Kieffer-Higgins, S. (1988) Science, 240, 185-188. 4. Watson, J. D. (1990) Science, 248, 44-49. <br><br> 5. Baer, R., Bankier, A. T., Biggin, M. D., Deininger, P. L., Farrell, P. J., <br><br> Gibson, T. J., Hatfull, G., Hudson, G. S., Satchwell, S. C., Seguin, C., Tuffnell, P. S. and Barrell, B. G. (1984) Nature, 310, 207-211. <br><br> 6. Davison, A. J. and Scott, J. E. (1986) Journal of General Virology, 67, <br><br> 1759-1816. <br><br> 7. McGeoch, D. J., Dalrymple, M. A., Davison, A. J., Dolan, A., Frame, <br><br> M. C., McNab, D., Perry, L. J., Scott, J. E. and Taylor, P. (1988) Journal of General Virology, 69, 1531-1574. <br><br> 8. Chee, M. S., Bankier, A. T., Beck, S., Bohni, R., Brown, C. M., Cerny, <br><br> R., Horsnell, T., Hutchison III, C. A., Kouzarides, T., Martignetti, J. A., Satchwell, S. C., Tomlinson, P., Weston, K. M. and Barrell, B. G. (1990) Current Topics in Microbiology and Immunology, 154, 125-169. <br><br> 9. Goebel, S. J., Johnson, G. P., Perkus, M. E., Davis, S. W., Winslow, J. <br><br> P. and Paoletti, E. (1990) Virology, 179, 247-266. <br><br> 10. Ohyama, K., Fukuzawa, H., Kohchi, T., Shirai, H., Sano, T., Sano, S., <br><br> Umesono, K., Shiki, Y., Takeuchi, M., Chang, Z., Aota, S. -I, Inokuchi, H. and Ozeki, H. (1986) Nature, 322, 572-574. <br><br> 11. Shinozaki, K., Ohme, M., Tanaka, M., Wakasugi, T., Hayashida, N., <br><br> Matsubayashi, T., Zaita, N., Chunwongse, J., Obokata, J., YamaguchiShinozaki, K., Ohto, C., Torazawa, K., Meng, B. Y., Sugita, M., Deno, H., Kamogashira, T., Yamada, K., Kusuda, J., Takaiwa, F., Kato, A., Tohdoh, N., Shimada, H. and Sugiura, M. (1986) EMBO Journal, 5, 2043-2049. <h3>pmcA509286</h3>How can Health Behavior Theory be made more useful for intervention research?
Abstract
Background
The present paper expresses the author's views about the practical utility of Health Behavior Theory for health behavior intervention research. The views are skeptical and perhaps even a bit exaggerated. They are, however, also based on 20-plus years of in-the-trenches research focused on improving health behavior practice through research.<br><br>Discussion
The author's research has been theoretically driven and has involved measurement of varying variables considered to be important theoretical mediators and moderators of health behavior. Regretfully, much of this work has found these variables wanting in basic scientific merit. Health Behavior Theory as we have known it over the last 25 years or so has been dominated by conceptualizations of behavior change processes that highlight cognitive decision-making. Although much of health behavior practice targets what <span class="yellow">people</span> do rather than what they think, the logic of focusing on thoughts is that what <span class="yellow">people</span> think about is the key to what they will do in the future, and that interventions that can measure and harness those processes will succeed to a greater extent than those that do not. Unfortunately, in the author's experience, the premise of cognitive theories has fallen short empirically in a number of ways. The cognitive schemata favored by most health behavior theories are difficult to measure, they do not predict behavioral outcomes very well, there is little evidence that they cause behavior, and they are hard to change directly.<br><br>Summary
It is suggested that health behavior researchers reconsider their use of these theories in favor of models whose variables are more accessible to observation and experimental manipulation and that most importantly have strong empirical support.<br><br><br><br>Background
The author has been conducting research on behavioral treatment of obesity for about 25 years. During that time, the dominant conceptual models guiding intervention development have been cognitive behavior models that have their origin in psychological theory. Those most often cited include the Health Belief Model [1], Protection Motivation Theory [2], Subjective Expected Utility Theory [3], the Theory of Reasoned Action [4], Social Cognitive Theory [5], and the Transtheoretical Model [6]. All of these theories are concerned with how <span class="yellow">people</span> make behavioral choices and the general idea is that <span class="yellow">people</span> decide what to do based on the extent to which they expect that their choices will produce results that they value. Much of the content of the theories is concerned with factors that may affect value/expectancy calculations. As summarized by Weinstein in a comparative review of four social psychological theories [7], variables thought to influence value/expectancy judgments include such factors as perceived rewards of current behavior, self-efficacy, normative beliefs, motivation, and the perceived consequences of not changing behavior.
Weinstein's summary is illustrative of the fact that Health Behavior Theory has tended to be particularly interested in understanding <span class="yellow">people</span>'s motivation to change behavior rather than ability to change. Moreover, motivation is thought to be the result of a relatively complex, but logical, interpretation of large quantities of information about self and environment. The theories that Weinstein reviewed deal almost exclusively with behavioral decision processes in <span class="yellow">people</span>'s minds. They have few if any terms relating to how information gets into <span class="yellow">peoples</span> minds or how subsets of it receive more or less attention. Broader health behavior theories such as Social Cognitive Theory or the Transtheoretical model have addressed issues and variables outside the <span class="blue">person</span> to a greater extent, but the fundamental interest in and belief in psychological variables as the key force in determining health behavior remains.
The implications of the focus of health behavior theory on psychological determinants of behavioral decision-making for my own research area of interest, obesity treatment, are several. One is the inclusion of measures of psychological characteristics in most research protocols (e.g., assessment of behavioral intentions, self-efficacy, perception of barriers to change, perception of social support, and outcome expectations). A second is the inclusion of treatment elements that specifically target psychological perceptions and processes independent of the diet and physical activity behaviors that actually produce weight change (e.g., how to deal with emotional eating, how to deal with the frustration of lapses and relapses, and how to talk to yourself to increase self-motivation). A third is the belief that psychological reactions to treatment experiences themselves are very important and deserve independent attention. Common behavioral prescriptions for weight-loss goals and frequency of self-weighing are exemplary (i.e., recommending infrequent weighing to prevent discouraging feedback about progress and encouraging smaller and thus "more attainable" behavior and weight-loss goals in the belief that they will be more motivating).
The problem with the emphasis on cognitive variables in weight-control research is that they have so far failed to meet fundamental scientific criteria for empirical verification. Thus, they also have not led to a better understanding of the weight-loss process, have not improved our ability to predict weight-loss outcomes, and have not led to improvement in treatment methods. In some cases it is even arguable that they have made treatment worse. I will illustrate these problems with results from my own research.<br><br>Discussion
Like most behavioral researchers in the obesity area, I have attempted to measure elements of health behavior theory in every obesity intervention project I have ever conducted. I have assessed weight-loss goals, behavioral and weight-loss self-efficacy, psychological well-being, perceived barriers to diet and physical activity change, stages-of-change, and perceived social support. How well have empirical examinations of these factors fared as predictors of success in weight control?
Self-efficacy
We have examined the predictive value of self-efficacy assessments in several of our studies and describe the results from three of these here in more detail [8-10]. In the first study, self-efficacy was assessed at baseline, posttreatment, and one year later in 85 <span class="yellow">men</span> participating in a 15-week weight-loss program [8]. The self-efficacy instrument had subscales for emotional states (e.g., anxiety) and situations (e.g., eating away from home). Higher baseline self-efficacy on both subscales was associated with greater weight loss in treatment and at 1- and 2-year follow-up. Emotional self-efficacy at posttreatment did not predict weight loss at 1- or 2-year follow-up. Situational self-efficacy at posttreatment predicted weight loss at 1-year but not 2-year follow-up.
The second study examined mood and situational self-efficacy in 55 <span class="yellow">men</span> and 58 <span class="yellow">women</span> before and after a 16-week weight-loss treatment with a 1-year follow-up [9]. <span class="yellow">Women</span> had lower pretreatment self-efficacy than <span class="yellow">men</span>. Self-efficacy was predictive of weight loss and maintenance in <span class="yellow">men</span> but not in <span class="yellow">women</span>. Change in self-efficacy over time was positively related to weight change in <span class="yellow">women</span> but not in <span class="yellow">men</span>.
The third study examined predictors of weight change over a 2-year period in 460 <span class="yellow">men</span> and 1172 <span class="yellow">women</span> who received a low-intensity weight-loss intervention delivered through their HMO [10]. The self-efficacy measure was the WEL questionnaire. <span class="yellow">Men</span> again were found to have higher baseline self-efficacy than <span class="yellow">women</span>. Self-efficacy did not predict weight change in <span class="yellow">men</span> but was positively, though weakly, related to weight change at 6 months only in <span class="yellow">women</span>.
Our overall conclusion from the analyses described above, as well as others not pursued in as great detail, is that self-efficacy is a weak predictor of weight loss and is inconsistent across study populations and gender. It tends to increase with weight loss. However, treatment-induced increases in efficacy are not predictive of longer-term weight-loss success.<br><br>Barriers to Adherence
We have also attempted to measure barriers to adherence to weight-control behaviors in many of our studies [11-14]. The instruments used for this have typically been formatted similarly to efficacy questionnaires in that <span class="yellow">people</span> are asked to indicate how difficult they find situational, knowledge, and motivational challenges to achieving diet and exercise changes. The findings in these studies have been quite consistent. Baseline assessments of perceived barriers to behavior change are not predictive of weight change. Weight loss is associated with reported decreases in perceived barriers. Treatment-induced change in perceived barriers are not predictive of future weight change. In other words, barrier perceptions as we have measured them do not appear to have pragmatic significance.<br><br>Weight Goals
Goal-setting has long been of interest to health behavior theory and in recent years has attracted attention in weight-loss research when it was realized that most <span class="yellow">people</span> who enter weight-loss treatments want to lose a lot more weight than is realistic given the potency of current weight-loss methodologies [15]. When asked to describe weight losses they deem to represent "dream, happy, acceptable, and disappointing," many individuals in treatment fail to reach even "disappointing" weight losses even though in objective medical terms the results are positive. Based on the argument that failure to reach gratifying weight-loss goals leads to psychological distress that lowers weight self-efficacy and undermines weight-loss efforts, it has become popular to recommend counseling in weight-loss treatments specifically targeting the lowering of weight-loss goals. The theoretical argument is that excessive outcome expectations undermine behavioral efforts. We have now completed three sets of formal analyses examining whether weight goals are predictive of weight-loss success. In one of these analyses the relationship between weight-loss goals, weight-loss goal attainment, and long-term (30 months) weight-loss attainment and psychological well-being were assessed in 69 <span class="yellow">men</span> and 61 <span class="yellow">women</span> participating in an intensive behavioral treatment program [16]. Results indicated that weight-loss goals were unrealistically high on average and that lower goals were more likely to be reached. Nevertheless, weight-loss goals did not predict either short- or long-term weight losses and were not associated with elevated psychological distress. Two more recent analyses we have conducted looking at weight-loss goals as predictors of success have produced similar results [Linde JA, Jeffery RW, Levy RL, Pronk NP and Boyle RG, unpublished data [17]]. Weight-loss goals either did not predict weight loss at all or were slightly positively related to weight-loss success.<br><br>Perceived Social Support
Perceived social support is another psychological factor thought to influence health behavior decision-making. We have measured social support in a variety of ways in our studies, ranging from single-item questions to multipaged assessments attempting to differentiate among informational, instrumental, and emotional support. The results, unfortunately, have closely paralleled those we have seen with other assessments of barriers to adherence. Assessments of social support prior to treatment do not predict weight loss. Average reports of social support tend to parallel weight loss itself. When <span class="yellow">people</span> lose weight they report more social support. When they regain, they report less. In other words, perceptions of social support are not predictive of success in weight-loss treatments.<br><br>Frequency Weight Self-monitoring
Self-monitoring of health behavior is incorporated into many health behavior theories, usually as part of a <span class="blue">person</span>'s assessment of achieved outcomes. Although self-monitoring is usually considered a positive element in the adoption of health behavior, in obesity treatment frequent self-monitoring of weight has tended to be down-played or even discouraged on the grounds that disappointing results (i.e., less than desired weight change) may undermine motivation. This is another example in which health behavior theory may have indirectly led to incorrect treatment recommendations. In weight-loss treatments, active discouragement of frequent self-observation of weight has become popular based on the premise that more frequent weighting will cause psychological stress and lower self-efficacy. Recently, we have examined the relationship between frequency of self-weighing and body weight in both clinical and population samples and have found, somewhat to our surprise, that frequency of self-weighing is one of the strongest single predictors of body weight cross-sectionally, and change in the frequency of self-weighing is one of the strongest predictors of weight change [Linde JA, Jeffery RW and French SA, unpublished data]. The direction of predictions, however, is opposite that derived from theory. <span class="yellow">People</span> who weigh themselves more weigh less and are more successful in losing weight.<br><br>Stage-of-Change
A final failure of current health behavior theory to prove useful in weight-control research is a recent examination of the relationship between a stage-of-change measure adopted from Prochaska and short- and long-term weight loss [18]. Categories of precontemplation, contemplation, preparation, and action were defined based on questions about weight-loss intentions and recent weight-loss attempts. Despite a large sample size, excellent follow-up rates, and well-measured objective outcomes, we were unable to demonstrate that staging algorithms recommended by proponents of the Transtheoretical Model could predict weight-loss outcomes.<br><br>Experimental Modification of Expectations
Our most recent effort to utilize health behavior theory in obesity intervention research is a study that attempted to examine the effectiveness of experimentally-induced outcome expectancies on weight loss [Finch EA, Linde JA, Jeffery RW, Rothman AJ and King CM, unpublished data]. Obese <span class="yellow">men</span> and <span class="yellow">women</span> participated in an 8-week weight-loss program with 18-month follow-up in which they were assigned to one of two expectancy groups. The optimistic group was told that focusing exclusively on the positive benefits of weight loss would be valuable in ensuring that they remained motivated in their weight-loss efforts and was given assignments during weekly group sessions and homework between sessions to reinforce this optimistic mindset. A "balanced" expectancy group received the instructions that focusing on both the positive and negative aspects of weight loss, a balanced approach, would be most conducive to maintaining weight-loss motivation. This group also received assignments to reinforce their message. Results of this study indicated that the expectation induction was successful initially but difficult to maintain in the face of real weight-loss experience. We were also unable to show that experimentally-induced expectations influenced weight-loss success.<br><br>
Summary and Conclusion
To summarize the findings described above, I have had considerable difficulty over the last 25 years in confirming that the psychosocial variables favored by health behavior theory are of much value for obesity intervention research. They do not predict weight loss well, either as mediators or moderators. There is little evidence to support the idea that targeting them for intervention improves weight-loss outcomes. It is, of course, arguable that the weak findings relating to health behavior theory variables are due in large part to methodological weaknesses, either in measurement tools and/or their frequency of measurement. I would argue, however, that 25 years is long enough to wait for improved methods and that it is time to look elsewhere for variables that better predict weight-change outcomes and that, therefore, may form a better basis for improving future treatments.
Implication for Weight-Loss Treatment
Given the lack of success finding support for cognitive mediators of behavior change in weight loss, one might surmise that progress in improving weight-loss interventions over the last 20 years must have been dreary indeed. Somewhat surprisingly, however, that is not the case. In fact, the short-term (6 to 12 months) success of weight-loss treatments has approximately doubled over that time and several variables have been identified that reliably enhance treatment outcomes. It has been clearly shown experimentally that increasing treatment length [19], prescribing low-energy intakes [20], prescribing high-energy expenditure [21], using a deposit contract and group-based reward systems [22], and simplifying adherence to diet through meal substitutes [23] and exercise by providing exercise equipment [24] all improve initial weight loss. From a theoretical perspective, however, one thing is noteworthy about these successful innovations. Although not incompatible with health behavior theory, none of them are specifically derived from cognitive decision-making models. Indeed, health behavior theory does not include variables like these in its models.<br><br>Where Do We Go From Here?
The argument above about the practical limitations of many popular theories of health behavior is not meant to be a call to abandon theory. Behavior scientists have amassed much useful information about the principles underlying <span class="yellow">human</span> behavior that should be valuable for health behavior interventions. Much is known about <span class="yellow">human</span> perception, learning, motivation, and responsiveness to environmental opportunities and contingencies. Health behavior intervention lies at the interface between <span class="yellow">people</span> and their environment. Interventionists change aspects of the environment (cues, information, behavioral contingencies) with the intention of producing changes in how <span class="yellow">people</span> behave. What is needed to advance health behavior intervention is theory that addresses relationships between modifiable aspects of the environment and behavior. There is no doubt that cognitive processes are involved in these relationships. However, the extent to which current theories capture this is questionable. Data now available suggest that easily obtainable information about <span class="yellow">people</span>'s cognitive processes adds little to our ability to predict the results of interventions. Thus, it may be wise to pay more attention to applied theories like classical behavior theory [25], communications theory [26], and learning theory [27] than to those coming out of the social cognitive traditions.<br><br>
Competing interests
None declared.<br><br>
<h3>pmcA1590010</h3>Drug information resources used by nurse practitioners and collaborating physicians at the point of care in Nova Scotia, Canada: a survey and review of the literature
Abstract
Background
Keeping current with drug therapy information is challenging for health care practitioners. Technologies are often implemented to facilitate access to current and credible drug information sources. In the Canadian province of Nova Scotia, legislation was passed in 2002 to allow nurse practitioners (NPs) to practice collaboratively with physician partners. The purpose of this study was to determine the current utilization patterns of information technologies by these groups of practitioners.<br><br>Methods
Nurse practitioners and their collaborating physician partners in Nova Scotia were sent a survey in February 2005 to determine the frequency of use, usefulness, accessibility, credibility, and current/timeliness of personal digital assistant (PDA), computer, and print drug information resources. Two surveys were developed (one for PDA users and one for computer users) and revised based on a literature search, stakeholder consultation, and pilot-testing results. A second distribution to nonresponders occurred two weeks following the first. Data were entered and analysed with SPSS.<br><br>Results
Twenty-seven (14 NPs and 13 physicians) of 36 (75%) recipients responded. 22% (6) returned personal digital assistant (PDA) surveys. Respondents reported print, health professionals, and online/electronic resources as the most to least preferred means to access drug information, respectively. 37% and 35% of respondents reported using "both print and electronic but print more than electronic" and "print only", respectively, to search monograph-related drug information queries whereas 4% reported using "PDA only". Analysis of respondent ratings for all resources in the categories print,  health professionals and other, and online/electronic resources, indicated  that the Compendium of Pharmaceuticals and Specialties and pharmacists  ranked highly for frequency of use, usefulness, accessibility, credibility,  and current/timeliness by both groups of practitioners. Respondents' preferences and resource ratings were consistent with self-reported methods for conducting drug information queries. Few differences existed between NP and physician rankings of resources.<br><br>Conclusion
The use of computers and PDAs remains limited, which is also consistent with preferred and frequent use of print resources. Education for these practitioners regarding available electronic drug information resources may facilitate future computer and PDA use. Further research is needed to determine methods to increase computer and PDA use and whether these technologies affect prescribing and <span class="yellow">patient</span> outcomes.<br><br><br><br>Background
Challenges with knowledge management for health care professionals
In 1986, Haynes et al. published a series of 6 articles entitled "how to keep up with the medical literature" in an effort to help clinicians with information management, but this challenge has not decreased in last two decades [1-6]. Alper et al. suggest that maintaining currency with relevant literature in primary care would "require 627.5 hours per month, or about 29 hours per weekday, or 3.6 full-time equivalents of physician effort" [7]. The volume of information associated with keeping up to date is frequently cited as a barrier [8]. It is estimated that annually there are approximately 10,000 new randomized trials in MEDLINE and over 450,000 clinical trials identified by the Cochrane Collaboration [9,10]. Keeping up to date has been described with several analogies including clinicians attempting to drink water from a fire hose and swimming in rivers of clinical research with unprecedented depth, velocity, and turbulence [11,12].
Difficulties with dissemination of research evidence and keeping up to date on pharmacotherapeutic interventions are reported despite the development of tools such as clinical practice guidelines and systematic reviews that are intended to reduce the need for practitioners to evaluate original research [13]. To complicate matters further, there are often issues of credibility, timeliness, and volume of clinical practice guidelines and reviews. Many guidelines are criticized for their methodological development. Shaneyfelt et al. reviewed 279 guidelines for methodological standards from peer reviewed medical literature [14]. These authors found that only 51%, 33.6%, and 46% adhered to standards on guideline development and format, evidence identification and summary, and formulation of recommendations, respectively [14]. A Canadian review on drug therapy guidelines found significant variation in quality depending on the developer [13]. Approximately 25% of guidelines were not recommended for use in practice by the appraisers' criteria [13]. As an example of the volume of clinical practice guidelines available, eleven recent guidelines on community acquired pneumonia exist [15]. To add to the complexities involved with keeping current with pharmacotherapeutic management strategies, as of 2000, there were over 22,000 drug products approved for sale in Canada for <span class="yellow">human</span> use [16].
There is also considerable debate regarding what constitutes "evidence" in practice, which contributes to confusion for clinicians [17,18]. Sim et al. succinctly describe the gap between evidence and action as difficulties with obtaining, systematically reviewing, applying in context, and measuring the outcome following application of evidence [19].<br><br>Maintaining competence – nurse practitioners as a new group of prescribers
Competencies for nurse practitioners (NPs) on a local and international level include critically appraising and applying literature and research findings in practice [20-23]. The Canadian Nurses Association (CNA) has developed the Canadian Nurse Practitioner Core Competency Framework that describes the knowledge, skills, judgment, and attributes required for practice. Evidence based practice is integral to pharmacotherapeutic interventions and prescribing competencies [23]. The National Prescribing Centre, an organization of the National Health Service in the UK, describes several competencies around information needs relevant to prescribing and emphasis is placed on using relevant and up to date information in various formats (e.g. print, electronic, verbal). Several related competencies include understanding advantages and disadvantages of information sources and the currency of resources [21]. Researchers in the US developed NP informatics competencies for integration into advanced nursing practice curricula [24]. Competencies related to informatics knowledge include critical analysis of data and information for use in evidence based practice, evaluating and applying relevant information, synthesizing best evidence, and using optimal search strategies to locate clinically sound and useful studies from information resources [24]. Achieving and maintaining competence in these domains as well as a solid foundation in pharmacology is necessary to support NPs in their relatively new role as a prescriber [25-27].<br><br>Knowledge management and information seeking behaviours among nurse practitioners and physicians
Information seeking behaviours of physicians are better documented than NPs [11]. Information related to diagnosis is important to both groups but drug therapy queries may occur more frequently with NPs [28-33]. Research on nurses' behaviours related to information seeking is available from the hospital setting [33-35] but the generalizability of these behaviours to NPs with a prescribing role is unclear. Differences in nursing roles, responsibilities, and legislation, including prescriptive authority, exist depending on the country of practice.<br><br>Nurse practitioners and their collaborating physician partners in Nova Scotia
Nova Scotia is a Canadian province with a population of approximately 942,000 [36]. The province is divided into six health zones that include nine district health authorities, one of which includes the provincial capital and is considered to be urban [37,38]. Health care service delivery is challenging due to many factors including the rural nature of the province, which is estimated to be 60% of population [37,39].
Starting in 1998, the Nova Scotia Department of Health led an initiative to explore different methods of delivering, managing, and funding primary care services. The Strengthening Primary Care in Nova Scotia Communities Initiative (SPCI) was established with the selection of four primary care demonstration sites where a primary health care NP was hired to practice collaboratively with one or more family/general physicians and other members of an interdisciplinary team. Each demonstration site adopted alternative (non fee-for-service) physician payment mechanisms and used electronic <span class="yellow">patient</span> records (EPRs) to support service delivery [41]. Demonstration sites participated in project evaluation components that included, but were not limited to, NP roles, alternative fee structures, consumer satisfaction, and implementation and integration of EPRs [41,42].
Legislation to allow NPs to practice collaboratively with physicians in Nova Scotia was passed in 2002, part way through the SPCI project [39]. Prescriptive authority granted through legislation authorizes NPs to prescribe from a schedule of drugs [43,44]. At the time of conducting this research project, 16 primary health care NPs were in active practice [43].
The EPR component of the SPCI project evaluation provided information on the use of technologies in the community context. Results from the implementation process indicated that considerable attention is required for technology literacy, time for training, and selection of software for EPRs [41]. Although the majority of community-based, non-institutional clinical practice settings in Nova Scotia primarily operate with paper-based charting systems, there is a movement toward integrating electronic technologies, including the EPR, in practice among health care providers, administrators, and the provincial government. In addition to recording <span class="yellow">patient</span> visit information, a component of the EPR package serves to provide drug information resources.
Drug therapy information resources for NPs and nurse prescribers have frequently been described as essential in supporting practice [25,28,29]. The role of NPs is relatively new in Canada [39] and there is limited information available to indicate the type of resources (e.g. print, electronic, EPR based) these prescribers use for drug and therapeutic information queries at the point of care. It is unknown as to whether differences exist regarding types of resources used, drug information needs, and utilization patterns among NPs and collaborating physician partners. Some research has suggested that the degree of multidisciplinary team functioning relates to the adoption of technology or innovations in practice but more research is required to determine the extent of these relationships [45,46].
The use of EPR technology is increasing in Nova Scotia but little information is available regarding the readiness of practitioners for use of specific features such as drug information resources. Based on the EPR related results of the SPCI evaluation, use of these functions could be challenging without proper facilitation. The purpose of the survey for this research was to describe drug information resources used by NPs and their collaborating physician partners at the point of care. The results of the survey will be used to guide further technology implementation strategies and stimulate further discussion around drug information resource usage at the point of care.<br><br>
Methods
Survey development
Survey development involved three stages including identification of important content areas, development of draft questions, and survey refinement.
Identifying important content areas for inclusion in the survey involved conducting a comprehensive English language literature search, consultation with relevant stakeholders (e.g. members of the Nova Scotia Department of Health), and input from subject matter experts at Dalhousie University. The literature review was conducted using the following bibliographic databases: PubMed, Cumulative Index to Nursing and Allied Health Literature (CINAHL), International Pharmaceutical Abstracts (IPA), and Web of Science Citation Databases. Hand and electronic searching of relevant journals was also conducted. Broad search terms were used without limits on publication date or place as nurse practitioner titles, roles and scopes of practice, and terminology regarding technology vary nationally and internationally. Some examples of terms used included nurse practitioner, nurse prescriber, nurse clinicians, district nurse, health visitor, drug information resources, drug information services, information needs, and information technology.
The draft survey was reviewed by the research team to reduce the number of items and improve clarity. The layout of the questionnaire was carefully examined to ensure that it was easy to follow and complete. Research results from a previous investigation of Nova Scotian physicians' behaviours regarding drug information were also used to further revise the survey [47]. This draft questionnaire was pilot tested by two out of province NPs and one physician. The results of the pilot were used to make final revisions to the survey. Based on pilot-testing feedback and investigator consensus, the final survey was divided into 2 versions, one for personal digital assistant (PDA) users and one for computer users.
The 10 page surveys for PDA and computer users had 5 or 6 sections, respectively, and 37 questions, many with multiple parts. The survey content included demographics, computer or PDA use and experience, drug and therapeutic resource use and preferences, PDA future use, perceived barriers and facilitators to PDA use, and technology training preferences.
Section one contained demographic questions such as gender, age, job title, volume of <span class="yellow">patients</span>, and EPR availability in the practice setting. Section two was designed to determine PDA or computer use and experience in the practice setting with questions regarding length of use, costs, and work versus home usage. This section also addressed usage and rating of different drug information resources. Resource ratings were based on the frequency of usage, usefulness, accessibility, credibility, and current/timeliness. Resources were grouped as print (i.e. books, journals, and clinical practice guidelines), online/electronic resources, and health professionals and other. Respondents used 5-point Likert scales (strongly agree to strongly disagree) for rating opinions related to resources. A rating of 6 (not applicable, I do not use this resource) was also included for respondents who did not use a particular resource. Frequency of searching for specific information was rated on a 3-point Likert scale (frequently to never). The final sections of the survey included categorical, open-ended, and Likert scale questions regarding preferred resources, technology barriers, PDA future use, and technology training preferences. Copies of the surveys are attached as an appendix in PDF format [see additional file 1 and 2] or can also be accessed from the Initiative for Medication Management, Policy Analysis, Research & Training (IMPART) website [48].
Ethics approval for the survey was granted through Dalhousie University Research Ethics Board on February 3, 2005.<br><br>Survey population
Licensed, actively practicing, primary health care NPs (n = 16) and their collaborating physician partners (n = 21) were eligible to participate.<br><br>Survey procedures
The survey recruitment procedures were based on the methods of Dillman [49] and Salant and Dillman [50]. Survey packages contained a cover letter, separate surveys for PDA and computer users, and a return self-addressed stamped envelope. The covering letter instructed respondents to self-select the appropriate survey (either PDA or computer) based on their drug information seeking behaviours. <span class="yellow">Participants</span> who had used a PDA at any time were instructed to complete the PDA version of the survey. Those who had never used a PDA for drug information were instructed to complete the computer version of the survey. Several strategies were used to optimize response rate and included: personalized cover letters, coloured paper for surveys, stamped return envelopes, follow-up mailing, and a priority post mailing [51]. The covering letter included coloured logos of Dalhousie University and the Nova Scotia Department of Health representing the investigator affiliations and endorsement of the project.
A master mailing list with names and addresses of NPs and their collaborating physician partners was created. To maintain confidentiality of respondents, a number placed on the bottom right corner of each survey corresponded to a name on the confidential master mailing sheet. The postage paid return envelopes were addressed to the research coordinator at the School of Nursing, Dalhousie University, who matched respondents to the mailing list from the first distribution. The cross-referenced mailing list was not accessible to those entering or analysing data. The research coordinator sent the second distribution to those who had not initially responded. A fluorescent coloured page was included in the second mailing to notify recipients of the second and final mailing status. The second mailing followed 2 weeks after the initial mailing (February 2005). The surveys were sent via Xpresspost™ through Canada Post.<br><br>Data analyses
Quantitative
Data were entered and analysed in Statistical Package for Social Sciences (SPSS) (version 11.5 for Windows). Five surveys were randomly selected as a check for accuracy of data entry. Descriptive statistics were used to describe resource usage by practitioners. Chi Square (Fisher's Exact when cell count less than 5) analyses were used to determine differences in computer or PDA use based on predetermined variables (e.g. high speed Internet connection, number of <span class="yellow">patients</span> per day). Mann Whitney U tests were used to compare physician and NPs Likert scale ratings (1 = strongly agree to 5 = strongly disagree) of resource use. Physician and NP rankings of all resources (print, online/electronic, and health professionals and other) were determined from means of Likert scale ratings (1 = strongly agree, 5 = strongly disagree) for each of the pre-specified characteristics (e.g. frequency of use, accessibility, etc.) and the frequency of use of the resources. The best rankings were assigned for the lowest mean scores and the largest number of the sample using a resource. These rankings (ranks based on mean and ranks based on sample) were then entered into a formula to calculate an overall rank. The formula includes: rank = [(rank according to % of sample using the resource + rank based on mean score) ÷ 2]. This formula was used to account for mean scores based on small samples as these numbers could potentially over or underestimate the value of a resource. Ratings of 6 (i.e. not applicable, I do not use this resource) were excluded from the analyses.<br><br>Qualitative
Comments were entered in a word-processing program and organized by type of respondent (PDA versus computer) and question number. The coded survey number and respondent type (NP or physician) were also included next to comments. Investigators determined themes and categorized comments based on previous experience, knowledge, and familiarity with the topic.<br><br><br><br>Results
Surveys were completed and returned by 75% of eligible <span class="yellow">participants</span> (27 of 36). One physician survey was undeliverable. The response rates from within the NP and physician samples were 88% and 65%, respectively. Complete demographic information is available in Table 1.
Methods for accessing resources and self-reported resource use
Resource use was similar amongst practitioners. Respondents indicated that print resources (mean 4.56, SD 0.80), health professionals (mean 3.26, SD 0.90), and online/electronic resources (mean 2.70, SD 1.20) were the preferred method (1 = least preferred to 5 = most preferred) for accessing drug information. Thirty-seven percent of respondents reported that searching for specific questions related to drug information (e.g. usual dosage, duration of therapy) was conducted using both print and electronic resources (but print use greater than electronic) (Table 2). The preferred means (i.e. print) to access resources was consistent with the most common means of conducting searches for specific drug information queries.
Respondents' ratings for pre-specified print, online/electronic, and professional resources and other, based on means from Likert scales and number of respondents using the resources, are presented in Tables 3, 4, and 5. Of all resources within the print, online/electronic, and health professionals or other categories, NPs and physicians rated the Compendium of Pharmaceuticals and Specialties (CPS) [52] and pharmacists as the top two most frequently used resources for providing drug and therapeutic information. Physicians rated other physicians as the third most frequently used resource. The book Therapeutic Choices [53] ranked third for NPs. Based on written feedback, physicians and NPs consulted pharmacists and other physicians most frequently. The CPS and pharmacists were also ranked as the top two resources overall in terms of usefulness, accessibility, credibility, and current/timeliness for physicians. Rankings by NPs were similar for usefulness, accessibility, and credibility. NPs ranked pharmacists, Therapeutic Choices, and academic detailing first and the CPS as second for current/timeliness.
Within the online/electronic category, electronic clinical practice guidelines (eCPGs) were rated the highest for all characteristics (e.g. usefulness, credibility). Although eCPGs were highly ranked, approximately 30% of the sample reported not using this resource. Other resources in this category were infrequently used based on respondents' self-reports.
Pharmaceutical industry representatives were used as a source of drug information by 85% and 86% of physicians and NPs, respectively (Table 5). This was higher than regional drug information services (used by 23% of physicians and 50% of NPs). After exclusion of traditional health professionals (i.e. physicians, nurses, pharmacists, allied health) in the health professionals and other category, pharmaceutical industry representatives received rankings for second or third for frequency of use, usefulness, accessibility, credibility, and current/timeliness, based on means and number of respondents using this resource (data not shown).<br><br>Differences between nurse practitioners and physicians
A series of Mann Whitney U tests were used to compare the responses of NPs and physicians on their use of print, online/electronic, and health professional resources. In total 95 statistical tests were conducted. The large number of tests increases the likelihood of a type I error as five significant differences would be expected by chance alone at an alpha threshold of 0.05. It is therefore important to treat these results with caution. A limited number of statistically significant (p < 0.05) differences were identified between physicians and NPs and are reported in Table 6. Therapeutic Choices differed significantly for frequency of use with more NPs making use of this resource. Allied health professionals significantly differed between NPs and physicians for accessibility and current/timeliness while NPs were more in agreement with these characteristics of the resource. Nurse colleague credibility and current/timeliness was rated significantly higher by NPs versus physicians.<br><br>Factors influencing electronic technology use at the point of care
Factors such as gender, age, practitioner type (NP vs physician), accessibility, technical support, Internet connection speed, <span class="yellow">patient</span> volume, presence of an EPR, and home computer use were examined to determine if they were associated with the use of a work computer to search for drug information at the point of care. No statistically significant associations were found (Fisher's Exact).<br><br>Additional resources from respondent comments
Respondents indicated other resources and programs, such as clinical calculators, that they would like to access from their computer or PDA. The top three resources that were desired included Canadian clinical practice guidelines, <span class="yellow">patient</span> education information, and ability to track clinical activities/statistics. Further comments from two NP computer survey respondents revealed that a resource on drug interactions and dosages would be desired. One other NP also indicated "up to date info [sic] on drugs to treat various illnesses ie doseage [sic], length of use etc."<br><br>Computer or personal digital assistant use in practice
Approximately 50% of computer survey respondents reported using their work computers for searching drug or therapeutic information related to <span class="yellow">patient</span> care. Of those respondents, just over half (54%) also reported using their home computer for this purpose. Sixty-seven and 17% of PDA survey respondents reported using their PDA for searching drug or therapeutic information related to <span class="yellow">patient</span> care at work and home, respectively.<br><br>Searching on a weekly basis for specific information related to drugs
Of the 24 specified categories of drug information included in the survey, the majority were reported as infrequently searched and a smaller percentage as never searched by respondents (data not shown). The top three categories rated as frequently searched were side effects, adult or usual drug dosage, and most appropriate drug for an indication. (Table 7)<br><br>Issues related to personal digital assistants
Respondents reported their level of agreement with statements related to how PDAs may influence their practice. The statements included aspects of workload (organization and paper work), convenience, and improving quality of care and <span class="yellow">patient</span> outcomes. (Table 8) Respondents agreed that PDAs are a convenient resource but indicated that PDAs would not decrease paperwork or improve <span class="yellow">patient</span> health outcomes.<br><br>Barriers and facilitators to personal digital assistants: themes from written comments
Peer support from colleagues, convenience, standardized usage, and financial and technical support were the main perceived facilitators to PDA use reported by respondents. The main perceived barrier to PDA use reported by respondents (n = 10) included cost. Other factors such as technology literacy, time, lack of peer support, no high speed internet for downloads, lack of needed resources, keeping up to date on resources, and searching speed were also reported.<br><br>Future use of personal digital assistants
Fifty-two percent, including current PDA users, reported that they would use a PDA in the future. Twenty two percent were  uncertain and 19% reported that they would not use a PDA in the future. Two <span class="yellow">people</span> did not respond.<br><br>Confidentiality
Fifty two percent of respondents indicated that <span class="yellow">patient</span> confidentiality with PDAs was no more concerning compared to use of other technologies. Forty-four percent did not know if they had a policy on <span class="yellow">patient</span> confidentiality with regard to technologies.<br><br>Technology training and reimbursement
Respondents rated (1 = least preferred to 5 = most preferred) one on one instruction and group learning led by an expert facilitator as the most preferred (mean 4.32, SD 0.99) means by which to receive instruction on a new technology. Least preferred methods included online discussions/chatrooms (mean 1.52, SD 1.04), internet videos (live: mean 1.70, SD 1.10, or static: mean 1.87, SD 1.14), video cassettes (mean 2.30, SD 1.55), trial and error learning (mean 2.32, SD 1.28), and written manuals (mean 2.92, SD 1.44). Paid leave for attendance at technology training sessions was the preferred means (mean 1.77, SD 0.86; 1 = strongly agree to 5 = strongly disagree) of remuneration for respondents. Respondents also indicated that if financial remuneration was to occur, it should correspond to the amount of time for training that is required (versus a flat rate) (mean 1.96, SD 1.08). Continuing education credits were not viewed as an incentive (mean 2.69, SD 1.44).<br><br>
Discussion
Preferred resources
In our study, printed materials (e.g. compendia, journals, textbook resources) and professionals (e.g. pharmacists) were the most preferred and frequently used means to access information. Physician reliance on text and compendia relative to online/electronic resources has been frequently reported [11]. In a study examining family doctors' use of information sources to answer clinical questions, <span class="yellow">human</span> resources (e.g. doctor, pharmacist), non-prescribing print information (e.g. textbooks and journal articles), and prescribing texts were used 36%, 32%, and 25% of the time, respectively [54]. Books from the workplace were reported by approximately 79% of UK primary care nurses as a commonly used source of knowledge and information used to support practice [55]. Fewer than one-third (31%) reported using electronic resources (e.g. Internet, electronic journals) for this purpose [55]. Results of a postal questionnaire to NPs demonstrated that 61% and 51% of respondents reported using drug reference manuals and textbooks, respectively, a few times a week or more [29]. These frequencies were second and third only to consulting with their physician supervisor (63%). Data from structured interviews of a sample of 22 community nurse prescribers reported by Hall et al. revealed that the majority relied on print materials to access information, namely the British National Formulary [32]. A survey of a primary care practice-based research network in the US that included physicians, physician assistants, and nurse practitioners, revealed that interpersonal and rapidly accessed print resources were preferred. Sixty-one and 58% of respondents reported using drug reference sources such as the Physician's Desk Reference (PDR) and medical textbooks, respectively, a few times a day or daily [56].
The clinicians in our sample perceived the Canadian compendium, the CPS, to be useful, accessible, credible, and current/timely. The CPS, is described as "the Canadian drug reference for health professionals" and is intended to provide a central source of drug information on drug products available in Canada [52]. It is available in print (English and French) and became available online in June 2004. The CPS includes drug monographs for commonly used products approved for use in Canada, but it does not include all drugs available on the Canadian market [57]. The majority of these product monographs are based on monographs submitted by pharmaceutical manufacturers and approved by Health Canada. Some of the monographs are written by the Canadian Pharmacists Association and are described as being evidence-based [52]. The CPS also includes more than 100 pages of clinical tools [52]. The CPS has been criticized for including pharmaceutical company advertising and requiring manufacturer payment for inclusion of product monographs [58]. The accuracy of particular components of CPS monographs has also been investigated. A review of overdose management in 119 monographs from the 2001 CPS revealed considerable variability in the utility of information with 50% of the monographs containing misleading or dangerous advice [59]. Since 2004, the CPS has included an alert box in the overdose section of monographs notifying users to contact Poison Control Centres for overdose management information. Some authors have criticized references that are similar to the CPS as being inadequate with regard to inclusion of evidence based information [60].
The NPs in our sample also rated Therapeutic Choices highly for all characteristics.  This finding is most likely  attributable to the fact that it is a recommended resource for coursework  associated with the Dalhousie NP university program curriculum.  Therapeutic Choices is a concise therapeutics reference text published by the Canadian Pharmacists Association. The text contains approximately 120 extensively referenced chapters with a disease management approach including easy to use algorithms and tables. An editorial board is responsible for extensively reviewing the content to ensure unbiased and objective information is presented [53].<br><br>Health professionals
Reliance on other health professionals, especially pharmacists and physicians, as a resource for information was evident from our study and concurs with the findings of others [28,32,55,61]. Nurse practitioners have reported that collaborative relationships with pharmacists increase NP role satisfaction [61]. NPs frequently consult with allied health care professionals in their primary health care provider role and this is supported by written feedback from our sample regarding frequently consulted health professionals. Nursing colleagues are also likely to be rated highly by NPs due to their affiliation with peers from the same profession.
Some investigators have shown that non-<span class="yellow">human</span> references (e.g. textbook) are sought for more technical aspects of prescribing (e.g. dose), whereas guidance regarding selection of agents (i.e. right drug for an indication) is sought from <span class="yellow">human</span> resources (e.g. pharmacists or physicians) [62]. We were unable to determine what kinds of resources were used for specific purposes from our study.<br><br>Online and electronic resources, computers, and personal digital assistants
From our study, computer survey respondents ranked online/electronic resources third in preference following print and health professionals. Various barriers and facilitators to accessing information online/electronically or via the Internet have been described in the literature [55,63-66]. Variables that have been described by others as barriers such as accessibility, high speed internet access, <span class="yellow">patient</span> volume, age, practitioner type, and technology support did not appear to influence computer searching for information on drugs or therapeutics related to <span class="yellow">patient</span> care in our results. Some qualitative feedback does however support this notion. As an example, in response to a request for a rationale for not using computers one physician commented: "Retro tech [sic]/old fashion. I still like to use my mind and have always been a fan of pen and paper". Barriers that were identified with our sample regarding the use of handheld technologies such as PDAs included cost, time, and issues related to technology literacy. Several <span class="yellow">people</span> questioned the value of PDAs. One GP stated when referring to a PDA: "So far I have not discovered a use for one". Other respondents reinforced their preferences for other resources (e.g. books) and resistance to technology. When responding to barriers for the use of PDAs, one NP commented, "My huge dislike for machinery that frequently requires updating and patience". A physician responded, "as stated, I like to use my own mind, and can get all the info I need from books relatively quickly". Facilitators to the use of PDAs mainly included convenience factors such as having resources all in one place, faster means to get information, and portability. Our sample was not in agreement with some convenience factors in that they did not feel that PDAs would decrease paperwork. Practitioners from our sample felt relatively neutral about PDAs improving <span class="yellow">patient</span>'s health outcomes with 41% responding in this manner. Results from a sample of primary care practitioners in the US revealed that 76% agreed that the use of handheld devices for electronic prescribing would substantially reduce medical errors and improve the quality of health care [67].
Our study also suggests that resources such as the Cochrane Library and its Database of Systematic Reviews were not frequently used. This finding is similar to that of other investigators [30,35,64]. Despite the desire of some clinicians to use these resources, lack of confidence and ability to use them appropriately has been found [30,64,68,69]. Our study suggests that although this resource is perceived as credible, current/timely, and useful, it is also perceived to be somewhat inaccessible. The Cochrane Library is available to the health professionals (e.g. nurses, physicians, pharmacists, occupational therapists, physiotherapists, etc.) in our sample through professional bodies via the Atlantic Health Knowledge Partnership [70].<br><br>Technology training: preferences and incentives
With regard to receiving training for a new technology, our study demonstrates that in <span class="blue">person</span> conferences or one on one training sessions are the preferred means to receive continuing education. <span class="yellow">Person</span> to <span class="blue">person</span> interaction has been reported as the preferred and most frequently used means to access continuing education or training by other investigators [55,71].
Our study also indicates that this group of practitioners may benefit from accessing resources [72-80] that provide guidance on useful drug information resources available for devices such as PDAs. This is exemplified by one respondent's statement "knowledge regarding good software programs" as a barrier to the use of PDAs.<br><br>Pharmaceutical industry
The influence of the pharmaceutical industry on physician prescribing and research outcomes has been documented [81,82]. Although NP use of industry representatives as a source of pharmacological information has been documented, the influence on prescribing is largely uninvestigated [32,61,83-85]. The CNA competency framework includes a statement regarding prescribing and industry relations [23]. In our study, the physician and NP rankings of industry representatives were similar. Within the health professionals and other category, pharmaceutical representatives were used as a resource by more of the sample than regional drug information services and comparably to academic detailing services. Academic detailing is a form of continuing  medical education where a trained health professional visits prescribers for  a fifteen to twenty minute session to provide objective information  regarding a therapeutic topic based on best available evidence [86,87]. Following academic detailing, physician and NP rankings of pharmaceutical industry representatives were second or third for frequency of use, usefulness, accessibility, credibility, and current/timeliness.<br><br>Limitations
We do not have demographics or information regarding the reasons why survey recipients did not respond. As per ethical requirements to maintain confidentiality of respondents, we were not able to match respondents from their respective place of practice and therefore cannot conclude whether the practitioners within a practice setting influenced the others' responses. The sample size of the survey is small although it includes 88% response from community based NPs in Nova Scotia. The generalizability of the results is limited due to the variations in NP scopes of practice nationally and internationally. It is unknown whether the findings are generalizable to nonresponding physicians within Nova Scotia collaborating with NPs or to physicians not in collaborative practices with NPs as they were not included as a part of the sample. Due to multiple statistical comparisons (Mann Whitney U), the results comparing NP and physician ratings of results should be interpreted with caution.<br><br>
Conclusion
Respondent ratings of resources and preferences for resource use were consistent with self-reported means of conducting searches for specific drug information queries. The use of computers and PDAs remains limited and also matches preferences and resource ratings. Education to this group of practitioners regarding available drug information resources may facilitate use of computer and PDA resources. Further research is needed to determine methods to increase the use of computers and PDAs and if use of these technologies affects prescribing and <span class="yellow">patient</span> outcomes.<br><br>Competing interests
Ingrid Sketris holds a Chair from Canadian Institutes of Health Research (CIHR), Canadian Health Services Research Foundation (CHSRF) co-sponsored by the Nova Scotia Health Research Foundation (NSHRF). Andrea Murphy received salary support through this Chair as a research fellow at the time of conducting this research. The survey was performed in fulfillment of the requirements for the Drug Use Management and Policy Residency that Murphy participated in as a part of her fellowship. The residency was conducted with a decision making partner from the Nova Scotia Department of Health.
The opinions expressed in this paper are those of the authors and do not represent the opinions of the Nova Scotia Department of Health, CIHR/CHSRF or NSHRF.
MF, MM, RMM, and DG have no competing interests to declare.<br><br>Authors' contributions
AM conceptualized the design and composed the survey instruments, carried out the study, entered and analyzed the data, drafted the original manuscript, and modified subsequent drafts based on authors' and reviewers' feedback. MF, RMM, IS, MM, and DG reviewed and suggested revisions to the survey tools, covering letters, overall study design, and contributed to feedback on the analysis and manuscript revisions.<br><br>Pre-publication history
The pre-publication history for this paper can be accessed here:<br><br>
Supplementary Material<br><br>
</body></html>